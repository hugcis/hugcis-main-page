<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NAS on Hugo Cisneros</title>
    <link>https://hugocisneros.com/tags/nas/</link>
    <description>Recent content in NAS on Hugo Cisneros</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Mar 2021 09:58:00 +0100</lastBuildDate><atom:link href="https://hugocisneros.com/tags/nas/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Notes on: Evolving Neural Networks through Augmenting Topologies by Stanley, K. O., &amp; Miikkulainen, R. (2002)</title>
      <link>https://hugocisneros.com/notes/stanleyevolvingneuralnetworks2002/</link>
      <pubDate>Thu, 25 Mar 2021 09:58:00 +0100</pubDate>
      
      <guid>https://hugocisneros.com/notes/stanleyevolvingneuralnetworks2002/</guid>
      <description>tags Neural networks, Genetic algorithms, NAS source (Stanley and Miikkulainen 2002)  Summary This is the main paper introducing the NEAT system. This system is a direct-encoding based way of dealing with neuroevolution (evolution of ANNs). The encoding is based on a genome sequentially specifying each of the connections between modules of the network. Several tickes are used to make it possible applying GA methods to evolve networks:
 Historical tracking of genes to be able to align architectures and mate them.</description>
    </item>
    
    <item>
      <title>Notes on: Neuroevolution: from architectures to learning by Floreano, D., Dürr, P., &amp; Mattiussi, C. (2008)</title>
      <link>https://hugocisneros.com/notes/floreanoneuroevolutionarchitectureslearning2008/</link>
      <pubDate>Thu, 25 Mar 2021 09:58:00 +0100</pubDate>
      
      <guid>https://hugocisneros.com/notes/floreanoneuroevolutionarchitectureslearning2008/</guid>
      <description> tags NAS source (Floreano, Dürrand Mattiussi 2008)  Summary Comments Bibliography Floreano, Dario, Peter Dürrand Claudio Mattiussi. March 1, 2008. &#34;Neuroevolution: From Architectures to Learning&#34;. Evolutionary Intelligence 1 (1):47–62. DOI.  </description>
    </item>
    
    <item>
      <title>Notes on: Learning Transferable Architectures for Scalable Image Recognition by Zoph, B., Vasudevan, V., Shlens, J., &amp; Le, Q. V. (2018)</title>
      <link>https://hugocisneros.com/notes/zophlearningtransferablearchitectures2018/</link>
      <pubDate>Thu, 25 Mar 2021 09:57:00 +0100</pubDate>
      
      <guid>https://hugocisneros.com/notes/zophlearningtransferablearchitectures2018/</guid>
      <description>tags NAS source (Zoph et al. 2018)  Summary This paper is more or less a follow up of (Zoph and Le 2017) where the search space get at the same time widened and more constraints are added (division between normal cell for processing and reduction cell for pooling/downsampling). Normal cells get stacked \(N\) times resulting in very big architectures. NASNet is created by searching for thos cells but the actual number of cells stacked and number of filters of the penultimate layer are searched separately.</description>
    </item>
    
    <item>
      <title>Notes on: Neural Architecture Search with Reinforcement Learning by Zoph, B., &amp; Le, Q. V. (2017)</title>
      <link>https://hugocisneros.com/notes/zophneuralarchitecturesearch2017/</link>
      <pubDate>Thu, 25 Mar 2021 09:57:00 +0100</pubDate>
      
      <guid>https://hugocisneros.com/notes/zophneuralarchitecturesearch2017/</guid>
      <description>tags NAS source (Zoph and Le 2017)  Summary This paper introduces the idea of using a RNN controller system to generate the operations of a neural network. In a first setting the authors use this method to construct CNNs. The controller samples an architecture, the architecture is built and trained and the controller is rewarded with the maximum validation accuracy of the last 5 epochs cubed (??).
Another experiment uses this exploration method to produce recurrent cell through a complicated model based on a tree of units, for each of which the controller samples an operation.</description>
    </item>
    
  </channel>
</rss>
