<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Complexity on Hugo Cisneros</title><link>https://hugocisneros.com/tags/complexity/</link><description>Recent content in Complexity on Hugo Cisneros</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 12 Apr 2022 07:50:00 +0200</lastBuildDate><atom:link href="https://hugocisneros.com/tags/complexity/index.xml" rel="self" type="application/rss+xml"/><item><title>Complexity metrics</title><link>https://hugocisneros.com/notes/complexity_metrics/</link><pubDate>Tue, 12 Apr 2022 07:50:00 +0200</pubDate><guid>https://hugocisneros.com/notes/complexity_metrics/</guid><description>tags Complexity To study the complexity of various systems, researchers have come up with various metrics. They are based on several principles such as Information theory or Algorithmic Information theory. Many of these metrics are described in (Grassberger 1989).
Shannon entropy and Kolmogorov Complexity The paper (Grunwald, Vitányi 2004) is a great description and analysis of two of the most important Complexity metrics:
Shannon entropy Kolmogorov complexity Information-theoretic metrics Shannon entropy AIT based metrics For a Universal computer \(U\) the algorithmic information of \(S\) relative to \(U\) is defined as the length of the shortest program that yields \(S\) on \(U\).</description></item><item><title>Notes on: More Is Different by Anderson, P. W. (1972)</title><link>https://hugocisneros.com/notes/andersonmoredifferent1972/</link><pubDate>Sun, 16 May 2021 14:37:00 +0200</pubDate><guid>https://hugocisneros.com/notes/andersonmoredifferent1972/</guid><description>tags Complexity, Philosophy source (Anderson 1972) This is a fundamental paper discussing the fundamental laws of Physics and their relations with complexity.
Reductionism doesn&amp;rsquo;t imply constructionism It is generally accepted that the fundamental laws governing our Universe are relatively simple. We feel we understand many of these laws quite well. However, understanding these fundamental laws are far from enough to actually describe and reconstruct all phenomena we witness.</description></item><item><title>Lempel-Ziv-Welch algorithm</title><link>https://hugocisneros.com/notes/lempel_ziv_welch_algorithm/</link><pubDate>Tue, 04 May 2021 09:22:00 +0200</pubDate><guid>https://hugocisneros.com/notes/lempel_ziv_welch_algorithm/</guid><description>tags Compression, Complexity papers (Lempel, Ziv 1976; Ziv, Lempel 1977; Ziv, Lempel 1978; Welch 1984; Storer, Szymanski 1982) Context The LZW algorithm was originally designed as a complexity (&amp;ldquo;randomness&amp;rdquo;) metric for finite sequences (Lempel, Ziv 1976). It was then extended as a compression algorithm by the same authors to LZ77 (Ziv, Lempel 1977) and LZ78 (Ziv, Lempel 1978). Those last two are the basis of many well known and widely used compression utilities such as GIF, compress (LZW (Welch 1984) ) or DEFLATE, gzip (LZSS (Storer, Szymanski 1982)), etc.</description></item><item><title>Open-ended Evolution</title><link>https://hugocisneros.com/notes/open_ended_evolution/</link><pubDate>Mon, 12 Apr 2021 14:56:00 +0200</pubDate><guid>https://hugocisneros.com/notes/open_ended_evolution/</guid><description>tags Evolution, Complexity, Artificial Intelligence resources Open-endedness: The last grand challenge you’ve never heard of My idea of Open Ended evolution thoughtsopen-ended-evolution As part of my research, I have been thinking a lot about open-ended evolution and what this concept means to me. Although it is still early in my research journey, I will go into the process of writing down my thoughts about this very challenging concept in order to have material on which I will be able to reflect later and understand how my beliefs have changed.</description></item><item><title>Kolmogorov complexity</title><link>https://hugocisneros.com/notes/kolmogorov_complexity/</link><pubDate>Thu, 25 Mar 2021 09:58:00 +0100</pubDate><guid>https://hugocisneros.com/notes/kolmogorov_complexity/</guid><description>tags Complexity, Algorithmic Information theory, Computability theory Definition Invariance theorem For two descriptive languages \(L_1\) and \(L_2\) and their respective associated Kolmogorov complexity functions \(K_1\) and \(K_2\), there exist a constant \(c\) &amp;mdash; dependant only on \(L_1, L_2\) such that \[ \forall s, -c \leq K_1(s) - K_2(s) \leq c \]
In other words, there is always a bounded difference between the Kolmogorov complexity in two separate description languages.</description></item><item><title>Minimum description length</title><link>https://hugocisneros.com/notes/minimum_description_length/</link><pubDate>Thu, 25 Mar 2021 09:58:00 +0100</pubDate><guid>https://hugocisneros.com/notes/minimum_description_length/</guid><description> tags Complexity, Algorithmic Information theory papers (Grunwald 2007; Grunwald 2004) Bibliography Peter Grunwald. 2007. The Minimum Description Length Principle. Adaptive Computation and Machine Learning. Cambridge, Mass: MIT Press. Peter Grunwald. June 4, 2004. "A Tutorial Introduction to the Minimum Description Length Principle". Arxiv:math/0406077. http://arxiv.org/abs/math/0406077.</description></item><item><title>Notes on: Complexity and evolution: What everybody knows by McShea, D. W. (1991)</title><link>https://hugocisneros.com/notes/mcsheacomplexityevolutionwhat1991/</link><pubDate>Thu, 25 Mar 2021 09:57:00 +0100</pubDate><guid>https://hugocisneros.com/notes/mcsheacomplexityevolutionwhat1991/</guid><description> tags Evolution, Complexity source (McShea 1991) Summary Comments Bibliography Daniel W. McShea. July 1991. "Complexity and Evolution: What Everybody Knows". Biology &amp; Philosophy 6 (3):303–24. DOI.</description></item><item><title>Notes on: The Architecture of Complexity by Simon, H. A. (1962)</title><link>https://hugocisneros.com/notes/simonarchitecturecomplexity1962/</link><pubDate>Thu, 25 Mar 2021 09:57:00 +0100</pubDate><guid>https://hugocisneros.com/notes/simonarchitecturecomplexity1962/</guid><description>tags Complexity, Complex Systems source (Simon 1962) Complex systems In such systems, the whole is more than the sum of the parts, not in an ultimate, metaphysical sense, but in the important pragmatic sense that, given the properties of the parts and the laws of their interaction, it is not a trivial matter to infer the properties of the whole. In the face of complexity, an in-principle reductionist may be at the same time a pragmatic holist.</description></item><item><title>Complexity of cellular automata</title><link>https://hugocisneros.com/notes/complexity_of_cellular_automata/</link><pubDate>Wed, 25 Nov 2020 09:20:00 +0100</pubDate><guid>https://hugocisneros.com/notes/complexity_of_cellular_automata/</guid><description> tags Complexity, Cellular automata Measuring complexity created by cellular automata is a vast subject.
Using Entropy In (3.0.CO;2-V"Wuensche 1999), the author uses the entropy of rule table lookup frequencies to evaluate the complexity of a CA.
Bibliography 3.0.CO;2-V"Andrew Wuensche. 1999. "Classifying Cellular Automata Automatically: Finding Gliders, Filtering, and Relating Space-time Patterns, Attractor Basins, and the Z Parameter". Complexity 4 (3):47–66. 3.0.CO;2-V"DOI.</description></item><item><title>Self-replication</title><link>https://hugocisneros.com/notes/self_replication/</link><pubDate>Thu, 12 Nov 2020 11:49:00 +0100</pubDate><guid>https://hugocisneros.com/notes/self_replication/</guid><description> tags Complexity, Self-organization An early example of artificial self-replication is Von Neumann&amp;rsquo;s self-reproducing CA which is a cellular automaton.
Self-replication in neural networks can be done with neural network quines (Chang, Lipson 2018).
Bibliography Oscar Chang, Hod Lipson. May 24, 2018. "Neural Network Quine". Arxiv:1803.05859 [cs]. http://arxiv.org/abs/1803.05859.</description></item><item><title>Algorithmic probability</title><link>https://hugocisneros.com/notes/algorithmic_probability/</link><pubDate>Tue, 14 Jul 2020 08:34:00 +0200</pubDate><guid>https://hugocisneros.com/notes/algorithmic_probability/</guid><description> tags Complexity, Algorithmic Information theory</description></item><item><title>Emergence</title><link>https://hugocisneros.com/notes/emergence/</link><pubDate>Thu, 02 Jul 2020 09:13:00 +0200</pubDate><guid>https://hugocisneros.com/notes/emergence/</guid><description> tags Complexity</description></item></channel></rss>