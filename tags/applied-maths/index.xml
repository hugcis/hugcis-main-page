<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Applied maths on Hugo Cisneros</title><link>https://hugocisneros.com/tags/applied-maths/</link><description>Recent content in Applied maths on Hugo Cisneros</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 04 Aug 2022 14:09:00 +0200</lastBuildDate><atom:link href="https://hugocisneros.com/tags/applied-maths/index.xml" rel="self" type="application/rss+xml"/><item><title>Kullback-leibler divergence</title><link>https://hugocisneros.com/notes/kullback_leibler_divergence/</link><pubDate>Thu, 04 Aug 2022 14:09:00 +0200</pubDate><guid>https://hugocisneros.com/notes/kullback_leibler_divergence/</guid><description>tags Applied maths Definition The KL divergence is not symmetric. For \(P, Q\) defined on the same probability space \(\mathcal{X}\), KL of \(Q\) from \(P\) is \[ KL(P, Q) = \sum_{x \in \mathcal{X}} P(x) \log\left( \frac{P(x)}{Q(x)} \right) \]
It has two main interpretations:
It is the information gain from using the right probability distribution \(P\) instead of \(Q\) or the amount of information lost by approximating \(P\) with \(Q\). The average difference in code length for a sequence following \(P\) and using a code optimized for \(Q\) to encode it.</description></item><item><title>Machine learning</title><link>https://hugocisneros.com/notes/machine_learning/</link><pubDate>Tue, 19 Apr 2022 13:17:00 +0200</pubDate><guid>https://hugocisneros.com/notes/machine_learning/</guid><description>tags Artificial Intelligence, Applied maths Machine learning is about constructing algorithms that can approximate complex functions from observations of input/output pairs. Machine learning is related to Statistics since its goal is to make predictions based on data.
Examples of such functions include:
Image classification Time-series prediction Language modeling Regression The goal is to approximate a target function \(f\) or signal \(S\).</description></item><item><title>Cryptography</title><link>https://hugocisneros.com/notes/cryptography/</link><pubDate>Sun, 17 Apr 2022 13:13:00 +0200</pubDate><guid>https://hugocisneros.com/notes/cryptography/</guid><description> tags Applied maths, Computer science</description></item><item><title>Softmax</title><link>https://hugocisneros.com/notes/softmax/</link><pubDate>Fri, 27 Aug 2021 15:41:00 +0200</pubDate><guid>https://hugocisneros.com/notes/softmax/</guid><description> tags Applied maths The Softmax can refer to two mathematical functions:
In machine learning a softmax is the function which normalizes a vector of values to a probability vector: \(\text{softmax}(\mathbf{x}) = \dfrac{e^{\mathbf{x}}}{\sum_i e^{x_i}}\) where \(\mathbf{x} = (x_i) \in \mathbb{R}^n\). This function could also be called soft-argmax because it is a smooth approximation of the discrete argmax function. It may also refer to a smoothed maximum function like \(\epsilon \log \sum_i \exp (x_i / \epsilon)\) which approximates the \(\text{max}\) function in the limit \(\epsilon \rightarrow 0\)</description></item><item><title>System of linear equations</title><link>https://hugocisneros.com/notes/system_of_linear_equations/</link><pubDate>Tue, 24 Aug 2021 15:04:00 +0200</pubDate><guid>https://hugocisneros.com/notes/system_of_linear_equations/</guid><description>tags Applied maths Such a system with \(m\) equations and \(n\) unknowns is often denoted \(Ax = b\) where \(A\) is a matrix \(m\times n\) and \(b\) is a vector of size \(m\).
There are multiple methods to solve such a systems with different sets of hypotheses.
System types Square matrix with full rank In the most simple case: a square matrix with full rank, the solution exists and is unique: \(x = A^{-1} b\)</description></item><item><title>Generalization in Machine learning</title><link>https://hugocisneros.com/notes/generalization_in_machine_learning/</link><pubDate>Fri, 23 Apr 2021 11:26:00 +0200</pubDate><guid>https://hugocisneros.com/notes/generalization_in_machine_learning/</guid><description> tags Machine learning, Applied maths</description></item><item><title>Attractor networks</title><link>https://hugocisneros.com/notes/attractor_networks/</link><pubDate>Mon, 19 Apr 2021 11:24:00 +0200</pubDate><guid>https://hugocisneros.com/notes/attractor_networks/</guid><description>tags Physics, Applied maths, Neural networks resources Scholarpedia Attractor networks are sets of nodes connected in such a way that their dynamics are stable in a small subspace of their phase space. The network state usually resides on this smaller manifold after a few evolution steps.
These networks are often recurrent.</description></item><item><title>Diffusion limited aggregation</title><link>https://hugocisneros.com/notes/diffusion_limited_aggregation/</link><pubDate>Thu, 25 Mar 2021 09:58:00 +0100</pubDate><guid>https://hugocisneros.com/notes/diffusion_limited_aggregation/</guid><description> tags Applied maths, Physics</description></item><item><title>Ordinary least squares</title><link>https://hugocisneros.com/notes/ordinary_least_squares/</link><pubDate>Thu, 25 Mar 2021 09:56:00 +0100</pubDate><guid>https://hugocisneros.com/notes/ordinary_least_squares/</guid><description> tags Applied maths, Optimization</description></item><item><title>Automatic differentiation</title><link>https://hugocisneros.com/notes/automatic_differentiation/</link><pubDate>Wed, 03 Mar 2021 08:43:00 +0100</pubDate><guid>https://hugocisneros.com/notes/automatic_differentiation/</guid><description> tags Applied maths, Optimization</description></item><item><title>Nyström method</title><link>https://hugocisneros.com/notes/nystrom_method/</link><pubDate>Wed, 10 Feb 2021 09:36:00 +0100</pubDate><guid>https://hugocisneros.com/notes/nystrom_method/</guid><description> tags Applied maths This method was introduced as a way to speed-up kernel machines in (Williams, Seeger 2001).
Bibliography Christopher Williams, Matthias Seeger. 2001. "Using the Nyström Method to Speed up Kernel Machines". In Advances in Neural Information Processing Systems, edited by T. Leen, T. Dietterich, and V. Tresp, 13:682–88. MIT Press. https://proceedings.neurips.cc/paper/2000/file/19de10adbaa1b2ee13f77f679fa1483a-Paper.pdf.</description></item><item><title>Wavelets</title><link>https://hugocisneros.com/notes/wavelets/</link><pubDate>Wed, 04 Nov 2020 09:23:00 +0100</pubDate><guid>https://hugocisneros.com/notes/wavelets/</guid><description> tags Applied maths, Signal processing Wavelets are functions with specific properties that make them useful when dealing with images. They are used for lossy image compression.
Types of wavelets Haar wavelets Daubechies wavelets</description></item><item><title>Signal processing</title><link>https://hugocisneros.com/notes/signal_processing/</link><pubDate>Wed, 04 Nov 2020 09:18:00 +0100</pubDate><guid>https://hugocisneros.com/notes/signal_processing/</guid><description> tags Applied maths</description></item><item><title>Image processing</title><link>https://hugocisneros.com/notes/image_processing/</link><pubDate>Wed, 04 Nov 2020 09:17:00 +0100</pubDate><guid>https://hugocisneros.com/notes/image_processing/</guid><description>tags Applied maths, Signal processing Scale an image with no interpolation Imagemagick documentation
convert source.[png|gif|...] -scale 400% target.[png|gif|...] The scale option can also take integer parameters (without the percent sign) to indicate the target size.
Remove metadata from an image Useful for preserving Online privacy when publishing images. Pictures taken with smartphones and other modern devices often contain large amounts of data about location, time and date and device type.</description></item><item><title>Dynamical systems</title><link>https://hugocisneros.com/notes/dynamical_systems/</link><pubDate>Tue, 27 Oct 2020 20:26:00 +0100</pubDate><guid>https://hugocisneros.com/notes/dynamical_systems/</guid><description> tags Applied maths, Physics</description></item><item><title>Optimization</title><link>https://hugocisneros.com/notes/optimization/</link><pubDate>Fri, 02 Oct 2020 16:43:00 +0200</pubDate><guid>https://hugocisneros.com/notes/optimization/</guid><description> tags Mathematics, Applied maths</description></item><item><title>Optimal control</title><link>https://hugocisneros.com/notes/optimal_control/</link><pubDate>Wed, 23 Sep 2020 11:56:00 +0200</pubDate><guid>https://hugocisneros.com/notes/optimal_control/</guid><description>tags Applied maths resources Book by Daniel Liberzon Optimal control problem An typical optimal control problem starts with a control system \[ \dot{x} = f(t, x, u), \quad x(t_0) = x_0 \] where \(x\) is the state of the system, \(t\) represents time and \(u\) is the control input.
The goal of an OC problem is to minimize a cost functional of the form \[ J(u) := \int_{t_0}^{t_f}L(t, x(t), u(t))dt + K(t_f, x_f).</description></item><item><title>Fast Marching method</title><link>https://hugocisneros.com/notes/fast_marching_method/</link><pubDate>Mon, 07 Sep 2020 10:30:00 +0200</pubDate><guid>https://hugocisneros.com/notes/fast_marching_method/</guid><description>tags Applied maths, Algorithm The fast marching method can be seen as a way to improve the metric issue with Dijkstra&amp;rsquo;s algorithm (which actually computes the \(\ell_1\) distance on a grid). The graph update is replaced with the Eikonal equation resolution in the FM method. This reduces the bias of using a grid and converges towards the underlying geodesic distance when the grid step size tends towards 0.
The FM algorithm replaces the graph update (\(D_j \leftarrow \min_{k \sim j} D_k + W_j\)) with a local resolution of the Eikonal equation</description></item><item><title>Dijkstra's algorithm</title><link>https://hugocisneros.com/notes/dijkstra_s_algorithm/</link><pubDate>Mon, 07 Sep 2020 10:28:00 +0200</pubDate><guid>https://hugocisneros.com/notes/dijkstra_s_algorithm/</guid><description> tags Applied maths, Algorithm</description></item><item><title>Noise</title><link>https://hugocisneros.com/notes/noise/</link><pubDate>Mon, 27 Jul 2020 14:03:00 +0200</pubDate><guid>https://hugocisneros.com/notes/noise/</guid><description> tags Statistics, Applied maths</description></item><item><title>SIR model</title><link>https://hugocisneros.com/notes/sir_model/</link><pubDate>Thu, 09 Jul 2020 14:29:00 +0200</pubDate><guid>https://hugocisneros.com/notes/sir_model/</guid><description>tags Applied maths resources Wikipedia Simplest form The SIR model is defined for a population \(N\), \(S\) the number of susceptible persons, \(I\) the number of infected people and \(R\) the number of poeple who have recovered. The following system of differential equations governs the evolution of those three variables:
\[ \frac{dS}{dt} = - \frac{\beta I S}{N} \] \[ \frac{dI}{dt} = \frac{\beta I S }{N}- \gamma I \] \[ \frac{dR}{dt} = \gamma I \]</description></item><item><title>Statistics</title><link>https://hugocisneros.com/notes/statistics/</link><pubDate>Thu, 09 Jul 2020 14:28:00 +0200</pubDate><guid>https://hugocisneros.com/notes/statistics/</guid><description> tags Applied maths</description></item><item><title>Optimal transport</title><link>https://hugocisneros.com/notes/optimal_transport/</link><pubDate>Thu, 02 Jul 2020 10:23:00 +0200</pubDate><guid>https://hugocisneros.com/notes/optimal_transport/</guid><description> tags Applied maths</description></item></channel></rss>