<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NLP on Hugo Cisneros - Personal page</title>
    <link>https://hugocisneros.com/tags/nlp/</link>
    <description>Recent content in NLP on Hugo Cisneros - Personal page</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 25 Mar 2019 12:00:00 +0000</lastBuildDate><atom:link href="https://hugocisneros.com/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Posos Challenge</title>
      <link>https://hugocisneros.com/projects/posos_dl/</link>
      <pubDate>Mon, 25 Mar 2019 12:00:00 +0000</pubDate>
      
      <guid>https://hugocisneros.com/projects/posos_dl/</guid>
      <description>Links  Project slides PDF project report  Description This project was part of the course Theoretical deep learning (L&amp;rsquo;apprentissage par réseaux de neurones profonds, taught in French) by Stéphane Mallat at Collège de France.
This course was composed of theoretical lectures and a machine learning challenge.
I worked on an intent prediction problem for drug-related question, proposed by the healthcare startup Posos. The goal was to classify real user questions into one of 52 classes representing the type of drug-related information they are looking for.</description>
    </item>
    
    <item>
      <title>Data journalism extractor</title>
      <link>https://hugocisneros.com/projects/data_journalism_extractor/</link>
      <pubDate>Mon, 29 Oct 2018 12:00:00 +0000</pubDate>
      
      <guid>https://hugocisneros.com/projects/data_journalism_extractor/</guid>
      <description>Links  Github repo Online documentation Report (in French)  Data Journalism Extractor This project is an attempt to create a tool to help journalists extract and process data at scale, from multiple heterogenous data sources while leveraging powerful and complex database, information extraction and NLP tools with limited programming knowledge.
Features This software is based on Apache Flink, a stream processing framework similar to Spark written in Java and Scala.</description>
    </item>
    
    <item>
      <title>Arxiv explorer</title>
      <link>https://hugocisneros.com/projects/arxiv_explorer/</link>
      <pubDate>Fri, 26 Oct 2018 12:00:00 +0000</pubDate>
      
      <guid>https://hugocisneros.com/projects/arxiv_explorer/</guid>
      <description>Github repo  Description This project was about creating a tool similar to Arxiv Sanity with additional NLP functionalities for finding similar papers from their abstract.
I used a concept from [1], which uses earth mover&amp;rsquo;s distance metric between documents represented as normalized bag-of-words. The underlying transport cost between two words is given by their distance in a pre-trained word vector space. The app trains word vectors on all Arxiv abstracts and uses the EMD based metric to compute similarities between papers.</description>
    </item>
    
  </channel>
</rss>
