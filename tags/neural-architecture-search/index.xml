<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Neural architecture search on Hugo Cisneros</title><link>https://hugocisneros.com/tags/neural-architecture-search/</link><description>Recent content in Neural architecture search on Hugo Cisneros</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 17 Apr 2022 13:07:00 +0200</lastBuildDate><atom:link href="https://hugocisneros.com/tags/neural-architecture-search/index.xml" rel="self" type="application/rss+xml"/><item><title>Notes on: Efficient Neural Architecture Search via Parameter Sharing by Pham, H., Guan, M. Y., Zoph, B., Le, Q. V., &amp; Dean, J. (2018)</title><link>https://hugocisneros.com/notes/phamefficientneuralarchitecture2018/</link><pubDate>Sun, 17 Apr 2022 13:07:00 +0200</pubDate><guid>https://hugocisneros.com/notes/phamefficientneuralarchitecture2018/</guid><description>tags Neural architecture search source (Pham et al. 2018) Summary Like other papers, the controller is a RNN that generates each part of the architecture in sequence. The main contribution of this paper is to introduce parameter sharing in child models. For, this, it represents all possible architectures in a single DAG of operations and share weights between same operations. They explain how to design a RNN cell with their model, a convolutional network (and convolutional cell to build a CNN) and how to train.</description></item></channel></rss>