<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Diffusion models on Hugo Cisneros</title><link>https://hugocisneros.com/tags/diffusion-models/</link><description>Recent content in Diffusion models on Hugo Cisneros</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 26 Jul 2022 11:41:00 +0200</lastBuildDate><atom:link href="https://hugocisneros.com/tags/diffusion-models/index.xml" rel="self" type="application/rss+xml"/><item><title>Imagen</title><link>https://hugocisneros.com/notes/imagen/</link><pubDate>Tue, 26 Jul 2022 11:41:00 +0200</pubDate><guid>https://hugocisneros.com/notes/imagen/</guid><description>tags Transformers, Diffusion models, Computer vision, NLP, T5, CLIP paper (Saharia et al. 2022) Architecture This is based on the U-net diffusion architecture with a few extensions. T5 or CLIP or BERT is used as a frozen text encoder.
Parameter count 2B
Bibliography Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, et al.. May 23, 2022. "Photorealistic Text-to-image Diffusion Models with Deep Language Understanding"</description></item><item><title>GLIDE</title><link>https://hugocisneros.com/notes/glide/</link><pubDate>Tue, 26 Jul 2022 11:02:00 +0200</pubDate><guid>https://hugocisneros.com/notes/glide/</guid><description> tags Diffusion models, NLP, Computer vision paper (Nichol et al. 2022) Architecture This model uses joint textual and visual embedding diffusion model followed by some upsampling.
Parameter count 3.5B
Bibliography Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, Mark Chen. March 8, 2022. "GLIDE: Towards Photorealistic Image Generation and Editing with Text-guided Diffusion Models". arXiv. DOI.</description></item><item><title>DALL-E-2</title><link>https://hugocisneros.com/notes/dall_e_2/</link><pubDate>Fri, 22 Jul 2022 13:00:00 +0200</pubDate><guid>https://hugocisneros.com/notes/dall_e_2/</guid><description> tags Transformers, Diffusion models, CLIP paper (Ramesh et al. 2022) Architecture This is the successor of DALL-E, it is an encoder/decoder model that uses a combination of CLIP and Diffusion models to generate images from text. The diffusion decoder is similar to GLIDE.
Parameter count 3.5B
Bibliography Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, Mark Chen. April 12, 2022. "Hierarchical Text-conditional Image Generation with CLIP Latents". arXiv. DOI.</description></item></channel></rss>