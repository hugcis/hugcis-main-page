<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data science on Hugo Cisneros - Personal page</title>
    <link>https://hugocisneros.com/tags/data-science/</link>
    <description>Recent content in Data science on Hugo Cisneros - Personal page</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 07 Dec 2019 23:20:20 +0100</lastBuildDate><atom:link href="https://hugocisneros.com/tags/data-science/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Elegance of Optimal Transport</title>
      <link>https://hugocisneros.com/blog/2019/12/the-elegance-of-optimal-transport/</link>
      <pubDate>Sat, 07 Dec 2019 23:20:20 +0100</pubDate>
      
      <guid>https://hugocisneros.com/blog/2019/12/the-elegance-of-optimal-transport/</guid>
      <description>This post was largely inspired by Gabriel Peyré and Marco Cuturi&amp;rsquo;s excellent book about Computational Optimal Transport, which is free, (arXiv link, ref: [1]).
A simple problem? Let&amp;rsquo;s start at the beginning: what is Optimal transport (OT)?
It all begins with Gaspard Monge, reading his mémoire [2] in front of eminent scientists and engineers of the time &amp;mdash; including famous Enlightenment philosopher Condorcet &amp;mdash; at the French Académie Royale des Sciences in 1776.</description>
    </item>
    
    <item>
      <title>Data journalism extractor</title>
      <link>https://hugocisneros.com/projects/data_journalism_extractor/</link>
      <pubDate>Mon, 29 Oct 2018 12:00:00 +0000</pubDate>
      
      <guid>https://hugocisneros.com/projects/data_journalism_extractor/</guid>
      <description>Links  Github repo Online documentation  Data Journalism Extractor This project is an attempt to create a tool to help journalists extract and process data at scale, from multiple heterogenous data sources while leveraging powerful and complex database, information extraction and NLP tools with limited programming knowledge.
Features This software is based on Apache Flink, a stream processing framework similar to Spark written in Java and Scala. It executes dataflow programs, is highly scalable and integrates easily with other Big Data frameworks and tools such as Kafka, HDFS, YARN, Cassandra or ElasticSearch.</description>
    </item>
    
    <item>
      <title>Arxiv explorer</title>
      <link>https://hugocisneros.com/projects/arxiv_explorer/</link>
      <pubDate>Fri, 26 Oct 2018 12:00:00 +0000</pubDate>
      
      <guid>https://hugocisneros.com/projects/arxiv_explorer/</guid>
      <description>Github repo  Description This project was about creating a tool similar to Arxiv Sanity with additional NLP functionalities for finding similar papers from their abstract.
I used a concept from [1], which uses earth mover&amp;rsquo;s distance metric between documents represented as normalized bag-of-words. The underlying transport cost between two words is given by their distance in a pre-trained word vector space. The app trains word vectors on all Arxiv abstracts and uses the EMD based metric to compute similarities between papers.</description>
    </item>
    
  </channel>
</rss>
