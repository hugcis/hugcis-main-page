<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1">
  <base href="https://hugocisneros.com/">
  <title>Notes on: Safe Reinforcement Learning through Meta-learned Instincts by Grbic, D., & Risi, S. (2020) - Hugo Cisneros</title>
  <meta property="og:title" content="Notes on: Safe Reinforcement Learning through Meta-learned Instincts by Grbic, D., &amp; Risi, S. (2020) - Hugo Cisneros">
  <meta property="og:type" content="article">
  <meta property="og:image" content="/img/main.jpeg">
  <meta property="og:url" content="https://hugocisneros.com/notes/grbicsafereinforcementlearning2020/">
  <meta property="og:description" content="Notes about Safe Reinforcement Learning through Meta-learned Instincts by Grbic, D., &amp; Risi, S. (2020)">
  <meta name="Description" property="description" content="Notes about Safe Reinforcement Learning through Meta-learned Instincts by Grbic, D., &amp; Risi, S. (2020)">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@cisne_hug">
  <meta name="twitter:creator" content="@cisne_hug">
  <link rel="stylesheet" href="https://hugocisneros.com/main.min.css" media="all" type="text/css">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="theme-color" content="#ffffff">
  <link rel="webmention" href="https://webmention.io/hugocisneros.com/webmention">
  <link rel="pingback" href="https://webmention.io/hugocisneros.com/xmlrpc">
</head>
<body>
  <div class="wrapper">
    <header class="header">
      <nav class="nav">
        <div class="nav-main">
          <a href="https://hugocisneros.com/" class="nav-title">Hugo Cisneros</a>
        </div>
        <ul class="nav-links">
          <li>
            <a href="/blog/">Blog</a>
          </li>
          <li>
            <a href="/notes/">Notes</a>
          </li>
          <li>
            <a href="/projects/">Projects</a>
          </li>
          <li>
            <a href="/resume/">Resume</a>
          </li>
          <li>
            <a href="/contact/">Contact</a>
          </li>
        </ul>
      </nav>
    </header>
    <main class="content" role="main">
      <article class="article h-entry" itemprop="mainEntity" itemscope itemtype="http://schema.org/BlogPosting">
        <div class="single-note note-container">
          <h1 class="article-title p-name" itemprop="name">Safe Reinforcement Learning through Meta-learned Instincts by Grbic, D., & Risi, S. (2020)</h1>
          <div class="article-content e-content p-name" itemprop="articleBody">
            <dl>
              <dt>source</dt>
              <dd>
                (<a href="#grbicSafeReinforcementLearning2020"><cite itemprop="citation" itemscope itemid="key:grbicSafeReinforcementLearning2020">Grbic and Risi 2020</cite></a>)
              </dd>
              <dt>tags</dt>
              <dd>
                <a href="/notes/meta_learning/">Meta-learning</a>, <a href="/notes/reinforcement_learning/">Reinforcement learning</a>, <a href="/notes/alife_2020/">ALife 2020</a>
              </dd>
            </dl>
            <h2 id="summary">Summary</h2>
            <p>In RL an important goal is to find agents that can quickly adapt to changing environments while avoiding unsafe states. However, in deep RL, there is often noise added to explore the action space: this can lead to unsafe part of the state-action space.</p>
            <p>{{&lt; img src="/img/grbicslide.jpeg" title=“Slide from the Alife talk” width=200 alt=“Slide from the Alife talk” class=“center” &gt;}}</p>
            <p>The meta-learning setting of MAML is adapted to RL, with a policy network learning the policy in a standard way and a “instinctual network” which is fixed for a group of tasks and modulates the regular policy with its own action vector.</p>
            <p>They show results on a navigation tasks with and without hazards and with and without instincts. It seems that instincts makes convergence slower when there are no hazards in the navigation task but allows to reach better fitness in the presence of hazards.</p>
            <h2 id="bibliography">Bibliography</h2>
            <ol class="biblio-list">
              <li itemprop="citation" itemscope itemtype="https://schema.org/ScholarlyArticle" id="grbicSafeReinforcementLearning2020">
                <span itemprop="author">Grbic, Djordjeand Sebastian Risi</span>. <time datetime="2020" itemprop="datePublished">May 6, 2020</time>. "<span itemprop="name">Safe Reinforcement Learning Through Meta-learned Instincts</span>". <span itemprop="isPartOf" itemscope itemtype="https://schema.org/Periodical"><i itemprop="name">Arxiv:2005.03233 [cs]</i></span>. <a itemprop="sameAs" href="http://arxiv.org/abs/2005.03233">http://arxiv.org/abs/2005.03233</a>.
              </li>
            </ol>
          </div>
          <div class="bl-section">
            <h2>Links to this note</h2>
            <div class="backlinks">
              <ul>
                <li>
                  <a href="/notes/alife_2020/">ALife 2020</a>
                </li>
                <li>
                  <a href="/notes/grbicsafereinforcementlearning2020/">Notes on: Safe Reinforcement Learning through Meta-learned Instincts by Grbic, D., & Risi, S. (2020)</a>
                </li>
              </ul>
            </div>
          </div>
          <div class="note-footer">
            Last changed <a class="u-url" href="https://hugocisneros.com/notes/grbicsafereinforcementlearning2020/"><time itemprop="datePublished" class="dt-published" datetime="2021-03-25T09:57:00+0100">25/03/2021</time></a> | authored by <a href="https://hugocisneros.com/" rel="author" class="p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Hugo Cisneros</span></a>
          </div>
        </div>
      </article>
      <h3>Comments</h3>
      <script data-isso="//comment.hugocisneros.com/" data-isso-require-author="true" data-isso-vote="true" src="//comment.hugocisneros.com/js/embed.min.js"></script>
      <section id="isso-thread"></section><br>
      <a href="/notes#grbicsafereinforcementlearning2020"><b>← Back to Notes</b></a>
      <hr>
    </main>
    <footer class="footer">
      <ul class="footer-links">
        <li>
          <a class="rss-link" href="/blog/index.xml" type="application/rss+xml" target="_blank">Blog <img class="rss-icon" src="/img/RSS.svg" alt="RSS feed icon"></a>
        </li>
        <li>
          <a href="https://github.com/hugcis/hugo-astatine-theme">Code</a>
        </li>
        <li>© Hugo Cisneros 2022</li>
      </ul>
    </footer>
  </div>
  <link rel="stylesheet" href="/js/katex/katex.min.css">
  <script src="/js/katex/katex.min.js"></script> 
  <script src="/js/katex/contrib/auto-render.min.js"></script> 
  <script>

    document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        delimiters: [
            {left: "\\[", right: "\\]", display: true},
            {left: "$$", right: "$$", display: true},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "$", right: "$", display: false},
            {left: "\\(", right: "\\)", display: false},
        ]
  })
    });
  </script>
</body>
</html>
