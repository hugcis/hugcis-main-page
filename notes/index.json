[
    
    
    
    {"body":" tags NLP  Definition Word vectors are abstract representation of words embedded in a dense space.\nThey are closely related to Language modeling, since the implicit representation a language model builds for prediction can often be used as a word (or sentence) vector.\nUsage Word vectors can encode interesting information, such as semantic similarity between words. This can help for text classification tasks as it may be easier to learn a mapping between this intermediate space and a result rather than between the space of one-hot encoded words/sentences.\n \u0026lt;~/Papers/library.json\u0026gt;\n","title":"Word vectors","url":"https://hugocisneros.com/notes/word_vectors/"}
    
    , 
    
    {"body":" tags Machine learning  Catastrophic forgetting is the name given to a common problem of machine learning models: when training on some new data from a new distribution (a new \u0026ldquo;task\u0026rdquo;), many models forget what they learned from the first task.\nThis isn\u0026rsquo;t surprising since models are following a loss function that is often applied solely on the task at hand, and not constraining the model to retain past information.\nThe field of continual learning is an effort to counteract catastrophic forgetting in machine learning.\nCatastrophic forgetting in neural networks This phenomenon is common in neural networks. It was strongly identified in  and investigated in \u0026lt;robinsCatastrophicForgettingNeural1993,goodfellowEmpiricalInvestigationCatastrophic2015\u0026gt;.\n\u0026lt;~/Papers/library.json\u0026gt;\n","title":"Catastrophic forgetting","url":"https://hugocisneros.com/notes/catastrophic_forgetting/"}
    
    , 
    
    {"body":" tags Cellular automata resources    It is one of the most famous Cellular automata rule, invented as a game by mathematician John Conway.\nLearn the game of life with a neural network This paper investigates how hard it is for neural networks to approximate the Game of Life rule .\n\u0026lt;~/Papers/library.json\u0026gt;\n","title":"Conway's Game of Life","url":"https://hugocisneros.com/notes/conway_s_game_of_life/"}
    
    , 
    
    {"body":" tags Machine learning  Continual learning is a type of supervised learning where there is no \u0026ldquo;testing phase\u0026rdquo; associated to a decision process. Instead, training samples keep being processed by the algorithm which has to simultaneously make predictions and keep learning.\nThis is challenging for a fixed neural network architecture since it has a fixed capacity and is bound to either forget things or be unable to learn anything new.\nA definition from the survey (De Lange et al. 2020):\n The General Continual Learning setting considers an infinite stream of training data where at each time step, the system receives a (number of) new sample(s) drawn non i.i.d from a current distribution that could itself experience sudden of gradual changes.\n Examples of continual learning systems  Never Ending Language Learner (NELL) (Carlson, Betteridge, and Kisiel 2010)  Benchmarks Computer vision based benchmarks   Split MNIST: the MNIST dataset is split into 5 2-classes tasks.\n  Split CIFAR10: the CIFAR10 dataset is split into 5 2-classes tasks.\n  Split mini-ImageNet: a mini ImageNet (100 classes) task split into 20 5-classes tasks.\n  Continual Transfer Learning Benchmark: A benchmark from Facebook AI, built from 7 computer vision datasets: MNIST, CIFAR10, CIFAR100, DTD, SVHN, Rainbow-MNIST, Fashion MNIST. The tasks are all 5-classes or 10-classes classification tasks. Some example task sequence constructions from (Veniat, Denoyer, and Ranzato 2021):\n The last task of \\(S_out\\) consists of a shuffling of the output labels of the first task. The last task of \\(S_in\\) is the same as its first task except that MNIST images have a different background color. \\(S_long\\) has 100 tasks, and it is constructed by first sampling a dataset, then 5 classes at random, and finally the amount of training data from a distribution that favors small tasks by the end of the learning experience.\n   Permuted MNIST: here for each different task the pixels of the MNIST digits are permuted, generating a new task of equal difficulty as the original one but different solution. This task is not suitable if the model has some spatial prior (like a CNN). Used first in (Kirkpatrick et al. 2017).\n  Rotated MNIST: each task contains digits rotated by a fixed angle between 0 and 180 degrees.\n  Bibliography Carlson, Andrew, Justin Betteridge, and Bryan Kisiel. 2010. \"Toward an Architecture for Never-Ending Language Learning.\". In Proceedings of the Conference on Artificial Intelligence (AAAI) (2010), 1306–13. DOI. De Lange, Matthias, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Gregory Slabaugh, and Tinne Tuytelaars. May 26, 2020. \u0026ldquo;A Continual Learning Survey: Defying Forgetting in Classification Tasks\u0026rdquo;. arXiv:1909.08383 [Cs, Stat]. http://arxiv.org/abs/1909.08383.\nKirkpatrick, James, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, et al.. January 25, 2017. \u0026ldquo;Overcoming Catastrophic Forgetting in Neural Networks\u0026rdquo;. arXiv:1612.00796 [Cs, Stat]. http://arxiv.org/abs/1612.00796.\nVeniat, Tom, Ludovic Denoyer, and Marc’Aurelio Ranzato. February 12, 2021. \u0026ldquo;Efficient Continual Learning with Modular Networks and Task-Driven Priors\u0026rdquo;. arXiv:2012.12631 [Cs]. http://arxiv.org/abs/2012.12631.\n","title":"Continual learning","url":"https://hugocisneros.com/notes/continual_learning/"}
    
    , 
    
    {"body":" tags Neural networks resources (Bishop 1994)  Variational autoencoders (VAEs) are a type of generative Autoencoders.\nThey use a Bayesian latent encoding for the input dataset.\nVAEs vs. GANs VAEs have fallen out of fashion when GANs became popular, because they were able to get visually interesting results more easily. However, some works a few years later seem to show that they have similar potential (Vahdat and Kautz 2020).\nBibliography Vahdat, Arash, and Jan Kautz. July 8, 2020. \"NVAE: A Deep Hierarchical Variational Autoencoder\". arXiv:2007.03898 [Cs, Stat]. http://arxiv.org/abs/2007.03898. Bishop, Christopher M.. 1994. \u0026ldquo;Mixture Density Networks\u0026rdquo;. Aston University.\n","title":"Variational autoencoders","url":"https://hugocisneros.com/notes/variational_autoencoders/"}
    
    , 
    
    {"body":"Compression with Neural networks Compression can be done with the help of neural networks as estimators of the sequence\u0026rsquo;s next character probability (Schmidhuber and Heil 1996).\nCompression as a measure of Artificial Intelligence Mahoney argues in (Mahoney 1999) that being able to compress information amounts to being able to predict optimally the distribution of an inputs natural language corpus. A good compression algorithm \u0026ldquo;learns\u0026rdquo; features of the language to make better predictions. This is maybe one of the original motivation for language modeling, and can be used as an artificial intelligence test.\nCompression as a measure of Complexity Compression algorithms have long been used as a way of measuring complexity of data.\nBibliography Schmidhuber, J., and S. Heil. January 1996. \"Sequential Neural Text Compression\". IEEE Transactions on Neural Networks 7 (1):142–46. DOI. Mahoney, Matthew V. 1999. \u0026ldquo;Text Compression as a Test for Artificial Intelligence\u0026rdquo;. In Proceedings of AAAI-1999, 3.\n","title":"Compression","url":"https://hugocisneros.com/notes/compression/"}
    
    , 
    
    {"body":" tags Compression, Graphs  (Bouritsas et al. 2021)\nBibliography Bouritsas, Giorgos, Andreas Loukas, Nikolaos Karalias, and Michael M. Bronstein. July 5, 2021. \"Partition and Code: Learning How to Compress Graphs\". arXiv:2107.01952 [Cs, Math, Stat]. http://arxiv.org/abs/2107.01952.","title":"Graph compression","url":"https://hugocisneros.com/notes/graph_compression/"}
    
    , 
    
    {"body":" tags Neural networks, Dynamical systems  Neural networks can be seen as dynamical systems in different contexts.\nRecurrent networks With Recurrent neural networks, the continuous dynamical system analogy is very striking. These networks evolve progressively in time by updating an internal state with a fixed algorithm. Usually the state dynamics are not studied because the recurrent networks is designed to complete some fixed task.\nThe notion of attractor can be defined for such networks, making them related to the notion of attractor networks.\nTraining as a dynamical system For a neural network with parameters \\(\\theta\\) trained with example pairs \\((x_i, y_i)\\), the parameters trajectory \\(\\theta_0, \\theta_1, \\ldots, \\theta_n\\) until convergence can be interpreted as the evolution of a dynamical system.\nOne may study the various attractors of that dynamical system and how the training examples affect them.\nThis can be thought of as a sort of learning in dynamical systems.\nResidual networks as dynamical systems Residual neural networks may be seen as discretized dynamical systems. In the limit of small step sizes, it becomes a continuous resnet, we get Neural ordinary differential equations (Chen et al. 2019).\nBibliography Chen, Ricky T. Q., Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. December 13, 2019. \"Neural Ordinary Differential Equations\". arXiv:1806.07366 [Cs, Stat]. http://arxiv.org/abs/1806.07366.","title":"Neural networks as dynamical systems","url":"https://hugocisneros.com/notes/neural_networks_as_dynamical_systems/"}
    
    , 
    
    {"body":" tags Neural networks resources (He et al. 2016)  Residual neural networks are neural networks with skip-connections (or shortcuts, residual connections) that will bypass some of the networks operations in depth.\nHighway networks (Srivastava, Greff, and Schmidhuber 2015)\nDenseNets (Huang and Liu, n.d.)\nBibliography He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. June 2016. \"Deep Residual Learning for Image Recognition\". In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 770–78. Las Vegas, NV, USA: IEEE. DOI. Huang, Gao, and Zhuang Liu. n.d. \u0026ldquo;Densely Connected Convolutional Networks\u0026rdquo;, 9.\nSrivastava, Rupesh Kumar, Klaus Greff, and Jürgen Schmidhuber. November 3, 2015. \u0026ldquo;Highway Networks\u0026rdquo;. arXiv:1505.00387 [Cs]. http://arxiv.org/abs/1505.00387.\n","title":"Residual neural networks","url":"https://hugocisneros.com/notes/residual_networks/"}
    
    , 
    
    {"body":" tags Machine learning, Dynamical systems resources (Weinan 2017)  Bibliography Weinan, E. March 2017. \"A Proposal on Machine Learning via Dynamical Systems\". Communications in Mathematics and Statistics 5 (1):1–11. DOI.","title":"Learning in dynamical systems","url":"https://hugocisneros.com/notes/learning_in_dynamical_systems/"}
    
    , 
    
    {"body":" tags Compression, Entropy coding  ","title":"Huffman coding","url":"https://hugocisneros.com/notes/huffman_coding/"}
    
    , 
    
    {"body":" tags Mathematics  Definition The min tropical semiring is the semiring \\((\\mathbb{R} \\cup \\{ +\\infty \\}, \\oplus, \\otimes )\\) with the operations:\n \\(x \\oplus y = \\min(x, y)\\) \\(x \\otimes y = x + y\\)  The unit for \\(\\oplus\\) is \\(+\\infty\\) and the unit for \\(\\otimes\\) is \\(0\\). The max tropical semiring is defined similarly by replacing \\(\\min\\) with \\(\\max\\).\nRelation with shortest path algorithms There is an interesting connection between the min tropical semiring and Dijkstra\u0026rsquo;s algorithm.\nLet \\(G\\) the weighted graph representing a shortest path problem and \\(A\\) its adjacency matrix (the elements of \\(A\\) are the weight between the nodes, or \\(+\\infty\\) if there is no path between two node).\nFor \\(k \\in \\mathbb{N}\\), coefficient \\(i, j\\) of the matrix \\(A^k\\) contains the smallest cost of all path from node \\(i\\) to node \\(j\\) with \\(k\\) edges. Moreover, the vector \\((+\\infty, +\\infty, \u0026hellip;, 0, \u0026hellip;, +\\infty)A^n\\) with a \\(0\\) in position \\(p\\) is the cost from any nodes to the target node \\(p\\).\nSee these slides by Nicolas Delanoue for some more details.\n","title":"Tropical semiring","url":"https://hugocisneros.com/notes/tropical_semiring/"}
    
    , 
    
    {"body":" tags Compression, Entropy coding resources (Witten, Neal, and Cleary 1987)  Bibliography Witten, Ian H., Radford M. Neal, and John G. Cleary. 1987. \"Arithmetic Coding for Data Compression\". Communications of the ACM 30 (6). ACM New York, NY, USA:520–40.","title":"Arithmetic coding","url":"https://hugocisneros.com/notes/arithmetic_coding/"}
    
    , 
    
    {"body":" tags Noise resources (Wong and Wong 2017)  Bibliography Wong, Kin-Ming, and Tien-Tsin Wong. June 1, 2017. \"Blue Noise Sampling Using an N-Body Simulation-Based Method\". The Visual Computer 33 (6):823–32. DOI.","title":"Blue noise","url":"https://hugocisneros.com/notes/blue_noise/"}
    
    , 
    
    {"body":" tags Compression, Entropy  ","title":"Entropy coding","url":"https://hugocisneros.com/notes/entropy_coding/"}
    
    , 
    
    {"body":" tags Dynamical systems  The Poincaré recurrence time for a finite dynamical system is the maximal theoretical time after which the system will return to its initial state and the trajectory will repeat.\nIn the case of a cellular automaton on a grid of size \\(n\\) with \\(k\\) possible states per cell, the recurrence time is \\(t_P = k^n\\).\n","title":"Poincaré recurrence time","url":"https://hugocisneros.com/notes/poincare_recurrence_time/"}
    
    , 
    
    {"body":" source (Adams et al. 2017) tags Open-ended Evolution, Cellular automata  Summary This paper defines two properties for dynamical systems which are claimed to be related to open-ended evolution: Unbounded evolution (UE) and Innovation (INN). The combination of these two properties makes a system open-ended according to this paper\u0026rsquo;s definition For such properties to be possible, a system has to be decomposed into two entities that interact with each other:\n an organism, an environment.  For the purpose of measuring \u0026ldquo;open-endedness\u0026rdquo;, the environment is ignored and the author wish to see if the organism can do more than what it could do if it was an isolated system.\n Figure 1: Figure 1 from the paper. Different systems might exhibit INN or UE. To go past its intrinsic Poincare recurrence time, a system needs to interact with an environment.\n  Unbounded evolution A system decomposed into an organism \\(o\\) and an environment \\(e\\) is said to exhibit UE if there exist a (state or rule) trajectory longer than the Poincaré recurrence time of the equivalent isolated organism.\nInnovation To exhibit innovation, a system \\(o + e\\) must have a trajectory not contained within the possible trajectories of an isolated version of \\(o\\).\nExperiments with CA extensions The authors experiment with a few extensions of the cellular automaton model to incorporate these organism/environment dynamics.\nComments Bibliography Adams, Alyssa, Hector Zenil, Paul C. W. Davies, and Sara Imari Walker. April 2017. \"Formal Definitions of Unbounded Evolution and Innovation Reveal Universal Mechanisms for Open-Ended Evolution in Dynamical Systems\". Scientific Reports 7 (1):997. DOI.","title":"Formal Definitions of Unbounded Evolution and Innovation Reveal Universal Mechanisms for...","url":"https://hugocisneros.com/notes/adamsformaldefinitionsunbounded2017/"}
    
    , 
    
    {"body":" tags Cryptography resources Monero  ","title":"Monero","url":"https://hugocisneros.com/notes/monero/"}
    
    , 
    
    {"body":" tags Cryptography  A ring signature is a protocol that allows a single entity from a group or public-private key pairs to sign a message in such a way that anyone can check the signature was indeed made by someone from that group but it is impossible to tell who exactly. It should also be very hard to create a fake signature without knowing any of the private keys from the group.\nThe cryptocurrency Monero uses a version of the ring signature protocol to make it very hard to know who was involved in some transaction.\n","title":"Ring signatures","url":"https://hugocisneros.com/notes/ring_signatures/"}
    
    , 
    
    {"body":" tags Statistics  A set of numbers satisfies Benford\u0026rsquo;s law if the leading digits of these numbers occur with a probability logarithmically decreasing with the digit. More precisely, for \\(d \\in \\{1, \\ldots, 9\\}\\),\n\\[ P(d) = \\log_10 \\left(1 + \\frac{1}{d} \\right) \\]\n","title":"Benford's law","url":"https://hugocisneros.com/notes/benford_s_law/"}
    
    , 
    
    {"body":" tags Cellular automata, Recurrent neural networks  Since cellular automata are a kind of dynamical system, they may also be seen as a type of recurrent neural network. They can even be seen as a recurrent-convolutional network because each of the \u0026ldquo;hidden neurons\u0026rdquo; update depends only on the neighboring neurons and the update rule is shared across the whole hidden state.\n","title":"Cellular automata as recurrent neural networks","url":"https://hugocisneros.com/notes/cellular_automata_as_recurrent_neural_networks/"}
    
    , 
    
    {"body":" tags Philosophy, Physics  Reductionism is a philosophy according to which the laws of physics are relatively simple and could be expressed concisely. If we were to understand and model all those laws we could explain any given phenomenon by breaking it down into its smaller parts until we just need to apply these simple laws.\nWith the current state of physics, it seems we are close to understanding many of these fundamental laws (although major shortcomings remain in the theory). Therefore, according to reductionism we should be close to understanding everything?\nHowever as Murray Gell-Mann put it:\n Reductionism is correct, but incomplete.\n As a matter of fact, it was noted by Anderson (Anderson 1972) and many others (Gu et al. 2009) that phenomena at different scales exhibit properties that couldn\u0026rsquo;t be reduced to lower scales, even though they are governed by the same exact laws. We need new models to describe these larger scale phenomena .\nThis fact was observed in several complex systems including cellular automata (Cisneros, Sivic, and Mikolov 2020).\nBibliography Cisneros, Hugo, Josef Sivic, and Tomas Mikolov. July 1, 2020. \"Visualizing Computation in Large-Scale Cellular Automata\". Artificial Life Conference Proceedings 32 (July). MIT Press:239–47. DOI. Gu, Mile, Christian Weedbrook, Alvaro Perales, and Michael A. Nielsen. May 2009. \u0026ldquo;More Really Is Different\u0026rdquo;. Physica D: Nonlinear Phenomena 238 (9-10):835–39. DOI.\nAnderson, P. W.. August 4, 1972. \u0026ldquo;More Is Different\u0026rdquo;. Science 177 (4047). American Association for the Advancement of Science:393–96. DOI.\n","title":"Reductionism","url":"https://hugocisneros.com/notes/reductionism/"}
    
    , 
    
    {"body":" tags Emergence, Chaos, Artificial Intelligence resources Wikipedia, (Von Neumann and Burks 1966; Wolfram 2002)  Definition A cellular automaton is a computational model defined with respect to a regular grid of individual elements (called cells). Each of those cells can be in one of a finite number of states \u0026mdash; alive or dead, \\(\\{1, 2, 3\\}\\), etc.\nA cellular automaton\u0026rsquo;s evolution is simulated in discrete timesteps. At each new timestep, cells are updated according to a local evolution rule. The rule is a table or function mapping every possible state of a cell and their local neighborhoods to a new state. It follows that a CA is a kind of dynamical system.\nThere are multiple ways to define the topology of the grid, rules, local neighborhoods and simulation steps. Some well known types of automata are listed below\nElementary cellular automata Cellular automata on 1D grids, with two states and neighborhood radius 1 (middle cell + one cell on each side) are called Elementary cellular automata \u0026mdash; or ECA.\nReversible cellular automata Reversible cellular automata are CA rules with one and only one image and pre-image. Each step of the evolution is reversible.\nCyclic cellular automata Cellular automata and Reaction-diffusion systems I just realized that cellular automata and reaction-diffusion systems are strongly related. This might be a well known fact but it seemed particularly striking when looking at the following image from (Manukyan et al. 2017) it seems clear that there is a continuum between the two models.\n Cellular automata in Image processing Papers about using cellular automata in image processing (Selvapeter and 2009; Wongthanavasu and Ponkaew 2013)\nSome cellular automata have a characteristic \u0026ldquo;blob-preserving\u0026rdquo; behavior where parts of the space get organized in large blobs. This behavior is very similar to an application of local median. See this twitter link for an animated example.\nCoarse-graining CA I am very attracted to this idea of coarse graining CAs. This is reminiscent of physical systems where the inner working of a system are mostly opaque to an observer and we only see a complex macro-behavior. In the case of CAs this might be the key to overcoming this problem of seemingly impossible increase of complexity beyond a certain point if we keep looking at individual cells. This also allows an external observer to understand a complex behavior happening in billions of cells visually. It can be done with Autoencoders.\nCA as regular languages CAs can be studied with regular languages.\nEvolution and CAs Why would things evolve in a CA? I was running interesting CAs for several 100s of thousands of steps recently and realized that I did not really know what I would be expecting to happen in one of those without any input from outside. Could it be that, by just pure luck, some things start to evolve in it? That some species or life-like forms emerge?\nIf this is even possible, what are the odds of this happening? Was it how it worked in our case (earth)? Did just random particle interactions in a large soup gave rise to a complete miracle? So far from my experiment I have seen complex previously unseen structures emerge during an automaton evolution, but this has never gone farther than just a few big structures appearing and not staying this way. I believe it is a bias to think that those structures would have been suited to keep evolving because their brittleness did not let them survive. Therefore the (unpractical) way forward might be to let those things run and see what happens, where the \u0026ldquo;surviving\u0026rdquo; would be the ones left after all this.\nI\u0026rsquo;m wondering whether some kind of external input to those small \u0026ldquo;universe\u0026rdquo; could help give rise to more complex behavior. Because I am starting to think that even with the most efficient system possible, the probability of seeing a complex structure appearing decreases somewhat exponentially with the complexity of the structure (or according to a power law).\nObviously I have no idea about all this and this is just based on speculation. But I\u0026rsquo;ve yet to see reasonable evidence that we can run a CA for a large number of time steps without any kind of input and see this increase in complexity happen by itself. Maybe the key would be to help it? But is it even possible?\nPlaying god with cellular automata I believe an exciting part of working on spontaneous emergence, artificial evolution, and cellular automata is the fact that it really feels like playing with a microverse. Some relevant recent pop-cultures examples involving this idea include:\n Rick and morty Season 2 Episode 6: The Ricks Must Be Crazy Love, Death \u0026amp; Robot Episode 16: Ice Age  Each one of those cellular automata can be seen as a universe, with its own laws of physics (update rule) and initial big bang-like configuration (the initial state). Most combinations of the laws of physics are not stable and create completely disordered systems, but some rare configurations give rise to large structures sifting through space and exhibit highly non-trivial macro behavior (2-3 cells wide up to several 100s of cells-wide). Many of these structures interact in different ways, some create siblings and children structures while other get destroyed very quickly.\nThis transition from randomness to order could be seen in the case of our universe as the 4 physical forces pulling together particles into bigger and bigger structures which form a large system with a lot of emptiness and some localized structures. In this analogy, our planet and even our galaxy are just a microscopic ripple on of those giant structures, but what if we could make this kind of ripple happen in a much smaller universe, with much simpler laws? This is more or less what we are trying to achieve with cellular automata.\nObviously starting from scratch is hard, and it might not be necessary to let this microverse evolve in a closed way without interacting with it somehow.\nThis point of view is related to The Simulated reality hypothesis and Zuse\u0026rsquo;s thesis, and is an interesting argument for the universe being a computer simulation \u0026mdash; and even a CA.\nBibliography Manukyan, Liana, Sophie A. Montandon, Anamarija Fofonjka, Stanislav Smirnov, and Michel C. Milinkovitch. April 2017. \"A Living Mesoscopic Cellular Automaton Made of Skin Scales\". Nature 544 (7649):173–79. DOI. Selvapeter, P. Jebaraj, and . 2009. \u0026ldquo;Cellular Automata for Image Noise Filtering\u0026rdquo;. In 2009 World Congress on Nature \u0026amp; Biologically Inspired Computing (NaBIC), 193–97. Coimbatore, India: IEEE. DOI.\nVon Neumann, John, and Arthur W. Burks. 1966. \u0026ldquo;Theory of Self-Reproducing Automata\u0026rdquo;. IEEE Transactions on Neural Networks 5 (1):3–14. https://cba.mit.edu/events/03.11.ASE/docs/VonNeumann.pdf.\nWongthanavasu, Sartra, and Jetsada Ponkaew. May 8, 2013. \u0026ldquo;Cellular Automata for Pattern Recognition\u0026rdquo;. In Emerging Applications of Cellular Automata, edited by Alejandro Salcido. InTech. DOI.\nWolfram, Stephen. 2002. A New Kind of Science. Champaign, IL: Wolfram Media. https://www.wolframscience.com/nks/.\n","title":"Cellular automata","url":"https://hugocisneros.com/notes/cellular_automata/"}
    
    , 
    
    {"body":" tags Transformers source (Xiong et al. 2021)  Summary This paper describes a way of applying the Nyström method for approximating matrix multiplication to transformers. More precisely, the approximation is used in the self-attention mechanism\u0026rsquo;s softmax calculation.\nThis approximation adresses one of the biggest downside of attention: its computational complexity. The authors claim that their method reduces it from \\(O(n^2)\\) to \\(O(n)\\).\nThe goal of the method is to efficiently approximate the matrix\n\\[\\begin{align*} S = \\text{softmax}\\left(\\dfrac{QK^T}{\\sqrt{d_q}}\\right) \\end{align*}\\]\nWhy the standard Nyström method won\u0026rsquo;t work To apply matrix approximation to this problem, one would start by writing \\(S\\) as\n\\[ S = \\begin{bmatrix} A_S \u0026amp; B_S \\newline F_S \u0026amp; C_S \\end{bmatrix}\\]\nThe full matrix \\(S\\) can be approximated using only \\(m\\) columns and \\(m\\) rows\n\\[ \\hat{S} = \\begin{bmatrix} A_S \\newline F_S \\end{bmatrix} A^+ \\begin{bmatrix} A_S \u0026amp; B_S \\end{bmatrix} \\]\nLinearized self-attention via the Nyström method Comments Bibliography Xiong, Yunyang, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, and Vikas Singh. February 7, 2021. \"Nystr\\\\“Omformer: A Nystr\\\\“Om-Based Algorithm for Approximating Self-Attention\". arXiv:2102.03902 [Cs]. http://arxiv.org/abs/2102.03902.","title":"Nyströmformer: A Nyström-Based Algorithm for Approximating Self-Attention by Xiong, Y.,...","url":"https://hugocisneros.com/notes/xiongnystromformernystr2021/"}
    
    , 
    
    {"body":" tags Neural networks, Graphs  Basic properties To operate on graphs, a neural network must be invariant to isomorphism of these graphs. This translates to permutation invariance for the nodes of a graph.\n\\[ f(\\mathbf{PX}) = f(\\mathbf{X}) \\]\nWhere \\(\\mathbf{P}\\) is a permutation matrix. For simple sets, this amounts to performing node-wise transformations and use a permutation invariant aggregator (sum/max/avg/\u0026hellip;). This was done in (Zaheer et al. 2018).\n\\[ f(\\mathbf{X}) = \\phi\\left( \\bigoplus_i \\psi(\\mathbf{x}_i) \\right) \\]\nIn the case of GNNs, the local neighborhood of a node can also be defined, and therefore the neural network can be written:\n\\[ f(\\mathbf{X}, \\mathbf{A}) = \\begin{bmatrix} \u0026mdash; g(\\mathbf{x}_1 , \\mathbf{X}_{\\mathcal{N}_1} ) \u0026mdash; \\newline \u0026mdash; g(\\mathbf{x}_2 , \\mathbf{X}_{\\mathcal{N}_2} ) \u0026mdash; \\newline \\vdots\\newline \u0026mdash; g(\\mathbf{x}_n , \\mathbf{X}_{\\mathcal{N}_n} ) \u0026mdash; \\end{bmatrix} \\]\nwhere \\(\\mathbf{A}\\) is the adjacency matrix of the graph. The function \\(g\\) also need to be permutation invariant to ensure the permutation invariance of \\(f\\).\nThe various ways of defining \\(g\\) give rise to three main flavours of GNNs:\n Graph convolutional networks Attention graph networks Message-passing graph networks  Bibliography Zaheer, Manzil, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan Salakhutdinov, and Alexander Smola. April 14, 2018. \"Deep Sets\". arXiv:1703.06114 [Cs, Stat]. http://arxiv.org/abs/1703.06114.","title":"Graph neural networks","url":"https://hugocisneros.com/notes/graph_neural_networks/"}
    
    , 
    
    {"body":" tags Optimization, Algorithm resources Slides by Christian S. Perone  Fixed learning rate The simplest way to apply the gradient descent algorithm on a function \\(g\\) convex and $L-$smooth on \\(\\mathbb{R}^d\\) is to use the parameter update:\n\\[ \\theta_t = \\theta_{t-1} - \\gamma g'(\\theta_{t-1}) \\]\nThis is based on the standard first-order approximation of the function \\(g\\). It can be very sensitive to the learning rate and suffer from pathological curvature.\nMomentum Momentum has been introduced in the gradient descent algorithm to dampen oscillations in the pathological cases and accelerating descent. Trajectories are less sensitive to changes in the loss landscape.\n\\[ \\begin{align} V_{t + 1} = \\beta V_t + g'(\\theta_{t})\\newline \\theta_{t + 1} = \\theta_t - \\gamma V_{t + 1} \\end{align}\\]\nLine search Another common way to apply the gradient descent algorithm with non fixed learning rate is to use line search at each step. This corresponds to searching for the best \\(\\gamma\\) to use in \\(\\theta_{} + \\gamma \\Delta\\theta\\) (in gradient descent, \\(\\Delta\\theta = - g'(\\theta)\\)).\nExact line search For exact line search, we take \\(\\gamma = \\arg\\min_{s\\geq 0} g(\\theta + s \\Delta \\theta)\\). This method is used when the cost of minimizing the function above is low compared to computing the search direction \\(\\Delta\\theta\\).\nBacktracking line search This is an algorithm for inexact line search. It depends on two parameters \\(0 \u0026lt; \\alpha \u0026lt; 0.5\\) and \\(0 \u0026lt; \\beta \u0026lt; 1\\). It is composed of one step which is run until the following condition is verified\n\\[ g(\\theta + t \\Delta \\theta)\u0026gt; g(\\theta) + \\alpha t \\nabla g(\\theta)^T \\Delta\\theta \\]\nAt each step, \\(t \\leftarrow \\beta t\\), \\(t\\) is initialized to 1.\n","title":"Gradient descent","url":"https://hugocisneros.com/notes/gradient_descent/"}
    
    , 
    
    {"body":" tags Information theory, Life source (Krakauer et al. 2020)  Summary This paper introduces an information theoretic definition of individuality for complex systems.\nIn a few words, the authors idea of individuality is based on the amount of information transmitted through time.\n If the information transmitted forward in time is close to maximal, we take that as evidence for individuality.\n Formally, a system \\(\\mathcal{S}\\) is considered in interaction with an environment \\(\\mathcal{E}\\). Two channels \\(\\phi: \\mathcal{E} \\times \\mathcal{S}\\rightarrow\\mathcal{S}\\) and \\(\\psi : \\mathcal{S} \\times \\mathcal{E} \\rightarrow \\mathcal{E}\\) corresponds to the transition probabilities for \\(\\mathcal{S}\\) and \\(\\mathcal{E}\\) respectively (\\(\\phi(e, s; s')\\) is the probability to be in state \\(s'\\) at the next time step for current states \\(s\\) and \\(e\\) for \\(\\mathcal{S}\\) and \\(\\mathcal{E}\\)).\nThe predictability of the next state of the system is characterized in terms of entropy and mutual information by\n\\[ \\begin{align*} I(S_n, E_n ; S_{n+1} ) \u0026amp;= I(S_{n+1} ; S_n) + I(S_{n+1} ; E_n | S_n)\\newline \u0026amp; = I(S_{n+1} ; E_n) + I(S_{n+1} ; S_n|E_n) \\end{align*} \\]\nDepending on which quantity dominates, different types of individuality can be defined\n Colonial Individuality: \\(A = I(S_{n+1} ; S_n|E_n)\\)   Organisms are well adapted when they share through adaptation or learning significant information with the environment in which they live. In addition, they contain a large amount of private information required for effective function. By maximizing this measure, we are able to identify complex organisms in their environments.\n  Organismal Individuality: \\(A^* = I(S_{n+1} ; S_n)\\)   Many organisms such as microbes share only a small amount of information with the environment in which hey live. They contain regulatory mechanisms that allow for adaptation through ongoing interaction between their biotic and abiotic environment. By maximizing this measure, we are able to identify “environmentally regulated aggregations,” which we call “colonial individuals.”\n  Environmental Determined Individuality: \\(nC = I(S_{n+1} ; E_n|S_n)\\)   This measure quantifies the degree of environmental determinism on the temporal evolution of an individual. When this measure is minimized an individual becomes completely insensitive to the environment — and hence is neither in the organismal or colonial form — and not in any real sense adaptive. It represents the persistence of an environmental memory capable through interaction with the system of generating structure, such as temperature gradients in a fluid that produce vortices.\n Another additional measure is defined, quantifying contribution of different terms in case of hybrid that have multiple components to their \u0026ldquo;individuality\u0026rdquo;. This is called Environmental Coding,\n\\[ NTIC=SI(S_{n+1};S_n, E_n)−CI(S_{n+1};S_n, E_n) \\]\n The intuition behind this measure is to quantify the difference between a colonial and organismal measure of individuality. The difference is captured by the difference between shared information (e.g., adaptive information) and the interaction of individual and environment (e.g., regulatory information). One way to think about this is how much information can be encoded about the environment in the system innately (e.g., inherited information) versus how much information needs to be encoded through ongoing interaction. When the measure is large nature dominates nurture. As the measure declines, nurture begins to dominate nature.\n Comments This looks like a great way to study emergence of life and evolutionary processes in complex systems. I gives theoretical grounding into the fact that many complex systems look as if they behaved as individuals.\nHowever, the main drawback seems to be in accurately computing mutual information for each of the terms. Also, the definition of the system \\(\\mathcal{S}\\) and environment \\(\\mathcal{E}\\) can be problematic when dealing with systems in which the distinction isn\u0026rsquo;t clear (such as Cellular automata).\nBibliography Krakauer, David, Nils Bertschinger, Eckehard Olbrich, Jessica C. Flack, and Nihat Ay. June 1, 2020. \"The Information Theory of Individuality\". Theory in Biosciences 139 (2):209–23. DOI.","title":"The information theory of individuality by Krakauer, D., Bertschinger, N., Olbrich, E.,...","url":"https://hugocisneros.com/notes/krakauerinformationtheoryindividuality2020/"}
    
    , 
    
    {"body":" tags Neural networks  Hopfield networks are a kind of recurrent neural network with binary threshold nodes.\nDefinition Nodes have indexes \\(i \\in \\{1, \\cdots, n\\}\\) and are in state \\(s_i \\in \\{-1, 1\\}\\). Nodes have connections between them, characterized by a weight \\(w_{ij}\\). Each node also has an associated threshold \\(\\theta_i\\) such that\n\\[\\begin{equation*} s_i \\leftarrow \\begin{cases} +1 \u0026amp; \\text{if}\\ \\sum_j w_{ij} s_j \\geq \\theta_i, \\newline -1 \u0026amp; \\text{otherwise}. \\end{cases} \\end{equation*}\\]\nEnergy A Hopfield network has an associated energy value \\[ E = - \\frac{1}{2} \\sum_{i,j} w_{ij} s_i s_j + \\sum_i \\theta_i s_i \\] which makes it part of the Ising models.\nHopfield networks and attention See Hopfield Networks is All You Need (Ramsauer et al. 2020)\nBibliography Ramsauer, Hubert, Bernhard Schäfl, Johannes Lehner, Philipp Seidl, Michael Widrich, Lukas Gruber, Markus Holzleitner, et al.. July 16, 2020. \"Hopfield Networks Is All You Need\". arXiv:2008.02217 [Cs, Stat]. http://arxiv.org/abs/2008.02217.","title":"Hopfield Networks","url":"https://hugocisneros.com/notes/hopfield_networks/"}
    
    , 
    
    {"body":" tags Transformers, RNN source (Katharopoulos et al. 2020)  Summary Transformers have traditionally been described as different models from RNNs. This is because instead of processing the sequence one token at a time, Transformers use attention to process all elements simultaneously.\nThe paper introduces an interesting new formulation, replacing the softmax attention with a feature map-based dot product.\nThis new formulation yields better time and memory complexity as well as a model that is casual and autoregressive (similar to RNNs).\nA Transformer applied on sequence \\(x\\) is presented as a composition of multiple Transformer layers \\(T_l\\), with\n\\[ T_l(x) = f_l(A_l(x) + x) \\]\nFunction \\(f_l\\) is applied to each component independently, while attention \\(A_l\\) is applied to the whole input sequence.\nSoftmax self-attention at layer \\(l\\) with queries, keys and values matrices is written\n\\[A_l(x) = V' = \\text{softmax}\\left( \\dfrac{QK^{T}}{\\sqrt{D}} \\right) V.\\]\nThe equation above can be generalized to any similarity function \\(\\text{sim}\\), and if \\(V'_i\\) designates the $i$-th row of \\(V'\\),\n\\[ V'_i = \\dfrac{\\sum_{j = 1}^N \\text{sim}(Q_i, K_j) V_j}{\\sum_{j = 1}^N \\text{sim}(Q_i, K_j)} \\]\nLinearizing attention In particular, all kernels \\(k(x, y) = \\langle\\phi(x), \\phi(y)\\rangle_\\mathcal{S} : \\mathbb{R}^{2\\times F} \\rightarrow \\mathbb{R}_+\\) can be used as a similarity function, changing the equation above to\n\\[ V'_i = \\dfrac{\\phi(Q_i)^T \\sum_{j = 1}^N \\phi(K_j) V_j^T}{ \\phi(Q_i)^T \\sum_{j = 1}^N \\phi(K_j)}.\\]\nBecause the right term of the numerator and denominator above does not depend on \\(i\\), it can be computed once for all sequence, and time and memory complexity become \\(\\mathcal{O}(N)\\).\nMasking for autoregressive models By replacing \\(N\\) by \\(i\\) in the expression above, one readily obtains a formulation of the Transformer function which only depends on previous tokens. This is used to train language models in particular, because the prediction of a token can only depend on the previous tokens.\nTransformers are RNNs By rewriting the main kernel formulation of a Transformer above, one sees how it can actually be seen as a RNN. Timesteps of the recurrence are denoted as subscripts.\n\\[ \\begin{aligned} \u0026amp; s_0 = 0, z_0 = 0 \\newline \u0026amp; s_i = s_{i-1} + \\phi(x_i W_K) (x_i W_V)^T \\newline \u0026amp; z_i = z_{i-1} + \\phi(x_i W_K) \\newline \u0026amp; y_i = f_l \\left( \\dfrac{\\phi(x_i W_Q)^T s_i}{\\phi(x_i W_Q)^T z_i} + x_i \\right) \\end{aligned} \\]\nThe resulting RNN has two hidden states, namely the attention memory \\(s\\) and the normalizer memory \\(z\\).\nComments The parallel between RNNs and Transformer models is clearly made in this paper. I believe this is significant because it give insights into why Transformers might be better at language modeling than RNN-based models.\nIt would seem from this new formulation that they aren\u0026rsquo;t better than RNNs but the choice of update function (in the equation above) they are equivalent to is superior.\nAnother possibility is that RNNs and Transformers have always had the same potential. The hype might have fuelled more effort into making Transformers models work better and have thus widened the performance gap between the two otherwise equivalent models. Recent research into RNN models also seems to have favored a few dominant models (standard RNN, LSTM and GRU) and might have slowed the discovery of other, more effective cells.\nExperiments in the paper only demonstrate the performance of their new model on small tasks and I would like to see how this holds up for language modeling.\nBibliography Katharopoulos, Angelos, Apoorv Vyas, Nikolaos Pappas, and François Fleuret. June 29, 2020. \"Transformers Are RNNs: Fast Autoregressive Transformers with Linear Attention\". arXiv:2006.16236 [Cs, Stat]. http://arxiv.org/abs/2006.16236.","title":"Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention by...","url":"https://hugocisneros.com/notes/katharopoulostransformersarernns2020/"}
    
    , 
    
    {"body":" tags Cellular automata source (Mordvintsev et al. 2020)  Summary This paper introduces interesting ideas for training cellular automata as CNNs to have self-repairing stable structures. The automata have 16 dimensional continuous states. The main modeling ideas are:\n Use hard-coded filters for the initial perception step. The filters are Sobel convolutions and those two are concatenated with the current state. Update rules are then 1D convolutions applied to the \\(3 * 16 = 48\\) dimensional state vector. They use a neural network with dimensions 40 -\u0026gt; 128 -\u0026gt; 16. States are updated with probability .5 only, making them highly asynchronous. One of the 16 channels is an \\(\\alpha\\) channel that determines whether the cell is alive or dead. The threshold is set to 0.1 for setting a cell to alive. dead cells have their state manually set to 0 at each step.  The authors then apply several training tricks to make the patterns more robust, self-repairing, etc.\nComments I find the paper quite interesting, especially with its take on CA update as CNN. The fixed convolutions restricts the possible rules while enabling a more stable search process probably.\nSome of the modeling ideas such as the size of the downstream neural in 1D convolutions and the asynchronous updates aren\u0026rsquo;t really justified clearly. The final quantization step to make the whole thing work in browsers is particularly interesting to me: the end up with a CA that has \\(16 * 8 = 128\\) bits states. Or maybe a 120 bits states and 8 bits alive/dead semi-independent state. This is something like \\(10^36\\) states which is many orders of magnitude larger than my experiments.\nThe very last paragraph I particularly like:\n Engineering and machine learning\nThe models described in this article run on the powerful GPU of a modern computer or a smartphone. Yet, let’s speculate about what a “more physical” implementation of such a system could look like. We can imagine it as a grid of tiny independent computers, simulating individual cells. Each of those computers would require approximately 10Kb of ROM to store the “cell genome”: neural network weights and the control code, and about 256 bytes of RAM for the cell state and intermediate activations. The cells must be able to communicate their 16-value state vectors to neighbors. Each cell would also require an RGB-diode to display the color of the pixel it represents. A single cell update would require about 10k multiply-add operations and does not have to be synchronised across the grid. We propose that cells might wait for random time intervals between updates. The system described above is uniform and decentralised. Yet, our method provides a way to program it to reach the predefined global state, and recover this state in case of multi-element failures and restarts. We therefore conjecture this kind of modeling may be used for designing reliable, self-organising agents. On the more theoretical machine learning front, we show an instance of a decentralized model able to accomplish remarkably complex tasks. We believe this direction to be opposite to the more traditional global modeling used in the majority of contemporary work in the deep learning field, and we hope this work to be an inspiration to explore more decentralized learning modeling.\n Bibliography Mordvintsev, Alexander, Ettore Randazzo, Eyvind Niklasson, and Michael Levin. February 11, 2020. \"Growing Neural Cellular Automata\". Distill 5 (2):e23. DOI.","title":"Growing Neural Cellular Automata by Mordvintsev, A., Randazzo, E., Niklasson, E., \u0026 Levin,...","url":"https://hugocisneros.com/notes/mordvintsevgrowingneuralcellular2020/"}
    
    , 
    
    {"body":" tags Cellular automata, Convolutional neural networks  Motivation Cellular automata are computational models based on several principles such as translation-invariance and parallelism of computations. These principles also motivated the creation of Convolutional neural networks \u0026mdash; used initially for images and text \u0026mdash;, making this model well-suited to reason about cellular automata.\nThere is indeed a deep connection between the two models, making it seem like there are two expressions of the same idea: spatially organized information can be processed locally in parallel.\nHere is an example with the Game of Life:\n Figure 1: Any cell update in the Game of Life could be expressed with a neural network, making the global update a series of convolutions + non-linearities\n  Relevant literature Cellular automata can easily be represented as Convolutional Neural Networks (CNNs). This relation has already been investigated in (Gilpin 2018) or (Mordvintsev et al. 2020) for instance. This idea has advantages and drawbacks:\n Computational cost of using floating points operations is higher than discrete operations. Discrete operations can lead to exponential growth of the number of possible configurations and update rules in a CA. This is why rules aren\u0026rsquo;t represented as bijective tables matching neighborhoods to states anymore in (Mordvintsev et al. 2020). The use of floating point operations is mainly there to be able to compute gradients for gradient based optimization. This is against a non-supervised philosophy I am trying to work on. Training cellular automata is basically re-implementing a \u0026ldquo;recurrent convolutional neural network\u0026rdquo;: this might lead to interesting models but isn\u0026rsquo;t exploiting all the potential of those computational models Ultimately computations in a computer are discrete and Mordvintsev et al. eventually use quantization to discretize the CA, resulting in an approximation of a discrete automaton.  Graph networks CNNs could be considered a particular architecture of neural network especially designed for regular grid-like graphs.\nHowever, a CA can have arbitrary structures as long as the rule is defined to deal with this type of structures. This extends the concept of CA-CNN to graph neural networks.\nTuring-completeness Turing-completeness of convolutional neural networks can be directly inferred from this close relation with cellular automata. The condition is to consider a recurrent-convolutional network where the output is fed back to the network at each step. A simple ECA rule such as rule 110 is easily implemented in this type of convolutional neural network, hence Turing-completeness.\nBibliography Mordvintsev, Alexander, Ettore Randazzo, Eyvind Niklasson, and Michael Levin. February 11, 2020. \"Growing Neural Cellular Automata\". Distill 5 (2):e23. DOI. Gilpin, William. September 9, 2018. \u0026ldquo;Cellular Automata as Convolutional Neural Networks\u0026rdquo;. arXiv:1809.02942 [Cond-Mat, Physics:Nlin, Physics:Physics]. http://arxiv.org/abs/1809.02942.\n","title":"Cellular automata as convolutional neural networks","url":"https://hugocisneros.com/notes/cellular_automata_as_cnns/"}
    
    , 
    
    {"body":" tags Cellular automata, Neural networks resources Scholarpedia, (Chua and Yang n.d., 1988)  Bibliography Chua, L.O., and L. Yang. October 1988. \"Cellular Neural Networks: Theory\". IEEE Transactions on Circuits and Systems 35 (10):1257–72. DOI. ———. n.d. \u0026ldquo;Cellular Neural Networks: Applications\u0026rdquo;. IEEE Transactions on Circuits and Systems 35 (10):1273–90. Accessed July 1, 2020DOI.\n","title":"Cellular neural networks","url":"https://hugocisneros.com/notes/cellular_neural_networks/"}
    
    , 
    
    {"body":" tags Unconventional computing, Cellular automata resources (Mitchell 2005; Wolfram 2002)  Cellular automata are computational models capable of interesting emergent behavior. A major challenge is to understand which CA rules are doing useful or efficient computations. It is not clear how these systems could be programmed or made to compute a particular function.\nHand-engineered CA rules Below images show CA rules that can compute non trivial functions (Images are from (Wolfram 2002), see A new kind of science online ). These examples are nice but likely challenging to produce for complex computations.\nBinary adder CA rule Square CA rule Prime CA rule (sieve of Eratosthenes) Hyperbolic space A cellular automaton can solve the 3-SAT problem in polynomial time on a pentagrid \u0026mdash; grids of pentagons \u0026mdash; in hyperbolic space (Margenstern 1999).\nEvolution of CA rules CA rules can also be evolved with Genetic algorithms to perform a particular type of computation. Because it uses a genetic algorithm, this method requires a clear reward/objective function to be effective, which might not be achievable for complex functions were input/output pairs aren\u0026rsquo;t enough of a signal for finding a solution. (Packard 1988; Mitchell, Crutchfield, and Das 1997)\nLink with reservoir computing Computation in cellular automata are difficult to construct and control finely, which is why many have tried to use the reservoir computing with cellular automata framework to try and discover useful computations in cellular automata.\nBibliography Mitchell, Melanie, James P Crutchfield, and Rajarshi Das. 1997. \"Evolving Cellular Automata to Perform Computations\". In Handbook of Evolutionary Computation, edited by B�ck Thomas, David B Fogel, and Zbigniew Michalewicz. IOP Publishing Ltd. DOI. Margenstern, Maurice. 1999. \u0026ldquo;A Polynomial Solution for 3-SAT in the Space of Cellular Automata in the Hyperbolic Plane.\u0026rdquo;. J. UCS 5 (9):563–73. DOI.\nMitchell, Melanie. January 24, 2005. \u0026ldquo;Computation in Cellular Automata: A Selected Review\u0026rdquo;. In Non-Standard Computation, by Tino Gramß, Stefan Bornholdt, Michael Groß, Melanie Mitchell, and Thomas Pellizzari, 95–140. Weinheim, FRG: Wiley-VCH Verlag GmbH \u0026amp; Co. KGaA. DOI.\nPackard, Norman H.. 1988. \u0026ldquo;Adaptation toward the Edge of Chaos\u0026rdquo;. Dynamic Patterns in Complex Systems 212. World Scientific:293.\nWolfram, Stephen. 2002. A New Kind of Science. Champaign, IL: Wolfram Media. https://www.wolframscience.com/nks/.\n","title":"Computing in cellular automata","url":"https://hugocisneros.com/notes/computing_in_cellular_automata/"}
    
    , 
    
    {"body":"(Crutchfield and Young 1989)\nBibliography Crutchfield, James P., and Karl Young. July 10, 1989. \"Inferring Statistical Complexity\". Physical Review Letters 63 (2):105–8. DOI.","title":"Epsilon machines","url":"https://hugocisneros.com/notes/epsilon_machines/"}
    
    , 
    
    {"body":" tags Computer vision  Style transfer is the process of transferring some visual features from one image to another image while preserving the latter\u0026rsquo;s content information. Since both these notions may be considered subjective, the problem of style transfer is not well defined and may be approached in many ways.\nStyle transfer with CNNs This is an early example of style transfer with convolutional neural networks: (Gatys, Ecker, and Bethge 2016)\nBibliography Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. June 2016. \"Image Style Transfer Using Convolutional Neural Networks\". In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2414–23. Las Vegas, NV, USA: IEEE. DOI.","title":"Style transfer","url":"https://hugocisneros.com/notes/style_transfer/"}
    
    , 
    
    {"body":" tags Artificial life, ALife 2020  This keynote is about this sub-community of ALife which is dedicated to constructing actual artificial systems that can exhibit Open-ended Evolution, and Life-like behavior.\nThe first models that tried to construct ALife were probably Von Neumann\u0026rsquo;s self-reproducing CA and Langton\u0026rsquo;s loop. However, their main limitation was they were extremely brittle, which is why evolution did not really work in them.\nZaman\u0026rsquo;s definition of evolution is\n Adaptive evolution can occur iff there is reproduction, heritability of traits, and variation in individual\u0026rsquo;s reproductive success driven by those traits.\n Thomas Ray invented Tierra in 1995 by noting the difference between alterations of the genetic code and alterations of a computer program. To make computer programs resistant to alterations, Tierra introduced a small alphabet of a few elementary assembly-like instructions (similar in number to amino acids). Ray also borrowed the idea of having instructions that can interact with only some other instructions to replicate the way amino acids and proteins need to bind to specific other objects.\nAt the same time, another group of scientists was working on Avida, another Alife system that Zaman is working on.\nHow could Artificial life really reach this space of incredible natural diversity? Zaman\u0026rsquo;s core research theme is co-evolution. This is what he believes could be the source of evolution as we know it.\n Perhaps biological systems have the same problem, that everything around them is constantly evolving and changing, the landscape that they exist in. So the only way to maintain your fitness in a world that is constantly changing is also to constantly change.\n This is also one of the ideas developed in (Pattee and Sayama 2019), that open-endedness could be the result of interactions with a very complex environment and other evolving objects which will increase the overall pressure to evolve.\nW. Daniel Hillis was one of the first person to work on this and use parasites that co-evolve with a solution in a Genetic algorithms-like procedure.\nParasites in Avida One of the main advantages of Avida in my opinion (and other program/string/combinatory logic-based Alife systems) is the fact that there is a very natural metric of complexity which derives from the structures of organisms themselves. In the case of computer programs, the length of the program is a reasonable proxy for its complexity.\nThis metric allows interesting experiments to show how parasites can accelerate evolution in Avida simulations. But the authors wanted to see if such results can also be obtained by using something else than \u0026ldquo;hard-coded\u0026rdquo; parasites. They used alternating environment parameters to reproduce the \u0026ldquo;constantly changing\u0026rdquo; part of natural environment.\nIt turns out this alternating environment experiments seem to show an advantage for obtaining systems that have \u0026ldquo;smoother\u0026rdquo; reward landscapes for a various set of tasks.\nBibliography Pattee, Howard H., and Hiroki Sayama. April 2019. \"Evolved Open-Endedness, Not Open-Ended Evolution\". Artificial Life 25 (1):4–8. DOI.","title":"Talk: Alife 2020 keynote Luis Zaman - New Frontiers in Alife: What was old is new again","url":"https://hugocisneros.com/notes/talk_alife_2020_keynote_luis_zaman_new_frontiers_in_alife_what_was_old_is_new_again/"}
    
    , 
    
    {"body":" tags Cellular automata, Graphs  This concept was mentioned in (O’Sullivan 2001), although it may not be the first ever mention of it.\nThe idea is also similar to graph convolutional networks and other graph neural networks, where the goal is to construct an update function for a node that doesn\u0026rsquo;t depend on the number of neighboring nodes. This enables running cellular automata on non-grid structures.\nBibliography O’Sullivan, David. October 2001. \"Graph-Cellular Automata: A Generalised Discrete Urban and Regional Model\". Environment and Planning B: Planning and Design 28 (5):687–705. DOI.","title":"Graph cellular automata","url":"https://hugocisneros.com/notes/graph_cellular_automata/"}
    
    , 
    
    {"body":" tags Machine learning, Unconventional computing, Unsupervised learning  Reservoir computing is a term used to describe a class of machine learning algorithms that rely on transient dynamics of a dynamical system to implement and manipulate goal-related information.\nThe most famous example is echo-state networks, which uses random recurrent neural networks as reservoirs, but other dynamical systems can also be used.\nReservoir computing with cellular automata Reservoir computing can use cellular automata as the reservoir. Some citations (Nichele and Molund 2017; Yilmaz 2014; Morán, Frasser, and Rosselló 2018; Babson, Teuscher, and 2019).\nEcho-state networks Reservoir computing for differential equation solving (Mattheakis, Joy, and Protopapas 2021)\nBibliography Babson, Neil, Christof Teuscher, and . December 15, 2019. \"Reservoir Computing with Complex Cellular Automata\". Complex Systems 28 (4):433–55. DOI. Mattheakis, Marios, Hayden Joy, and Pavlos Protopapas. August 25, 2021. \u0026ldquo;Unsupervised Reservoir Computing for Solving Ordinary Differential Equations\u0026rdquo;. arXiv:2108.11417 [Physics]. http://arxiv.org/abs/2108.11417.\nMorán, Alejandro, Christiam F. Frasser, and Josep L. Rosselló. June 21, 2018. \u0026ldquo;Reservoir Computing Hardware with Cellular Automata\u0026rdquo;. arXiv:1806.04932 [Nlin]. http://arxiv.org/abs/1806.04932.\nNichele, Stefano, and Andreas Molund. March 8, 2017. \u0026ldquo;Deep Reservoir Computing Using Cellular Automata\u0026rdquo;. arXiv:1703.02806 [Cs]. http://arxiv.org/abs/1703.02806.\nYilmaz, Ozgur. October 1, 2014. \u0026ldquo;Reservoir Computing Using Cellular Automata\u0026rdquo;. arXiv:1410.0162 [Cs]. http://arxiv.org/abs/1410.0162.\n","title":"Reservoir computing","url":"https://hugocisneros.com/notes/reservoir_computing/"}
    
    , 
    
    {"body":" source (Dong et al. 2020) tags Reservoir computing, Kernel Methods  Summary This paper presents a connection between large size reservoir computing and kernel methods.\nThe authors formulate a reservoir computing model as a form of recurrent kernel iteration. If the reservoir update is written \\[ x^{(t+1)} = \\dfrac{1}{\\sqrt{N}} f \\left(W_r x^{(t)} + W_i i^{(t)} \\right) \\] with \\(x^{(t)}\\) the state of the reservoir at time \\(t\\) and \\(i^{(t)}\\) sequential input at time \\(t\\), \\(W_r \\in \\mathbb{R}^{N\\times N}\\) and \\(W_i \\in \\mathbb{R}^{N\\times d}\\), we may re-frame it as a random feature embedding of the vector \\(\\left[ x^{(t)} , i^{(t)} \\right]\\) with the matrix \\(W = [W_r, W_i]\\).\nBibliography Dong, Jonathan, Ruben Ohana, Mushegh Rafayelyan, and Florent Krzakala. June 12, 2020. \"Reservoir Computing Meets Recurrent Kernels and Structured Transforms\". arXiv:2006.07310 [Cs, Eess, Stat]. http://arxiv.org/abs/2006.07310.","title":"Reservoir Computing meets Recurrent Kernels and Structured Transforms by Dong, J., Ohana,...","url":"https://hugocisneros.com/notes/dongreservoircomputingmeets2020/"}
    
    , 
    
    {"body":" tags Mathematics  ","title":"Differential equations","url":"https://hugocisneros.com/notes/differential_equations/"}
    
    , 
    
    {"body":" tags NLP  LM with RNNs Different models have been studied, starting from the initial Recurrent neural network based language model (Mikolov et al. 2011).\nLSTM were then used with more success than previous models (Zaremba, Sutskever, and Vinyals 2015).\nRecently, transformers seem to have dominated language modeling. However it is not clear if this is due to their real superiority over RNNs or their practical scalability (Merity 2019).\nLM with Transformers Language modeling and Compression Text generation Language models can be used to generate text from a prompt or starting sentence. This is the kind of examples that made models like GPT-2 and GPT-3 famous, because of their ability to generate long sequences of apparently coherent text (Radford et al. 2019; Brown et al. 2020).\nOther applications Language modeling for Automated theorem proving (Polu and Sutskever 2020)\nLanguage modeling for Reinforcement Learning (Janner, Li, and Levine, n.d.)\nBibliography Brown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al.. June 4, 2020. \"Language Models Are Few-Shot Learners\". arXiv:2005.14165 [Cs]. http://arxiv.org/abs/2005.14165. Janner, Michael, Qiyang Li, and Sergey Levine. n.d. \u0026ldquo;Reinforcement Learning as One Big Sequence Modeling Problem\u0026rdquo;, 15.\nMikolov, Tomas, Martin Karafiat, Lukas Burget, Jan Cernocky, and Sanjeev Khudanpur. 2011. \u0026ldquo;Recurrent Neural Network Based Language Model\u0026rdquo;, 4.\nPolu, Stanislas, and Ilya Sutskever. September 7, 2020. \u0026ldquo;Generative Language Modeling for Automated Theorem Proving\u0026rdquo;. arXiv:2009.03393 [Cs, Stat]. http://arxiv.org/abs/2009.03393.\nRadford, Alec, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. \u0026ldquo;Language Models Are Unsupervised Multitask Learners\u0026rdquo;. OpenAI Blog 1 (8):9.\nZaremba, Wojciech, Ilya Sutskever, and Oriol Vinyals. February 19, 2015. \u0026ldquo;Recurrent Neural Network Regularization\u0026rdquo;. arXiv:1409.2329 [Cs]. http://arxiv.org/abs/1409.2329.\nMerity, Stephen. November 26, 2019. \u0026ldquo;Single Headed Attention RNN: Stop Thinking with Your Head\u0026rdquo;. arXiv:1911.11423 [Cs]. http://arxiv.org/abs/1911.11423.\n","title":"Language modeling","url":"https://hugocisneros.com/notes/language_modeling/"}
    
    , 
    
    {"body":" tags Artificial Intelligence, Applied maths  Machine learning is about constructing algorithms that can approximate complex functions from observations of input/output pairs. Machine learning is related to Statistics since its goal is to make predictions based on data.\nExamples of such functions include:\n Image classification Time-series prediction Language modeling  Regression The goal is to approximate a target function \\(f\\) or signal \\(S\\).\n","title":"Machine learning","url":"https://hugocisneros.com/notes/machine_learning/"}
    
    , 
    
    {"body":" tags Artificial life, Complex Systems  He is a researcher in the field of artificial life and complex systems. He developed many tools and systems that the Alife community still uses today.\nHe created a particular cellular automata: the langton loop.\n","title":"Christopher Langton","url":"https://hugocisneros.com/notes/christopher_langton/"}
    
    , 
    
    {"body":" tags Data representation, Neural networks  Implicit neural representations is about parameterizing a continuous differentiable signal with a neural network. The signal is encoded within the neural network, providing a possibly more compact representation. This is a type of regression problem.\nApplications of these learned representations range from simple compression, to 3D scene reconstruction from 2D images, semantic information inference, etc.\nCPPN is an early example of a implicit neural representation implementation mainly used for pattern generation . It uses a neural network to generate patterns parameterized by two (or more) coordinates .\nImplicit neural representations for high frequency data To encode potentially high frequency data such as sound or images, it is much more efficient to start from periodic feature transformations. This can be achieved with periodic activation functions (Sitzmann et al. 2020) or by using a Fourier feature mapping (Tancik et al. 2020) .\nNeural radiance fields (Mildenhall et al. 2020)\nBibliography Mildenhall, Ben, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng. August 3, 2020. \"NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis\". arXiv:2003.08934 [Cs]. http://arxiv.org/abs/2003.08934. Sitzmann, Vincent, Julien N. P. Martel, Alexander W. Bergman, David B. Lindell, and Gordon Wetzstein. June 17, 2020. \u0026ldquo;Implicit Neural Representations with Periodic Activation Functions\u0026rdquo;. arXiv:2006.09661 [Cs, Eess]. http://arxiv.org/abs/2006.09661.\nTancik, Matthew, Pratul P. Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan T. Barron, and Ren Ng. June 18, 2020. \u0026ldquo;Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains\u0026rdquo;. arXiv:2006.10739 [Cs]. http://arxiv.org/abs/2006.10739.\n","title":"Implicit neural representations","url":"https://hugocisneros.com/notes/implicit_neural_representations/"}
    
    , 
    
    {"body":" tags Applied maths  The Softmax can refer to two mathematical functions:\n In machine learning a softmax is the function which normalizes a vector of values to a probability vector: \\(\\text{softmax}(\\mathbf{x}) = \\dfrac{e^{\\mathbf{x}}}{\\sum_i e^{x_i}}\\) where \\(\\mathbf{x} = (x_i) \\in \\mathbb{R}^n\\). This function could also be called soft-argmax because it is a smooth approximation of the discrete argmax function. It may also refer to a smoothed maximum function like \\(\\epsilon \\log \\sum_i \\exp (x_i / \\epsilon)\\) which approximates the \\(\\text{max}\\) function in the limit \\(\\epsilon \\rightarrow 0\\)  ","title":"Softmax","url":"https://hugocisneros.com/notes/softmax/"}
    
    , 
    
    {"body":" tags Neural radiance fields, Meta-learning source (Tancik et al. 2021)  Summary This paper explores meta-learning techniques for improving the quality and speed of convergence of learned implicit neural representations.\nThe authors use meta-learning to optimize the initial weights \\(\\theta_0\\) of the neural networks such that it minimizes the loss \\(L(\\theta_m)\\) when the network is optimized on a new unseen observations.\nAs a meta-learning problem, there is an inner loop and an outer loop:\n The inner loop is the optimization procedure to go from a \\(\\theta_0\\) to an optimized \\(\\theta_m\\) for a specific observation T. This can be done with classical optimization methods The outer loop is about shifting the position of the \\(\\theta_0\\) to make the inner loop results better on average. This cannot be done with the usual learning algorithms.  Two algorithms are considered for that outer-loop:\n MAML where the update \\(\\theta_0^{(j+1)} = \\theta_0^j - \\beta\\nabla_\\theta L(\\theta_m(\\theta, T_j))\\) is computed by taking inner-loop steps with different step sizes Reptile where the update \\(\\theta_0^{(j+1)} = \\theta_0^j - \\beta\\left( \\theta_m(\\theta_0^j, T_j) - \\theta_0^j \\right)\\) is a step towards the optimized weights from an observation  This setup gives very good results. The training of neural representations is faster and of better quality than with other types of initialization (even initialization trained to match the output of the met-learned one).\nThe results are encouraging both for image regression and view synthesis of 3D objects.\nBibliography Tancik, Matthew, Ben Mildenhall, Terrance Wang, Divi Schmidt, Pratul P. Srinivasan, Jonathan T. Barron, and Ren Ng. March 23, 2021. \"Learned Initializations for Optimizing Coordinate-Based Neural Representations\". arXiv:2012.02189 [Cs]. http://arxiv.org/abs/2012.02189.","title":"Learned Initializations for Optimizing Coordinate-Based Neural Representations by Tancik,...","url":"https://hugocisneros.com/notes/tanciklearnedinitializationsoptimizing2021/"}
    
    , 
    
    {"body":" tags Machine learning  Constrained meta-learning (Kirsch and Schmidhuber 2021)\nMeta-learning of initialization The goal is to learn the initialization of neural network parameters or recurrent neural network initial states in order to make the training faster or less prone to getting stuck in local minima.\nExample for implicit neural representations: (Tancik et al. 2021)\nMeta-learning algorithms MAML (Finn, Abbeel, and Levine 2017)\nReptile (Nichol, Achiam, and Schulman 2018)\nBibliography Finn, Chelsea, Pieter Abbeel, and Sergey Levine. 2017. \"Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\". In Proceedings of the 34th International Conference on Machine Learning, 70:10. Sydney, Australia. Kirsch, Louis, and Jürgen Schmidhuber. February 16, 2021. \u0026ldquo;Meta Learning Backpropagation and Improving It\u0026rdquo;. arXiv:2012.14905 [Cs, Stat]. http://arxiv.org/abs/2012.14905.\nNichol, Alex, Joshua Achiam, and John Schulman. October 22, 2018. \u0026ldquo;On First-Order Meta-Learning Algorithms\u0026rdquo;. arXiv:1803.02999 [Cs]. http://arxiv.org/abs/1803.02999.\nTancik, Matthew, Ben Mildenhall, Terrance Wang, Divi Schmidt, Pratul P. Srinivasan, Jonathan T. Barron, and Ren Ng. March 23, 2021. \u0026ldquo;Learned Initializations for Optimizing Coordinate-Based Neural Representations\u0026rdquo;. arXiv:2012.02189 [Cs]. http://arxiv.org/abs/2012.02189.\n","title":"Meta-learning","url":"https://hugocisneros.com/notes/meta_learning/"}
    
    , 
    
    {"body":" tags ALife Conference  Day 1 Tutorial - Functional programming for artificial life Tutorial - Visualization Principles and Techniques for Research in ALife Mike Levin - Keynote Lecture Day 2 Sara Walker, keynote Lecture About what life means and how it can be defined from the point of view of physics/information theory, etc.\nMelanie Mitchell, keynote Lecture This talk was very similar to another one I watched from Santa Fe Institute which promotes her book: Artificial Intelligence: A Guide for Thinking Humans.\nIt gives a detailed breakdown of why machine learning still fails at many tasks and might not be able to overcome them before we change the current way of doing it. The main takeaway for me is that Mitchell believes we will need to somehow build abstraction or conceptualization capabilities within our ML models to make them able to use “common sense” and understand things we consider as basic.\nDay 3 Lee Cronin, keynote Lecture Contributed session 1 Djordje Grbic, Sebastian Risi - Safe Reinforcement Learning through Meta-learned Instincts See notes.\nToby Howison, Josie Hughes, Fumiya Iida - Morphologically programming the interactions of V-shaped falling papers Interesting talk about falling V-shaped papers. The range of exhibited behavior is surprising and is an instance of complex systems with a few controllable parameters but surprising dynamics.\nCem Tutum, Risto Miikkulainen - Adapting to Unseen Environments through Explicit Representation of Context See notes.\nManon Flageat, Antoine Cully - Fast and stable MAP-Elites in noisy domains using deep grids See notes.\nJulian F. Miller: Evolving developmental neural networks to solve multiple problems This talk is about introducing a new model of neural network neuron that could have enough modularity to deal with multiple problems at once.\nPeter Andras - Composition of Games as a Model for the Evolution of Social Institutions Socials institutions can be seen as large games with rules, norms, and values. They are complex evolving systems starting form simple cooperation and evolving to complex things. The author applies a game theory framework to these systems.\nJames M. Borg, Matt Grove, Fiona Polack - Coloured noise time series as appropriate models for environmental variation in artificial evolutionary systems Many biological time-series exhibit a type of colored noise. The authors use different noise functions in evolutionary models and observe that it profoundly affect the evolutionary response. This is interesting because it shows that the most often used white noise (Gaussian noise) might not be the best choice for evolution simulations.\nContributed session 2 Randall D. Beer - An Integrated Perspective on the Constitutive and Interactive Dimensions of Autonomy See notes.\nMark Bedau - Dynamic natural kinds: Open-ended evolution in the joints of nature The authors use word2vec on patents to identify technological feature spaces. The similarity between patent descriptions is used to measure their proximity. This offers and interesting perspective on the space of different technologies and their hierarchical and dynamical properties.\nAcacia Ackles, Austin Ferguson, Connor Grady, Charles Ofria - Rank epistasis: A new model for analyzing epistatic interactions in the absence of quantifiable fitness interactions This paper studies an epistasis model. The new proposed model is based on ranking loci of a genetic model based on their fitness. Then, after mutating a locus and computing the new ranking. By comparing statistical differences between the two rankings one can estimate the effect of the previously introduced mutation.\nThe authors used NK model to study the new metric in a relatively well studied environment. Sites with higher epistatic activity score higher according to their metric and this happens without any a priori information about how the sites interact with each other.\nThomas Helmuth, Edward Pantridge, Grace Woolson Lee Spector - Genetic Environment Sensitivity and Transfer Learning in Genetic Programming This paper is about using genetic programming for program synthesis.\nMahi Luthra, Eduardo J. Izquierdo, Peter M. Todd - Cognition Evolves with the Emergence of Environmental Patchiness Using a simple agent based simulation of animals and plants in a grid world, the authors observe spontaneous \u0026ldquo;patchiness\u0026rdquo; of the partition of plants. Cognition, defined as the ability perceptual strength of an agent and the stochasticity of its decisions increases and stabilizes in those simulations.\nWhen cognition is not restricted, patches are larger and more visible, whereas for restricted cognition resource distribution is more uniform. There is a two way influence of both parameters on the evolution of patches and cognition.\nLauren Benso, Lauren Benson, Madhavun Candadai and Eduardo Izquierdo - Neural reuse in multifunctional circuits for control tasks This talk is about studying a simple two-layers feedforward neural network evolved to solve three RL tasks at the same time. Then by introducing neuron lesions and their effect on the fitness, one is able to identify the useful neurons and their importance.\nMany neurons are re-used across multiple tasks. With neural variance and mutual information within each neurons the authors are able to analyze the reuse of neurons.\nThe takeaways are :\n It seems relatively simple to obtain neuron reuse across tasks with simple evolutionary methods Successful neural networks on theses toy tasks appear to reuse their neurons  Contributed session 3 Shane St. Luce, Hiroki Sayama - Phase Spaces of the Strategy Evolution in the El Farol Bar Problem Guillaume St-Onge, Antoine Allard, Laurent Hébert-Dufresne - Localization, bistability and optimal seeding of contagions on higher-order networks In this talk, the author studies higher-order networks, which differently from simple networks, have interactions that can exist within groups of elements (instead of pairs). This allows studying contagion and spreading dynamics from a new angle.\nJuan Perez-Mercader - Non-biochemical autonomous synthesis and boot-up from a chemical homogeneous mixture of a population of vesicles: their birth, growth, self-replication, extinction and competition cycles Abe Leite, Madhavun Candadai and Eduardo J. Izquierdo - Reinforcement learning beyond the Bellman equation: Exploring critic objectives using evolution Thomas Helmuth, Lee Spector - Explaining and Exploiting the Advantages of Down-sampled Lexicase Selection Oskar Elek, Joseph N. Burchett, J. Xavier Prochaska and Angus G. Forbes - Monte Carlo Physarum Machine: Agent-based Model for Reconstructing Complex 3D Transport Networks Cosmic web is diffuse, not only composed of galaxies but hot and cold gas and dark matter. It is very hard to capture from experimental data. Authors use the slime mold as a model for reconstructing this network. This mold is interesting because by using gradients of chemicals emitted by food and itself, it can construct near-optimal transport networks. Their model is also inspired from Sage Jensons\u0026rsquo;s cyber critters adapted to 3D. They use Monte-carlo sampling of directions around the gradient for moving each tiny agent which results in more natural-looking simulations.\nThis model reproduces the cosmic web in a relatively faithful way visually, and is robust thanks to its stochastic component.\nContributed session 4 Matthew Egbert - Marangoni Based Motile Oil-Droplets in Simulated Artificial Chemistry Nicolas Lobato-Dauzier, Leo Cazenille , Teruo Fujii, Anthony Genot and Nathanael Aubert-Kato -Temperature-based inputs for molecular reservoir computers Azumi Mamiya, Genki Ichinose - Zero-Determinant Strategies under Observation Errors Ekaterina Sangati, Simon M. Hofmann - The Role of Co-Representations in Joint Tracking Palin Choviwatana, Shota Ejima, Mizuki Oka, Takashi Ikegami - Web as an Evolutionary Ecosystem: Emergence of Keystone Species Contributed session 5 Hoang Nguyen, Peter Banda, Darko Stefanovic, Christof Teuscher - Reservoir Computing with Random Chemical Systems Zineb Elhamer, Reiji Suzuki, Takaya Arita - Hybrid Approach to Understanding Continuous Social Dynamics Based on A Large-Scale Modeling and A Face-to-Face Experiment Hiroki Sato, Itsuki Doi, Yasuhiro Hashimoto, Mizuki Oka, Takashi Ikegami - Selection and Accelerated Divergence in Hashtag Evolution on a Social Network Service Michael L Wong and Stuart Bartlett - Defining Lyfe in the Universe: From Three Privileged Functions to Four Pillars Wen-Chi Yang, Yuh-Huey Lee, Kuo-Shih Yang - Modeling the Impact of Social Comparison on Student Engagement by the Equity Theory Manh Hong Duong, The Anh Han - The effect of mutation on equilibrium properties of deterministic and random evolutionary games Poster Session Matthew Dale - Designing Computational Substrates using Open-Ended Evolution This poster is about characterizing the computational capabilities of reservoir computing systems. The author\u0026rsquo;s goal is to design computational substrates that have interesting properties when used as reservoir computing basis.\nFor this, the authors have to define a behavior space that they slice up into voxels. They use novelty search to explore that space and measure the quality of the possible behavior.\nElissa Cohen - Resilient Life: An Exploration of Perturbed Autopoietic Patterns in Conway’s Game of Life See notes.\nDay 4 Luis Zaman, keynote Lecture Contributed session 6 Contributed session 7 Day 5 Contributed session 8 Contributed session 9 Day 6 Contributed session 10 Demyan Vakhrameev, Xabier Barandiaran, Miguel Aguilera, Manuel Bedia - Measuring Autonomy for Life-Like AI Léni K. Le Goff, Emma Hart, Agoston E. Eiben - Sample and time-efficient policy learning with CMA-ES and Bayesian Optimisation Paul Ecoffet, Jean-Baptiste André, Nicolas Bredeche - Learning to Cooperate in a Socially Optimal Way in Swarm Robotics Payam Zahadat, Ada Diaconescu - Reactive or Stable: A Plant-inspired Approach for Organisation Morphogenesis Edmund Hunt, Nigel R. Franks, Roland J. Baddeley - The Bayesian Superorganism: Collective Probability Estimation in Swarm Systems Tim Taylor - The Importance of Open-Endedness (for the Sake of Open-Endedness) Asheesh Sharma, Sabine Hauert and Helmut Hauser - Morphological communication for swarms Contributed session 11 Gunnar Tufte, Johannes H. Jensen - Reservoir Computing in Artificial Spin Ice See notes.\nStephan Scheidegger, Alexander Mikos, Harold Fellermann - Modelling Artificial Immune – Tumor Ecosystem Interaction During Radiation Therapy Using a Perceptron – Based Antigen Pattern Recognition Juste Raimbault - A model of urban evolution based on innovation diffusion See notes.\nMerihan Alhafnawi, Sabine Hauert, Paul O\u0026rsquo;Dowd - Robotic Canvas: Interactive Painting onto Robot Swarms Léni K. Le Goff, Emma Hart, Stéphane Doncieux, Alexandre Coninx - On Pros and Cons of Evolving Topologies with Novelty Search Novelty search is used in simple maze and navigation tasks and different evolved and non evolved architecture are compared.\nDitlev Hartmann Bornebusch, Christina C. Soerensen, Peter Zingg, Gianluca Gazzola, Norman Packard and Steen Rasmussen Rebecca Kramer-Bottiglio keynote Lecture This keynote was about using robotic skins to make soft and \u0026ldquo;natural\u0026rdquo;-looking robots. This allows to transform inert object into actuators or moving robots.\nKramer\u0026rsquo;s team is developing molecules and composite materials with multiple functionalities.\n","title":"ALife 2020","url":"https://hugocisneros.com/notes/alife_2020/"}
    
    , 
    
    {"body":" source (Lu et al. 2021) tags Transformers  Summary Different types of neural network architecture encode different kinds of biases. For example, convolutional neural networks perform local, translation-invariant operations and recurrent neural networks operate on sequential data.\nOne can use these biases in randomly initialized networks as a basis for interesting computations. This is on of the motivation for reservoir computing with echo-state networks, which uses fixed random recurrent neural network and a simple trainable linear transformation to perform complex computations. The intuition behind this is model is that interesting computations may be happening within the random RNN (and they are probably increasingly likely with bigger RNN). The linear layer can select useful computations and filter out the rest to give a result.\nThis paper invastigates something similar to that idea. However, instead of random models they investigate the capacity of pretrained models, more precisely pretrained transformers.\nIn their setup, all the weights of a transformer are frozen except for an input embedding layer, the positional embeddings, the layer norm parameters and a simple output layer. The architecture is shown in the Figure below taken from the paper:\n This model is tested on a set of tasks:\n Bit memory: a task about memorizing bits in a sequence Bit XOR: a task about being able to XOR bits from two sequences ListOps: this task is akin to an elementary interpreter which has to perform operations on lists of integers MNIST: digit classification CIFAR-10: image classification CIFAR-10 LRA: a modified version of CIFAR where images are converted to grayscale and fed to the transformer with a token length of 1. Remote homology detection  The paper uses a range of setups to understand which combination of architecture/pretraining/etc. works the best.\nComments The part which is most interesting to me is not the main result of that paper but the results from table 3, shown below\n It is very interesting to see a possible superiority of random transformers over random LSTM, which may also explain why the former is so much better at many tasks. However I couldn\u0026rsquo;t find information about the number of frozen parameters in that LSTM vs. the tested transformers. Also, because LSTMs don\u0026rsquo;t have layer normalization or positional embeddings, there have significantly less trainable parameters (80% less for a task like CIFAR according to numbers from the paper).\nMaybe the authors factored this in by changing the number of parameters in the LSTM model but I couldn\u0026rsquo;t find that information in the paper.\nA fairer comparison would have a transformer and LSTM with the same number of parameters. However this would make gradient computation in the LSTM very expensive compared to the transformer \u0026mdash; which was partly invented to cope with that problem.\nI also think that it is nice to find some evidence for a set of primitives being learned by language models and this may pave the way for unsupervised models that keep learning new things and reusing these elementary functions.\nBibliography Lu, Kevin, Aditya Grover, Pieter Abbeel, and Igor Mordatch. March 9, 2021. \"Pretrained Transformers as Universal Computation Engines\". arXiv:2103.05247 [Cs]. http://arxiv.org/abs/2103.05247.","title":"Pretrained Transformers as Universal Computation Engines by Lu, K., Grover, A., Abbeel,...","url":"https://hugocisneros.com/notes/lupretrainedtransformersuniversal2021/"}
    
    , 
    
    {"body":" tags NLP, Computer science source (Weiss, Goldberg, and Yahav 2021)  Summary This paper introduces a programming language that is inspired by the way Transformers process input data. The language is called Restricted Access Sequence Processing Language (RASP).\nData is represented as sequences, which is the structure transformers manipulate (since they have been designed for NLP applications). The language has two types of internal data representation:\n Sequence operators (s-ops) are functions that translate sequences into sequences. For example, the tokens operator is the identity and the length operator is defined by length([\u0026quot;h\u0026quot;, \u0026quot;i\u0026quot;]) = [2, 2]. Selectors are functions that takes two sequences and a boolean predicate that can be applied to all pairs of input values. It returns a matrix which values are the result of the boolean op on pairs of values. \\[ \\text{select}([1, 2, 3], [0, 3, 4], \u0026lt;) = \\begin{bmatrix} \\text{F} \u0026amp; \\text{T} \u0026amp; \\text{T}\\newline \\text{F} \u0026amp; \\text{T} \u0026amp; \\text{T}\\newline \\text{F} \u0026amp; \\text{F} \u0026amp; \\text{T} \\end{bmatrix} \\] Selectors are paired with aggregators that will convert a selector matrix and a sequence to a sequence. The selector filters and average input values: \\[ \\text{aggregate}(\\begin{bmatrix} \\text{F} \u0026amp; \\text{T} \u0026amp; \\text{T} \\newline \\text{F} \u0026amp; \\text{T} \u0026amp; \\text{T}\\newline \\text{F} \u0026amp; \\text{F} \u0026amp; \\text{T} \\end{bmatrix} , [0, 12, 3]) = [7.5, 7.5, 3] \\]  Correspondence between RASP ops and transformer components:\n Built-in s-ops like indices and tokens are similar to input embeddings of a transformer. Element-wise s-ops are related to feed-forward components in transformers which are just regular neural networks. Selection and aggregation are akin to attention in transformers.  To evaluate how \u0026ldquo;good\u0026rdquo; this new language is for understanding and designing transformer architectures, the authors study three main questions:\n  its ability to upper bound the number of heads and layers required to solve a task, the tightness of that bound, its feasibility in a transformer   Bibliography Weiss, Gail, Yoav Goldberg, and Eran Yahav. June 13, 2021. \"Thinking like Transformers\". arXiv:2106.06981 [Cs]. http://arxiv.org/abs/2106.06981.","title":"Thinking Like Transformers by Weiss, G., Goldberg, Y., \u0026 Yahav, E. (2021)","url":"https://hugocisneros.com/notes/weissthinkingtransformers2021/"}
    
    , 
    
    {"body":" tags Applied maths  Such a system with \\(m\\) equations and \\(n\\) unknowns is often denoted \\(Ax = b\\) where \\(A\\) is a matrix \\(m\\times n\\) and \\(b\\) is a vector of size \\(m\\).\nThere are multiple methods to solve such a systems with different sets of hypotheses.\nSystem types Square matrix with full rank In the most simple case: a square matrix with full rank, the solution exists and is unique: \\(x = A^{-1} b\\)\nUnderdetermined systems In general, such systems have a family of solutions that can be parametrized by some constraint on their components.\nThey can be solved with the following equation: \\[ x = A^+ b + (I - A^+ A)w \\], where \\(w\\) is a vector and \\(A^+\\) is the Moore-Penrose inverse of the matrix \\(A\\). The solutions form a vector space.\nOverdetermined systems In overdetermined systems, there is no actual solution. However, one can look for the best solution according to some criterion. If that criterion is the sum of squared residuals, this leads to ordinary least squares.\n","title":"System of linear equations","url":"https://hugocisneros.com/notes/system_of_linear_equations/"}
    
    , 
    
    {"body":" tags Signal processing  Description Compressed sensing is a technique to recover a sparse signal from partial observations.\nThe signal is described as a $N$-dimensional vector \\(\\textbf{s}\\). We make \\(M\\) measurements, where a measurements means a projection of the signal \\(\\textbf{s}\\) onto some known vector. The result of all these measurements can be written as \\(\\textbf{y} = \\textbf{Fs}\\), where \\(\\textbf{F}\\) is a \\(M \\times N\\) matrix.\nIn the context of compressed sensing, we have \\(M \u0026lt; N\\). This results in an underdetermined linear system which usually has an infinite number of solutions.\n\u0026lt;~/Papers/library.json\u0026gt;\n","title":"Compressed sensing","url":"https://hugocisneros.com/notes/compressed_sensing/"}
    
    , 
    
    {"body":" tags Algorithm, Computer science resources Yurichev.com  ","title":"Knuth-Morris-Pratt string-searching algorithm","url":"https://hugocisneros.com/notes/knuth_morris_pratt_string_searching_algorithm/"}
    
    , 
    
    {"body":" tags Cellular automata, Neural cellular automata  ","title":"Neural cellular automata and implicit representations","url":"https://hugocisneros.com/notes/neural_cellular_automata_and_implicit_representations/"}
    
    , 
    
    {"body":" tags Language resources https://s.ai/nlws/  A fascinating writing system based on glyphs connected to each other to create meaning. The system is quite advanced and reading its grammar is like discovering some new alien language. It was created by Alex Fink and Sai in 2010.\nThis is the kind of complexity that would be incredible to discover in open-ended evolving language systems. A system starting from elementary components and no particular assumption about what language should be, could come up with such exotic models (probably even more exotic in the case of a truly open-ended system).\nExample  Figure 1: An example of Unker non-linear writing system (UNLWS) with translation from Conlang Relay 19 (entry link).\n   The UNLWS has no inherent reading order, so this rendering proceeds in an order paralleling the Ttuan.\n The following story takes place a hundred million years ago. Two small stones were located at an extremely narrow mountain range. The first stone asked \u0026ldquo;What\u0026rsquo;s on the other side of our mountain range?\u0026rdquo; The other stone said \u0026ldquo;We\u0026rsquo;ll never perceive what\u0026rsquo;s over there.\u0026rdquo; This was overheard by a flying creature and a snake with two hands, who joined the conversation. The flier said \u0026ldquo;We two would be able to travel to the other side of the mountains, and return and tell you what we observed there. Would you like that?\u0026rdquo; The stones said they would. This induced the flier and snake to do so, separately. The flier gave its report: \u0026ldquo;From a distance, I perceived three things there: a river with a broad, sparkly surface; a long valley, which is filled with a mass of green vegetation; and an unusual tree with four trunks.\u0026rdquo; The first stone said \u0026ldquo;Hearing that, it\u0026rsquo;s just like we were there.\u0026rdquo; The second said \u0026ldquo;If we don\u0026rsquo;t get familiar with this place, we\u0026rsquo;ll be very sad forevermore.\u0026rdquo; Then the snake gave its report: \u0026ldquo;I got familiar with the place and experienced the same three things: a large body of slow-moving water, with the smell of formerly-present food; a bunch of stiff plants; and a place with many rodenty critters around.\u0026rdquo; The first stone said \u0026ldquo;I don\u0026rsquo;t want to see that.\u0026rdquo; The second said \u0026ldquo;You\u0026rsquo;re not like me, then. I\u0026rsquo;d already be content to the full degree if I saw that.\u0026rdquo;   If this had been the base language of humans, so many things would have been different. Books, ancient writings, computers, every communication device would have to be designed in a radically distinct way. I suspect our very way of forming thoughts and viewing the world would also be different.\nIntuitively, it seems likely that our writing systems and way of communicating are partially shaped by biological constraints (having a body, hands, tongue, etc.) and something similar to UNLWS to arise spontaneously could be very improbable because it is so impractical given those constraints.\n","title":"Unker non-linear writing system","url":"https://hugocisneros.com/notes/unker_non_linear_writing_system/"}
    
    , 
    
    {"body":" tags Recurrent neural networks source (Voelker, Kajić, and Eliasmith 2019)  Summary This paper introduces the LMU recurrent cell. This cell is based on a similar-ish idea to LSTM to maintain a memory hidden state. The main idea of the paper is to make this memory satisfy a set of first order ordinary differential equations.\n\\[\n\\begin{equation} \\theta \\dot{m}(t) = Am(t) + Bu(t) \\end{equation}\n\\]\nThis system has a solution which represents sliding windows of \\(u\\) via Legendre polynomials. This new unit is tested on a range of tasks. A memory only task, a permuted MNIST task and a dynamical chaotic system prediction task.\nComments Unfortunately, my understanding of this paper is slightly limited. The approach is interesting and has good properties, however the new RNN cell is tested on a small set of task that independently demonstrate useful properties but not all of them together (e.g. good MNIST prediction + long-term dependency).\nBibliography Voelker, Aaron, Ivana Kajić, and Chris Eliasmith. 2019. \"Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks\". In Advances in Neural Information Processing Systems 32, edited by H. Wallach, H. Larochelle, A. Beygelzimer, F. d\\textquotesingle Alché-Buc, E. Fox, and R. Garnett, 15544–53. Curran Associates, Inc. http://papers.nips.cc/paper/9689-legendre-memory-units-continuous-time-representation-in-recurrent-neural-networks.pdf.","title":"Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks by...","url":"https://hugocisneros.com/notes/voelkerlegendrememoryunits2019/"}
    
    , 
    
    {"body":" tags Artificial life, Emergence source (Gershenson 2021)  Summary The paper introduces a complexity metric based on information. emergence is first measured with Shannon\u0026rsquo;s information: \\[E = - K \\sum_{i} p_i \\log p_i\\]\nThen the author argues that self-organization can be seen as the opposite of emergence, and measured with \\[S = 1 - E\\]\n [\u0026hellip;] complex systems tend to exhibit both emergence and self-organization. Extreme emergence implies chaos, while extreme self-organization implies immutability. Complexity requires a balance between both emergence and self-organization.\n Therefore we can measure complexity as: \\[C = 4 S \\cdot E\\] where \\(S\\) and \\(E\\) have been normalized to \\([0, 1]\\). It is noted that the metric corresponds to phase transitions in several complex systems (citations omitted in quote):\n This measure \\(C\\) of complexity is maximal at phase transitions in random Boolean networks, the Ising model, and other dynamical systems characterized by criticality.\n Bibliography Gershenson, Carlos. April 30, 2021. \"Emergence in Artificial Life\". arXiv:2105.03216 [Physics]. http://arxiv.org/abs/2105.03216.","title":"Emergence in artificial life by Gershenson, C. (2021)","url":"https://hugocisneros.com/notes/gershensonemergenceartificiallife2021/"}
    
    , 
    
    {"body":" tags Computer science resources Tyler Neylon\u0026rsquo;s blog  ","title":"Locality-Sensitive Hashing","url":"https://hugocisneros.com/notes/locality_sensitive_hashing/"}
    
    , 
    
    {"body":" tags Generative modelling  ","title":"Diffusion models","url":"https://hugocisneros.com/notes/diffusion_models/"}
    
    , 
    
    {"body":" tags Neural networks, Generative modelling  Generative adversarial networks are a type of generative model. It is close in spirit to Variational autoencoders, but has key differences. The main one is the way the model is trained, which uses an adversarial equilibrium between training a generator and training a discriminator.\nAre GANs glorified PCA? (Richardson and Weiss 2020) This paper seems to show that image-to-image translation models are ill-posed and imply the image transformation should always be very local.\nThe authors propose a simple linear model for solving complex image-to-image translation tasks which seems to yield competitive results.\nBibliography Richardson, Eitan, and Yair Weiss. July 24, 2020. \"The Surprising Effectiveness of Linear Unsupervised Image-to-Image Translation\". arXiv:2007.12568 [Cs]. http://arxiv.org/abs/2007.12568.","title":"Generative adversarial networks","url":"https://hugocisneros.com/notes/generative_adversarial_networks/"}
    
    , 
    
    {"body":" tags Machine learning  ","title":"Generative modelling","url":"https://hugocisneros.com/notes/generative_modelling/"}
    
    , 
    
    {"body":" tags Physics, Philosophy resources Juergen Schmidhuber\u0026rsquo;s page, (Schmidhuber 1999)  Zuse\u0026rsquo;s thesis is the idea that the Universe could be running within a digital computer. It was formulated by Konrad Zuse in Rechnender Raum (Calculating Space) in 1969. The computer could be a very large Cellular automaton according to Zuse.\nA computer program to simulate our Universe (and all the others)  Systematically create and execute all programs for a universal computer, such as a Turing machine or a CA; the first program is run for one instruction every second step on average, the next for one instruction every second of the remaining steps on average, and so on.\n/Juergen Schmidhuber in (Schmidhuber 1999)\n The need for interlacing computations like this is to avoid the halting problem if we were to wait for any of these programs to finish.\nBibliography Schmidhuber, Juergen. April 13, 1999. \"A Computer Scientist’s View of Life, the Universe, and Everything\". arXiv:Quant-Ph/9904050. http://arxiv.org/abs/quant-ph/9904050.","title":"Zuse's thesis","url":"https://hugocisneros.com/notes/zuse_s_thesis/"}
    
    , 
    
    {"body":" tags Machine learning  In reinforcement learning, agents take actions within an environment. Usually, both the agent and environment states change in reaction to this action. A reward is given to the agent to tell it if the action was positive or negative.\nThe goal of a learning agent is to act so as to maximize that reward.\nAn agent can be anything from a fixed set of if-else statements to a deep neural network.\nAlgorithms Q-learning A3C TRPO PPO SAC Evolutionary strategies in RL A survey of evolutionary strategies for RL (Müller and Glasmachers 2018).\nOther/Misc algorithms, hacks and tricks Current RL is full of tricks to make the algorithms behave the way we want them to. It is not clear if the algorithms are getting better overall thanks to that collection of tricks or if this makes them over-specialized for a particular type of application.\nExploration bonuses Exploration bonuses are a class of methods that encourage an agent to explore even when the environment reward is sparse. This is done by adding an extra reward term. This may help an agent explore more states that are visually different from the ones before, or with different histories, etc.\nAn example of exploration bonus using random network distillation (Burda et al. 2018).\nBibliography Burda, Yuri, Harrison Edwards, Amos Storkey, and Oleg Klimov. 2018. \"Exploration by Random Network Distillation\". arXiv Preprint arXiv:1810.12894. Müller, Nils, and Tobias Glasmachers. July 1, 2018. \u0026ldquo;Challenges in High-Dimensional Reinforcement Learning with Evolution Strategies\u0026rdquo;. arXiv:1806.01224 [Cs]. http://arxiv.org/abs/1806.01224.\n","title":"Reinforcement learning","url":"https://hugocisneros.com/notes/reinforcement_learning/"}
    
    , 
    
    {"body":" tags Machine learning, Neural networks, Transfer learning  Distillation is used to describe the process of transferring performances from a large trained teacher neural network to a untrained student network.\nInstead of training the target network to score best according the task\u0026rsquo;s loss function, distillation optimizes for the target network to match the output distribution or neuron activation patterns of the teacher network.\nA review: (Beyer et al. 2021).\nBibliography Beyer, Lucas, Xiaohua Zhai, Amélie Royer, Larisa Markeeva, Rohan Anil, and Alexander Kolesnikov. June 9, 2021. \"Knowledge Distillation: A Good Teacher Is Patient and Consistent\". arXiv:2106.05237 [Cs]. http://arxiv.org/abs/2106.05237.","title":"Distillation","url":"https://hugocisneros.com/notes/distillation/"}
    
    , 
    
    {"body":" tags Machine learning  ","title":"Transfer learning","url":"https://hugocisneros.com/notes/transfer_learning/"}
    
    , 
    
    {"body":" tags Mathematics  Machine learning for theorem proving ","title":"Automated theorem proving","url":"https://hugocisneros.com/notes/automated_theorem_proving/"}
    
    , 
    
    {"body":" tags Neural networks  Implementation Self-attention is a weighted average of all input elements from a sequence, with a weight proportional to a similarity score between representations. The input \\(x \\in \\mathbb{R}^{L \\times F}\\) is projected by matrices \\(W_Q \\in \\mathbb{R}^{F \\times D}\\), \\(W_K \\in \\mathbb{R}^{F\\times D}\\) and \\(W_V \\in \\mathbb{R}^{F\\times M}\\) to representations \\(Q\\) (queries), \\(K\\) (keys) and \\(V\\) (values).\n\\[ Q = xW_Q\\] \\[ K = xW_K\\] \\[ V = xW_V\\]\nOutput for all positions in a sequence \\(x\\), is written\n\\[A(x) = V' = \\text{softmax}\\left( \\dfrac{QK^{T}}{\\sqrt{D}} \\right) V.\\]\nThe softmax is applied row-wise in the equation above.\nPossible interpretation Keys and queries have a relatively simple interpretation. The keys are embeddings of tokens that expose some useful information about them:\nThe key \\(K_3\\) associated with cat should probably encode some information about the fact that it\u0026rsquo;s a noun, that it refers to a living entity, an animal, etc. On the other hand, the key \\(K_2\\) encodes the fact that pretty is an adjective, and is used to denote some positive things about the subject\u0026rsquo;s appearance. That key is probably close to keys for beautiful and nice.\n The query encodes another type of information about what types of keys would be useful for that particular token. In the case of query \\(Q_3\\) it is probably useful to attend to any adjective-like key that could show something interesting about the current word. Therefore, the quantity \\(\\text{softmax}\\left( \\dfrac{QK^{T}}{\\sqrt{D}} \\right)\\) will be larger and will contribute more heavily in the resulting vector \\(V'\\). This is illustrated in the graph above with heavier edges.\nIs it necessary? Maybe not (Zhai et al. 2021).\nBibliography Zhai, Shuangfei, Walter Talbott, Nitish Srivastava, Chen Huang, Hanlin Goh, Ruixiang Zhang, and Josh Susskind. May 28, 2021. \"An Attention Free Transformer\". arXiv:2105.14103 [Cs]. http://arxiv.org/abs/2105.14103.","title":"Attention","url":"https://hugocisneros.com/notes/attention/"}
    
    , 
    
    {"body":"Genetic algorithms can be used as optimization algorithms for search problems, where usual optimization techniques such as gradient-based ones aren\u0026rsquo;t very effective.\nThese methods are loosely based on evolution in biological life, implementing a limited form variation and selection to progress towards better fitness (measured by a specific fitness function).\nNew candidate solutions for a problem are constructed by randomly combining and mutating parent solutions. The best candidate are kept and become parents of the next generation.\n","title":"Genetic algorithms","url":"https://hugocisneros.com/notes/genetic_algorithm/"}
    
    , 
    
    {"body":" tags Machine learning Many people, including Geoffrey Hinton, have raised concerns about the back-propagation algorithm and the fact that it\u0026rsquo;s likely not a promising way to achieve Artificial Intelligence (see this Axios blog post).\n  Alternative mechanisms for learning have been and are currently studied to try and approach the learning problem in a more effective way.\nDirect feedback alignment (Nøkland 2016)\nHebbian learning The theory is sometimes summarized as \u0026ldquo;Cells that fire together wire together.\u0026rdquo;.\nPredictive coding (Whittington and Bogacz 2017; Millidge, Tschantz, and Buckley 2020)\nBibliography Millidge, Beren, Alexander Tschantz, and Christopher L. Buckley. October 5, 2020. \"Predictive Coding Approximates Backprop along Arbitrary Computation Graphs\". arXiv:2006.04182 [Cs]. http://arxiv.org/abs/2006.04182. Whittington, James C. R., and Rafal Bogacz. May 2017. \u0026ldquo;An Approximation of the Error Backpropagation Algorithm in a Predictive Coding Network with Local Hebbian Synaptic Plasticity\u0026rdquo;. Neural Computation 29 (5):1229–62. DOI.\nNøkland, Arild. December 21, 2016. \u0026ldquo;Direct Feedback Alignment Provides Learning in Deep Neural Networks\u0026rdquo;. arXiv:1609.01596 [Cs, Stat]. http://arxiv.org/abs/1609.01596.\n","title":"Alternative learning mechanisms","url":"https://hugocisneros.com/notes/alternative_learning_mechanisms/"}
    
    , 
    
    {"body":" tags Cellular automata resources Wolfram Mathworld, Wikipedia  ECA are one of the simplest form of 1D cellular automata possible. The grid is a 1-dimensional array of cells in state 0 or 1 (dead or alive). The size of the neighborhood being used for the update is 3 (one cell to the left, the main cell and one cell to the right).\nEach of those \\(2^3\\) neighborhoods of size 3 can be mapped to either state 1 or 0. There are \\(2^{2^3} = 2^8 = 256\\) possible mappings and therefore 256 possible ECA rules.\nFrom this very simple definition, rules with various unexpected behavior emerge. Wolfram constructed a classification of those behavior, known as Wolfram\u0026rsquo;s classification (Wolfram 2002).\nSimple implementation In Python, taking advantage of Numpy\u0026rsquo;s array manipulation. This implementation is much faster than looping through elements of the grid to update them, but uses slightly more memory. The algorithm is simply based on the standard ECA update.\nimport numpy as np import matplotlib import matplotlib.pyplot as plt fig, ax = plt.subplots(figsize=(3,2)) N = 100 # Number of cells in the cellular automaton T = 50 # Number of steps to run for rule = 54 # Rule code rule_list = bin(rule)[2:] # Zero padding of the rule rule_list = [0] * (8 - len(rule_list)) + [int(i) for i in rule_list] # Convert to array and reverse the list rule_array = np.array(rule_list[::-1]) # Initial state init = np.random.randint(2, size=N) # We initialize a grid with T rows and N columns grid = np.zeros((T, N), dtype=np.int) grid[0, :] = init for i in range(1, T): next_step = rule_array[np.roll(grid[i-1, :], -1) + 2 * grid[i-1, :] + 4 * np.roll(grid[i-1, :], 1)] grid[i, :] = next_step # Plotting the results ax.matshow(grid, cmap=\u0026#39;Greys\u0026#39;) fig.tight_layout() fig.savefig(\u0026#39;img/plots/ca_rule54.png\u0026#39;) Results:\n Bibliography Wolfram, Stephen. 2002. _A New Kind of Science_. Champaign, IL: Wolfram Media. https://www.wolframscience.com/nks/.","title":"Elementary cellular automata","url":"https://hugocisneros.com/notes/elementary_cellular_automata/"}
    
    , 
    
    {"body":" tags Emacs, Org-mode website Org-roam  Org-roam is an org-mode package that implements features similar to Roam research:\n Bi-directional links between notes \u0026mdash; a link from a note to another note is also a \u0026ldquo;backlink\u0026rdquo; from the latter to the former. Possibility to reference whole notes or subtrees transparently Citation and references as links And many others  ","title":"Org-roam","url":"https://hugocisneros.com/notes/org_roam/"}
    
    , 
    
    {"body":" tags Writing  ","title":"Roam research","url":"https://hugocisneros.com/notes/roam_research/"}
    
    , 
    
    {"body":" tags Emacs, Writing  Org is a markup language similar to Markdown. It was designed to be used in the Emacs editor, which offers special features for working with files in the Org format.\nOrg mode can be used as an agenda, task manager, writing and publishing tool, and many other things. Extensions in the form of Emacs package offer even more features to make org-mode more powerful.\n","title":"Org-mode","url":"https://hugocisneros.com/notes/org_mode/"}
    
    , 
    
    {"body":"Artificial life could be thought of as attempts at re-creating biological Life or other types of life. It uses different tools such as biology, physics, chemistry, computer science, etc.\nCreating artificial life seems like a possible way to create AI, since most living systems on Earth seem to exhibit some form of robust intelligent behavior.\nDefinition of artificial life from Carlos Gershenson in (Gershenson 2021)\n Beginning in the mid-1980s, ALife has studied living systems using a synthetic approach: building life to understand it better (Aguilar et al. 2014). By having more precise control of ALife systems than in biological systems, we can study emergence in ALife. With this knowledge, we can go back to biology.Then, emergence might actually become useful to understand life.\n Bibliography Aguilar, Wendy, Guillermo Santamaría-Bonfil, Tom Froese, and Carlos Gershenson. 2014. \"The Past, Present, and Future of Artificial Life\". Frontiers in Robotics and AI 1. Frontiers. DOI. Gershenson, Carlos. April 30, 2021. \u0026ldquo;Emergence in Artificial Life\u0026rdquo;. arXiv:2105.03216 [Physics]. http://arxiv.org/abs/2105.03216.\n","title":"Artificial life","url":"https://hugocisneros.com/notes/artificial_life/"}
    
    , 
    
    {"body":" tags Computability theory  A function on the natural numbers can be computed effectively if and only if it can be computed by a Turing Machine (or any equivalent computational model).\nImplications for Zuse\u0026rsquo;s thesis An interesting implication of the Church-Turing thesis is any Turing-complete computational model could in theory be \u0026ldquo;computing\u0026rdquo; our Universe. However, the constant overhead of running this algorithm is very different from one model to another. There must be an optimal or close to optimal computational model for simulating life processes and it seems from everyday observation that it should be inherently parallel.\n","title":"Church-Turing thesis","url":"https://hugocisneros.com/notes/church_turing_thesis/"}
    
    , 
    
    {"body":" tags Complexity, Philosophy source (Anderson 1972)  This is a fundamental paper discussing the fundamental laws of Physics and their relations with complexity.\nReductionism doesn\u0026rsquo;t imply constructionism It is generally accepted that the fundamental laws governing our Universe are relatively simple. We feel we understand many of these laws quite well. However, understanding these fundamental laws are far from enough to actually describe and reconstruct all phenomena we witness.\n The main fallacy in this kind of thinking is that the reductionist hypothesis does not by any means imply a \u0026ldquo;constructionist\u0026rdquo; one: The ability to reduce everything to simple fundamental laws does not imply the ability to start from those laws and reconstruct the universe. In fact, the more the elementary particle physicists tell us about the nature of fundamental laws, the less relevance they seem to have to the very real problems of the rest of science, much less to those of society.\n Whenever we change scale, although the same fundamental laws still apply, entirely new properties and behavior emerge. Understanding those requires extensive research that Anderson feels is as fundamental as any. This interesting charts taken from the article illustrates how scale change affects the way we study phenomena:\n   X Y      Solid-state or many body physics Elementary particle physics   Chemistry Many-body physics   Molecular biology Chemistry   Cell biology Molecular biology   … …   Psychology Physiology   Social sciences Psychology    Comments This paper is without a doubt a major work \u0026mdash; I\u0026rsquo;m certainly not the first to say this. I believe this paradigm shift the author advocates has profoundly changed many areas of science and humanities \u0026mdash; and is still having a great impact.\nThe fact that profound changes of dynamics occur when changing scale is key to understanding nature and the seemingly strange laws which govern it. I also believe that we will never achieve anything close to open-ended Evolution, artificial life or even artificial Intelligence if we cannot re-create the conditions for this phenomena to happen. Obviously, this doesn\u0026rsquo;t say anything about what we should create, but I think that once we observe this in an artificial system, we will be a lot closer to the goal.\nBibliography Anderson, P. W.. August 4, 1972. \"More Is Different\". Science 177 (4047). American Association for the Advancement of Science:393–96. DOI.","title":"More Is Different by Anderson, P. W. (1972)","url":"https://hugocisneros.com/notes/andersonmoredifferent1972/"}
    
    , 
    
    {"body":" tags Artificial life, Emergence resources (Gershenson 2021)  Bibliography Gershenson, Carlos. April 30, 2021. \"Emergence in Artificial Life\". arXiv:2105.03216 [Physics]. http://arxiv.org/abs/2105.03216.","title":"Emergence in artificial life","url":"https://hugocisneros.com/notes/emergence_in_artificial_life/"}
    
    , 
    
    {"body":" tags Hopfield Networks, Attention source (Ramsauer et al. 2020) resources Blog post  Summary This quote summarizes the paper well: \u0026ldquo;In order to integrate modern Hopfield networks into deep learning architectures, we have to make them continuous\u0026rdquo;.\nComments Bibliography Ramsauer, Hubert, Bernhard Schäfl, Johannes Lehner, Philipp Seidl, Michael Widrich, Lukas Gruber, Markus Holzleitner, et al.. July 16, 2020. \"Hopfield Networks Is All You Need\". arXiv:2008.02217 [Cs, Stat]. http://arxiv.org/abs/2008.02217.","title":"Hopfield Networks is All You Need by Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P.,...","url":"https://hugocisneros.com/notes/ramsauerhopfieldnetworksall2020/"}
    
    , 
    
    {"body":" tags Compression, Complexity papers (Lempel and Ziv 1976; Ziv and Lempel 1977, 1978; 1984; Storer and Szymanski 1982)  Context The LZW algorithm was originally designed as a complexity (\u0026ldquo;randomness\u0026rdquo;) metric for finite sequences (Lempel and Ziv 1976). It was then extended as a compression algorithm by the same authors to LZ77 (Ziv and Lempel 1977) and LZ78 (Ziv and Lempel 1978). Those last two are the basis of many well known and widely used compression utilities such as GIF, compress (LZW (1984) ) or DEFLATE, gzip (LZSS (Storer and Szymanski 1982)), etc.\nDescription The base idea of these algorithms is to build a dictionary of words in the input sequence. A given sequence is scanned and an empty dictionary is initialized. Each new word is the shortest next word not in the dictionary. It is registered by using a previous word and adding a single digit in the form \\((j, s_{last})\\). This encoding allows a unique decoding of the original sequence. When encoding or decoding the string the same dictionary of words is built. For sequences with string repetitions, the length of each new word increases fast and the numbers of needed pairs to encode increases very slowly.\nExample implementation of the LZ algorithm in Python:\ndef compress(string): dic = {\u0026#39;0\u0026#39;: 0, \u0026#39;1\u0026#39;: 1} word = \u0026#34;\u0026#34; result = [] for c in string: wc = word + c if wc in dic: word = wc else: result.append(dic[word]) dic[wc] = len(dic) word = c if word: result.append(dic[word]) return result print(compress(\u0026#34;1101010101011101010001110100\u0026#34;)) print(compress(\u0026#34;1010101010101010101010101010\u0026#34;)) Results:\n[1, 1, 0, 3, 5, 4, 4, 2, 7, 3, 0, 8, 6, 0] [1, 0, 2, 4, 3, 6, 5, 8, 7, 6] Bibliography Lempel, A., and J. Ziv. January 1976. \"On the Complexity of Finite Sequences\". IEEE Transactions on Information Theory 22 (1):75–81. DOI. Storer, James A., and Thomas G. Szymanski. October 1982. \u0026ldquo;Data Compression via Textual Substitution\u0026rdquo;. Journal of the ACM (JACM) 29 (4):928–51. DOI.\nZiv, J., and A. Lempel. May 1977. \u0026ldquo;A Universal Algorithm for Sequential Data Compression\u0026rdquo;. IEEE Transactions on Information Theory 23 (3):337–43. DOI.\n———. September 1978. \u0026ldquo;Compression of Individual Sequences via Variable-Rate Coding\u0026rdquo;. IEEE Transactions on Information Theory 24 (5):530–36. DOI.\nJune 1984. \u0026ldquo;A Technique for High-Performance Data Compression\u0026rdquo;. Computer 17 (6):8–19. DOI.\n","title":"Lempel-Ziv-Welch algorithm","url":"https://hugocisneros.com/notes/lempel_ziv_welch_algorithm/"}
    
    , 
    
    {"body":" source (Aach, Goebbert, and Jitsev 2021) tags Cellular automata, Neural networks  Summary This paper studies the generalization abilities of neural networks on tasks involving learning the dynamics of cellular automata rules from examples.\nNeural networks are trained to predict the next state of a CA from the three previous timesteps. Different training examples for a single rule corresponds to different initialization.\nThe authors study three kinds of generalization:\n Simple generalization: The network is trained on 300 different CA rules and tested on more unseen initial configurations from those 300 rules. Level 1 generalization: Same setup as above but the rules have variable sized neighborhoods Level 2 generalization: The network is trained on 300 rules with different neighborhoods sizes and tested on new initial configurations and 30 new rules. Level 3 generalization: This level has two setups  Interpolation: train on rules with neighborhoods \\(3\\times 3\\), \\(5 \\times 5\\) and \\(9 \\times 9\\) and evaluate on rules with neighborhood \\(7 \\times 7\\) Extrapolation: train on rules with neighborhoods \\(3\\times 3\\), \\(5 \\times 5\\) and \\(7 \\times 7\\) and evaluate on rules with neighborhood \\(9 \\times 9\\)    The neural network used is an encoder-decoder architecture, with convolutions and down-sampling to convert input states into a low dimensional vector and convolutions + up-sampling to convert it back to the next predicted state.\nFor training and validation, all configurations above reach more than 90% accuracy. For the simple and level 1 generalizations (same CA rules), the test accuracy is also very high (\u0026gt; 90%). The test accuracy drops significantly for Level 2 and 3, where the network probably has trouble inferring the rule from the 4 previous steps only, whereas before it could have memorized those rules during training.\nBibliography Aach, Marcel, Jens Henrik Goebbert, and Jenia Jitsev. March 27, 2021. \"Generalization over Different Cellular Automata Rules Learned by a Deep Feed-Forward Neural Network\". arXiv:2103.14886 [Nlin]. http://arxiv.org/abs/2103.14886.","title":"Generalization over different cellular automata rules learned by a deep feed-forward...","url":"https://hugocisneros.com/notes/aachgeneralizationdifferentcellular2021/"}
    
    , 
    
    {"body":" tags Machine learning, Applied maths  ","title":"Generalization in Machine learning","url":"https://hugocisneros.com/notes/generalization_in_machine_learning/"}
    
    , 
    
    {"body":" tags Artificial Intelligence, Genetic algorithms, Open-ended Evolution source (Clune 2019)  Summary Nowadays, the design of AI systems is approached through one main way (more or less): the implementation of some elementary building blocks \u0026mdash; like convolutions, skip connections, activation functions, attention, etc. We currently have no clear idea how to combine these relatively successful blocks into a global system that would take advantage of each and every one of them.\nIn essence, Darwinian evolution is a form of algorithm that moved its way up from the simplest replicators to the human mind. It is probably not a very smart algorithm, but it was given an unfathomable amount of computation. The question of computation is therefore still open.\nThere would be three pillars for AI-GA:\nMeta-learning architectures This part is related to Neural architecture search: algorithms learn to create the learning architectures.\nMeta-learning the learning algorithms themselves This part wants to avoid learning algorithms such as SGD and instead learn them directly. Ex: Model Agnostic Meta Learning (MAML) aims at finding an initial set of weights that is the fastest at learning a range of tasks.\nAnother idea is to use RNN (Turing complete) trained via an outer loop optimization algorithm to be the most sample-efficient learning algorithm and use it then to train other models. This has been done in (Wang et al. 2017) and (Duan et al. 2016) in the context of Reinforcement learning, with policy gradients as the outer loop (in nature this would be the role of evolution).\nThe main question with meta-learning is: what tasks should the meta-learner learn on ? The author argues that can be learned too.\nAutomatically generating effective learning environments We should have algorithms that can learn to generate learning environments. This includes defining a reward in this environment. This is likely the hardest of the three pillars. This is what people attempt at reproducing in Alife simulations, coevolution, self-play (Dota, Go, etc.). They all more or less fail to create this open-ended complexity explosion like what happened on Earth. This is usually due to the fact that the environmental component of the algorithm is not evolving.\nThe authors suggests to focus on explicitly optimizing for environments that favor learning instead of hoping we can create environments that create dynamics that can lead to evolutionary explosions. The author sees open-ended evolution as a way to generate endlessly environments that are growing in complexity. This can be related in natural evolution to the active process of creating new species and niche, where the new species create more complex environments that can in turn create new even more complex creatures.\nThe author explicitly avoids the term evolutionary approach for AI-GAs because he argues that the outer-loop optimization method doesn\u0026rsquo;t have to be evolution and can rather be some other optimization algorithms.\nAccording to the authors, interesting path to this 3rd pillar include:\n Encouraging behavioral diversity (like Novelty search or Curiosity  search).\n Quality diversity, meaning that the algorithm should be able to generate  many solutions to a problem where each of those solutions is as high performing as possible for its type (or species) this is related to MAP-elites.\nThe authors believe that POET is a step in that direction.\nThe rest of the paper is a long discussion about the pros and cons of the method and potential ways it could be used/useful.\nComments This work resonates well with many of my opinions about the current state of machine learning research and its relation to AI research in general.\nI believe the 3rd pillar, which is the generation of effective learning environments is indeed the hardest and I even think that it is AI complete: meaning this would in itself be a sufficient to have AI. This is also because pillar 3 would necessitate open-ended evolution to work which is in my opinion AI-complete. Without even mentioning effectiveness.\nOverall, the goal and means to get to this goal seem very close to what many researchers are envisioning too, and I agree. However, these solutions don\u0026rsquo;t seem very promising to me , because the very system the author thinks could be generating this endless variety of environments is still undefined and remains the hardest part of the problem.\nBibliography Duan, Yan, John Schulman, Xi Chen, Peter L. Bartlett, Ilya Sutskever, and Pieter Abbeel. November 9, 2016. \"RL\\\\(^2\\\\): Fast Reinforcement Learning via Slow Reinforcement Learning\". arXiv:1611.02779 [Cs, Stat]. http://arxiv.org/abs/1611.02779. Wang, Jane X., Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel Z. Leibo, Remi Munos, Charles Blundell, Dharshan Kumaran, and Matt Botvinick. January 23, 2017. \u0026ldquo;Learning to Reinforcement Learn\u0026rdquo;. arXiv:1611.05763 [Cs, Stat]. http://arxiv.org/abs/1611.05763.\nClune, Jeff. May 27, 2019. \u0026ldquo;AI-GAs: AI-Generating Algorithms, an Alternate Paradigm for Producing General Artificial Intelligence\u0026rdquo;. arXiv:1905.10985 [Cs]. http://arxiv.org/abs/1905.10985.\n","title":"AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial...","url":"https://hugocisneros.com/notes/cluneaigasaigeneratingalgorithms2019/"}
    
    , 
    
    {"body":" tags Mathematics  LU Factorization  resources Nick Higham\u0026rsquo;s blog  An LU factorization of a \\(n \\times n\\) matrix \\(A\\) is a factorization \\(A = LU\\), where \\(L\\) is lower triangular and \\(U\\) is upper triangular\nLUP factorization LU factorization with partial pivoting: \\(PA = LU\\) with \\(P\\) a permutation matrix.\nLDU factorization Lower-diagonal upper factorization: \\(A = LDU\\) with \\(D\\) a diagonal matrix and \\(L\\) and \\(U\\) are uni-triangular (triangular with diagonal one).\n","title":"Matrix factorization","url":"https://hugocisneros.com/notes/matrix_factorization/"}
    
    , 
    
    {"body":" tags Mathematics  ","title":"Moore-Penrose inverse","url":"https://hugocisneros.com/notes/moore_penrose_inverse/"}
    
    , 
    
    {"body":" tags Physics, Applied maths, Neural networks resources Scholarpedia  Attractor networks are sets of nodes connected in such a way that their dynamics are stable in a small subspace of their phase space. The network state usually resides on this smaller manifold after a few evolution steps.\nThese networks are often recurrent.\n","title":"Attractor networks","url":"https://hugocisneros.com/notes/attractor_networks/"}
    
    , 
    
    {"body":" tags Complex Systems  A generalization of Cellular automata Boolean networks could be seen as CA generalization with any topology (not necessarily 1D or 2D). In the standard model, each node of the network is assigned a rule randomly chosen from the \\(2^{2^k}\\) possible ones with K inputs.\nLike for cellular automata, cells (or nodes) don\u0026rsquo;t have to be in just two states (although the name Boolean no longer holds) and updates can be done either synchronously or asynchronously.\nRandom Boolean networks Stuart Kauffman was the first to use Random Boolean networks (RBNs) in 1969 to model the dynamics of genetic and protein networks. A RBN is a random choice among all possible BNs of size \\(N\\).\n","title":"Boolean networks","url":"https://hugocisneros.com/notes/boolean_networks/"}
    
    , 
    
    {"body":"Cellular automata have been used a lot to create various forms of Generative art.\nHere is a collection of some interesting examples:\nExamples based on Neural CA  Self organizing textures: (Niklasson et al. 2021) Dialogue: an art project using interacting Neural CA to generate patterns  Revisiting classical CA  Crosshatch CA  CA Music  Wolfram tones  Bibliography Niklasson, Eyvind, Alexander Mordvintsev, Ettore Randazzo, and Michael Levin. February 11, 2021. \"Self-Organising Textures\". Distill 6 (2):e00027–003. DOI.","title":"Art with Cellular Automata","url":"https://hugocisneros.com/notes/art_with_cellular_automata/"}
    
    , 
    
    {"body":"","title":"Generative art","url":"https://hugocisneros.com/notes/generative_art/"}
    
    , 
    
    {"body":" tags Artificial life, Evolution  Avida is an Artificial life system inspired by Tierra which uses computer programs as individuals.\nOne interesting advantage of this system is the possibility to measure the complexity of organisms easily. This is done by counting the number of instructions in their computer program.\n","title":"Avida","url":"https://hugocisneros.com/notes/avida/"}
    
    , 
    
    {"body":" tags Computer science  Hash functions map variable sized inputs to a finite set of outputs.\nThey need to have a range of properties such as:\n Determinism: The output of a hash function should be the same every time for each input. Universality: Two inputs should have a probability of getting the same hash as close to \\(1/n\\) as possible, where \\(n\\) is the size of the output set. This is the minimum number of collisions.  They are essentials to many algorithms and applications in Cryptography, Data storage (hash tables and bloom filters), compression, proofs of work, file checksums, etc.\n","title":"Hash functions","url":"https://hugocisneros.com/notes/hash_functions/"}
    
    , 
    
    {"body":" tags Evolution, Complexity, Artificial Intelligence resources Open-endedness: The last grand challenge you’ve never heard of  My idea of Open Ended evolution As part of my research, I have been thinking a lot about open-ended evolution and what this concept means to me. Although it is still early in my research journey, I will go into the process of writing down my thoughts about this very challenging concept in order to have material on which I will be able to reflect later and understand how my beliefs have changed.\nI see open-ended evolution (OEE) as the holy grail of Artificial life (and maybe Artificial Intelligence) research. The only manifestation of intelligence we know of has emerged through a long and complex process, which inner workings we seem to understand. This process is often called evolution and sometimes reduced to one of its components: Natural Selection. Evolution obviously encompasses much more, starting from the process through which new characters and behaviors can emerge.\nWhen people from the computer science community refer to OEE, they usually mean artificial OEE. That is, the creation of artificial systems (usually computer simulations?) that can exhibit the same properties as natural evolution. The main problem is: What are those properties?. I know many researchers have spent a lot of time figuring this out, and this part of the problem is certainly the most important one. As Hiroki Sayama once told me, citing another Alife researcher: Give me a definition of OEE and I can build it. Here are some properties I would expect from an open-ended system from the top of my head:\n Ability to grow in complexity. From a given state of the system, we can expect it to grow in complexity by building on previous complexity and adding innovations. This is probably the biggest open question, because although we can easily think about systems that keep generating novel things, we don\u0026rsquo;t know if they can grow in complexity. And even for things where there is evidence that it is possible, we don\u0026rsquo;t know how efficient they are. Adaptability to new environmental conditions. The system should have some amount of plasticity, or capability to change its internal functions in response to a change in external conditions. It is hard to tell if this is just a spontaneous property of systems satisfying the condition above or something more? Ability to communicate information to the outside of the system (this is not required for any OEE system per se but necessary if we want to be able to get something out of the simulation). One could also argue that complexity means nothing without an observer.  This list is certainly not complete, and probably not correct. But I believe these objectives are already hard enough to make the scientific challenge they represent exciting. I believe the cellular automata I am studying have the potential to qualify for the first property and the third. However, it is still not clear how efficient this can be and if it is within reach.\nInteresting idea about open-endedness Interesting idea presented in a paper by Sayama and Pattee (Pattee and Sayama 2019).\nBibliography Pattee, Howard H., and Hiroki Sayama. April 2019. \"Evolved Open-Endedness, Not Open-Ended Evolution\". Artificial Life 25 (1):4–8. DOI.","title":"Open-ended Evolution","url":"https://hugocisneros.com/notes/open_ended_evolution/"}
    
    , 
    
    {"body":" tags Cryptography, Computer science resources Wikipedia  A number that represents some information which is illegal to posses or transmit, making said number technically illegal. It can also refer to numbers that have a particular meaning or connotation that a government wishes to censor.\nWhen focusing on some specific class of numbers one could create funny illegal numbers such as:\n Illegal primes Illegal Pythagorean triples Illegal triangular numbers Illegal Fibonacci numbers etc. This could be declined for any infinite sequence of numbers in which you could encode such illegal information.  Interestingly, there has to be some criterion on whether this information is easily recovered from its encoded form. Otherwise any normal number would qualify as illegal, maybe even \\(\\pi\\).\nIn practice this notion of making numbers illegal makes little sense. For example, one could always evade countermeasures by changing a few bits in the underlying data or source code and use that new number. One can also use various compression, or simple encryption methods (rot13) to change the data enough that it can be easily recovered but represents a completely different number. Most attempts at censoring numerical data have hardly succeeded because it is relatively easy to change their representation.\nOf course because of the nature of numerical data, illegal numbers can be encoded into images, videos, text, or any data format making it very hard to actually enforce their illegality.\n","title":"Illegal numbers","url":"https://hugocisneros.com/notes/illegal_numbers/"}
    
    , 
    
    {"body":" tags Machine learning, Artificial Intelligence author Richard Sutton resources Link  The Bitter Lesson is a pattern that can be observed in several areas of machine learning: many hard problems involving some form of artificial intelligence have seen dramatic progress at some point in the last 50 years, which was mostly driven by data and computations as opposed to \u0026ldquo;clever\u0026rdquo; human engineering.\nIf this trend is a fundamental principle (which is what the article argues) it would mean that most of the time spent on engineering features and task-specific representations is wasted. An automatically learning system such has a neural network will eventually have more success provided enough data is available to train it.\n","title":"The Bitter Lesson","url":"https://hugocisneros.com/notes/the_bitter_lesson/"}
    
    , 
    
    {"body":"","title":"Richard Sutton","url":"https://hugocisneros.com/notes/richard_sutton/"}
    
    , 
    
    {"body":" tags Writing  Note-taking in Emacs with org-roam ","title":"Note-taking","url":"https://hugocisneros.com/notes/note_taking/"}
    
    , 
    
    {"body":" tags Artificial Intelligence source (Brooks 1991)  Summary What is intelligence Intelligence cannot be thought of as a collection of building blocks that may one fall into place to form a coherent whole.\nThe authors argue for another approach to build artificially intelligent systems:\n Build the systems incrementally, with complete systems each step of the way to ensure that the pieces and their interfaces are valid. Build intelligent systems at each step of the way that should be let loose in the real world with real sensing and action.   We have been following this approach and have built a series of autonomous mobile robots. We have reached an unexpected conclusion (C) and have a rather radical hypothesis (H).\n (C) When we examine very simple level intelligence we find that explicit representations and models of the world simply get in the way. It turns out to be better to use the world as its own model. (H) Representation is the wrong unit of abstraction in building the bulkiest parts of intelligent systems.   Creating intelligent systems The timeline of natural evolution seems to suggest that problem solving, language, expert knowledge, etc. are relatively simple to obtain once the core of the evolutionary machinery gets going and the essence of being in the environment is available. Natural evolution has spent most of its time developing the ability to move, interact and sense its environment, indicating it is probably the hardest part of the problem.\nBy concentrating on the end goal (human-level intelligence) and its most exceptional features (high-level intelligence) we may miss the most essential parts to building an AI system, which are also the hardest to develop. Moreover, we must forget about this single example of intelligence. This is to adopt a more bottom-up approach to recreating the processes that have led to it rather than replicating it.\nThis quote resonates with the open-endedness assumption that it is necessary to have no objective to reach hard goals.\n We do claim however, that there need be no explicit representation of either the world or the intentions of the system to generate intelligent behaviors for a Creature. Without such explicit representations, and when viewed locally, the interactions may indeed seem chaotic and without purpose.\n Comments This is an interesting paper which I believe is still relevant today. Brooks' conception of intelligence is in my opinion very interesting. He applies it to robots because this is probably the only approach if you consider this path to AI.\nHowever, it might be that the complexity needed to have the above interactions happen doesn\u0026rsquo;t have to be exogenous. A complex system, generating complex behavior on its own could be the source of chaotic interactions our AI system is based on (and could even be a part of)\nBibliography Brooks, Rodney A. 1991. \"Intelligence without Representation\". In Proceedings of the International Joint Conference on Artificial Intelligence, 1:12.","title":"Intelligence without representation by Brooks, R. A. (1991)","url":"https://hugocisneros.com/notes/brooksintelligencerepresentation1991/"}
    
    , 
    
    {"body":" tags Cellular automata papers (Chan 2019, 2020)  Lenia is a continuous cellular automaton. It is sometimes referred to as a \u0026ldquo;continuous Conway\u0026rsquo;s Game of Life\u0026rdquo;.\nBibliography Chan, Bert Wang-Chak. May 4, 2019. \"Lenia - Biology of Artificial Life\". arXiv:1812.05433 [Nlin]. http://arxiv.org/abs/1812.05433. ———. May 7, 2020. \u0026ldquo;Lenia and Expanded Universe\u0026rdquo;. arXiv:2005.03742 [Nlin]. http://arxiv.org/abs/2005.03742.\n","title":"Lenia","url":"https://hugocisneros.com/notes/lenia/"}
    
    , 
    
    {"body":" tags RNN, NLP source (Aitken et al. 2020)  Summary This paper takes a dynamical system based approach to study learning in RNNs. Gradient descent optimization in RNNs allows them to learn a simplified form of memory and information processing.\nThe authors use simple text classification tasks to try and understand if these learned properties can be understood by looking at the state dynamics of RNNs.\nThe RNNs usually behave like attractor networks, with the hidden state lying on a low-dimensional manifold.\nSynthetic data A first task is to classify sentences based on the number of evidence word corresponding to a target class. A simple solution to this problem is a counter which returns a class with the majority of evidence words.\nWith 3 classes, the learned neural network functions exactly like an integrator working mostly on a 2D equilateral triangle. Each evidence word moves the hidden state towards a corner of this triangle while neutral words don\u0026rsquo;t move the hidden state.\nFor varying number of classes \\(N\\), the authors show that \\(N-1\\) dimensions are mostly used for classification, explaining 95% of the variance of the hidden state.\nNatural data Interestingly, learned attractors are more or less similar with natural classification data. A RNN learns for each word a direction that will lead the hidden state towards the corresponding class.\nOrdered classification With the more involved task of ordered classification (star review prediction), RNN still learn low dimensional attractors. The integration is now apparently twofold: sentiment and intensity both play a role for the final score.\nMulti-label classification With multi-label classification, a RNN keeps track of all classes combinations like if they were different classes.\nComments I\u0026rsquo;m particularly interested in this kind of work trying to understand how these neural networks work. Gradient descent seems pretty good at finding shortcuts in data. This makes it particularly efficient for relatively simple tasks like sentence classification or relatively OK language modeling, but fails to construct more complex primitives or attractors.\nNeuroscience seems to have shown that at least parts of our brain functions use attractor dynamics like RNNs, but they likely weren\u0026rsquo;t found through the same kind of optimization.\nIt is interesting to think about this in connection with (Katharopoulos et al. 2020). This also mean that the powerful transformers also act like some kind of fancy integrator in a large space. It seems like this would be limiting their capabilities, since our brain doesn\u0026rsquo;t look like its only doing integration.\nBibliography Aitken, Kyle, Vinay V. Ramasesh, Ankush Garg, Yuan Cao, David Sussillo, and Niru Maheswaranathan. October 28, 2020. \"The Geometry of Integration in Text Classification RNNs\". arXiv:2010.15114 [Cs, Stat]. http://arxiv.org/abs/2010.15114. Katharopoulos, Angelos, Apoorv Vyas, Nikolaos Pappas, and François Fleuret. June 29, 2020. \u0026ldquo;Transformers Are RNNs: Fast Autoregressive Transformers with Linear Attention\u0026rdquo;. arXiv:2006.16236 [Cs, Stat]. http://arxiv.org/abs/2006.16236.\n","title":"The geometry of integration in text classification RNNs by Aitken, K., Ramasesh, V. V.,...","url":"https://hugocisneros.com/notes/aitkengeometryintegrationtext2020/"}
    
    , 
    
    {"body":"Creating artificial intelligence through evolution If we take an evolutionary approach to the creation of AI, we may run into some problems. Of course, it is an extremely appealing idea, as it has been proven to work in our \u0026ldquo;Earth experiment\u0026rdquo;. Somehow, life and intelligent behavior has emerged from the synergy between the emergence of so-called living systems, Darwinian evolution and interactions with the environment.\nHowever a crucial issue is: Is there any shortcut in this approach?. In other words, will we have to ultimately simulate a whole universe to achieve this seemingly open-ended evolution that led to what we think of as intelligence? It might seem unlikely, but it is possible that our particular configuration is miraculous and was the only one that could lead to where we are now.\n","title":"Artificial Intelligence","url":"https://hugocisneros.com/notes/artificial_intelligence/"}
    
    , 
    
    {"body":" tags NLP  The process of byte-pair encoding can be summarized as follow:\n Each character is a token Find pairs that occur most often Create a new token that encoded those common pairs Repeat the process until target vocabulary size is reached  The output of this process is both a vocabulary and a set of merging rules for tokens to be used to process more data.\nThis technique has many advantages:\n It is inexpensive It can deal with previously unseen words and make reasonable predictions about them if the token matches semantic information about the word.  For these reasons, this encoding method is currently the dominant one for transformers architecture.\n","title":"Byte-pair encoding","url":"https://hugocisneros.com/notes/byte_pair_encoding/"}
    
    , 
    
    {"body":" tags Computer science, Programming languages  ","title":"Coding","url":"https://hugocisneros.com/notes/coding/"}
    
    , 
    
    {"body":"Some essential components of computer security:\n Cryptography  ","title":"Computer security","url":"https://hugocisneros.com/notes/computer_security/"}
    
    , 
    
    {"body":" tags Machine learning, Image processing  ","title":"Computer vision","url":"https://hugocisneros.com/notes/computer_vision/"}
    
    , 
    
    {"body":" tags Neural networks, Genetic algorithms papers (Stanley 2007) resources Wikipedia  Bibliography Stanley, Kenneth O.. June 6, 2007. \"Compositional Pattern Producing Networks: A Novel Abstraction of Development\". Genetic Programming and Evolvable Machines 8 (2):131–62. DOI.","title":"CPPN","url":"https://hugocisneros.com/notes/cppn/"}
    
    , 
    
    {"body":" tags Applied maths, Physics  ","title":"Diffusion limited aggregation","url":"https://hugocisneros.com/notes/diffusion_limited_aggregation/"}
    
    , 
    
    {"body":" tags Complexity metrics references (Shannon and Weaver 1975)  For a discrete random variable \\(X\\) with outcomes \\(x_i\\), \\(P(X=x_i) = P_i\\), the entropy or uncertainty function of \\(X\\) is defined as \\[ H(X) = -\\sum_{i=1}^{N} P_i \\log P_i \\]\nEntropy is always positive, and is maximized when the uncertainty is maximal, that is when \\(P_1 = P_2 = \u0026hellip; = P_N = \\frac{1}{N}\\) entropy in that case is \\(\\log N\\).\nInterpretations:\n \\(H\\) measures uncertainty of a process (or the average number of yes/no answers one needs to specify the value of \\(i\\)). Average information received by an observer when reading the outcomes of \\(X\\).  If we encode the random variable \\(X\\) with an erroneous encoding \\(P_i'\\), the resulting code length is \\(\\sum P_i \\log \\frac{1}{P_i'}\\). The difference between this encoding and the optimal encoding is the Kullback-leibler divergence.\nShannon entropy for a sequence In the case of a sequence of symbols $s_1, \u0026hellip;, s_i, \u0026hellip;$, following a translation invariant distribution (for any \\(n\\) and \\(k\\), \\(P(s_1s_2\u0026hellip;s_n) = P(s_{1+k}s_{2+k}\u0026hellip;s_{n+k})\\)).\nWe can define the block entropy of the $n$-tuple random variable \\(S=(S_1\u0026hellip;S_n)\\) like above \\[ H_n = \\sum_{s_1\u0026hellip;s_n} P(s_1\u0026hellip;s_n) \\log P(s_1\u0026hellip;s_n) \\]\nThen, we can define the average length of the description per symbol of the sequence as \\[ h =\\lim_{n \\rightarrow \\infty} h_n \\] \\[ h_n =H_{n+1} - H_n \\]\n\\(h\\) is called by Shannon the entropy of the source emitting the sequence, or entropy of the sequence.\nBibliography Shannon, Claude E., and Warren Weaver. 1975. _The Mathematical Theory of Communication_. Urbana: University of Illinois Press.","title":"Entropy","url":"https://hugocisneros.com/notes/entropy/"}
    
    , 
    
    {"body":" tags Complexity, Algorithmic Information theory, Computability theory  Definition Invariance theorem For two descriptive languages \\(L_1\\) and \\(L_2\\) and their respective associated Kolmogorov complexity functions \\(K_1\\) and \\(K_2\\), there exist a constant \\(c\\) \u0026mdash; dependant only on \\(L_1, L_2\\) such that \\[ \\forall s, -c \\leq K_1(s) - K_2(s) \\leq c \\]\nIn other words, there is always a bounded difference between the Kolmogorov complexity in two separate description languages.\nThis is proven by using the fact that the two descriptive languages have to be Turing-complete and therefore there exists an interpreter in \\(L_1\\) for \\(L_2\\) of finite size \\(l\\).\nUncomputability Lemma There exist strings of arbitrarily large Kolmogorov complexity. Formally: for each \\(n \\in \\mathbb{N}\\), there is a string s with \\(K(s) \\geq n\\).\nProof: Otherwise infinitely many sequences would have finitely many generating programs.\nTheorem Kolmogorov complexity is not computable. There doesn\u0026rsquo;t exist a program that can compute for any string \\(s\\) the quantity \\(K(s)\\).\nProof: Let\u0026rsquo;s assume that a given description language (e.g. a common programming language) has an interepreter of size \\(I\\) in our Universal Turing machine and that there exist a program of lenght \\(N\\) that computes the Kolmogorov complexity of any string. We can write a program of fixed small size \\(S\\) that loops for each string of increasing length and stops when the result of the Kolmogorov complexity function is above \\(2*(N+I+S)\\).\nTherefore, we found a contradiction with a string which Kolmogorov complexity is actually smaller than what our supposed function outputed.\nUpper bound Kolmogorov complexity is upper bounded by\n","title":"Kolmogorov complexity","url":"https://hugocisneros.com/notes/kolmogorov_complexity/"}
    
    , 
    
    {"body":" tags Complexity, Algorithmic Information theory papers (Grunwald 2007, 2004)  Bibliography Grunwald, Peter. June 4, 2004. \"A Tutorial Introduction to the Minimum Description Length Principle\". arXiv:Math/0406077. http://arxiv.org/abs/math/0406077. ———. 2007. The Minimum Description Length Principle. Adaptive Computation and Machine Learning. Cambridge, Mass: MIT Press.\n","title":"Minimum description length","url":"https://hugocisneros.com/notes/minimum_description_length/"}
    
    , 
    
    {"body":" tags Neural networks  For a neural network trying to minimize a quadratic loss, the gradient flow can be re-written from \\[ \\dot{w} = - \\nabla L (w(t)) \\] to \\[ \\dot{w} = - \\nabla y(w) (y(w) - \\bar{y}) \\]\nTherefore, the time derivative of \\(y\\) is \\[ \\dot{y}(w) = \\nabla y(w)^T \\dot{w} = - \\nabla y(w)^T \\nabla y(w) (y(w) - \\bar{y}) \\] The NTK is the quantity to the left of the last term: \\(\\nabla y(w)^T \\nabla y(w)\\). SIR model\n","title":"Neural tangent kernel","url":"https://hugocisneros.com/notes/neural_tangent_kernel/"}
    
    , 
    
    {"body":" source (Raimbault 2020) tags ALife 2020, Complex Systems, Evolution, Urban science  Summary This paper studies the concept of innovation diffusion and how this could be seen as a way cities evolve.\nModeling this enables finding that global integration of cities (fully connected city graph on a territory) is not optimal for efficiently diffusing innovation that can spontaneously appear in any city.\nI am interested in taking an ALife inspired approach to studying cities, as it can show cities as they could be.\nBibliography Raimbault, Juste. July 1, 2020. \"A Model of Urban Evolution Based on Innovation Diffusion\". Artificial Life Conference Proceedings 32 (July). MIT Press:500–508. DOI.","title":"A model of urban evolution based on innovation diffusion by Raimbault, J. (2020)","url":"https://hugocisneros.com/notes/raimbaultmodelurbanevolution2020/"}
    
    , 
    
    {"body":" tags Cellular automata source (Miller 2004)  Summary Comments Bibliography Miller, Julian Francis. 2004. \"Evolving a Self-Repairing, Self-Regulating, French Flag Organism\". In Genetic and Evolutionary Computation Conference, 129–39. Springer.","title":"Evolving a self-repairing, self-regulating, French flag organism by Miller, J. F. (2004)","url":"https://hugocisneros.com/notes/millerevolvingselfrepairingselfregulating2004/"}
    
    , 
    
    {"body":" tags Neural networks, Genetic algorithms, NAS source (Stanley and Miikkulainen 2002)  Summary This is the main paper introducing the NEAT system. This system is a direct-encoding based way of dealing with neuroevolution (evolution of ANNs). The encoding is based on a genome sequentially specifying each of the connections between modules of the network. Several tickes are used to make it possible applying GA methods to evolve networks:\n Historical tracking of genes to be able to align architectures and mate them. Innovation protection with speciation. A notion of speciation is used, and fitness is shares among entire species to make innovations that aren\u0026rsquo;t immediately beneficial still possible.  The method is first tested on XOR and is further applied to a 2 arms pole stabilization problem. NEAT seems capable of achieving satisfying solutions quicker than most methods except maybe ESP ((Gomez and Miikkulainen 1999)).\nComments This paper is very influential (one of the most cited one in neuroevolution). The idea is very interesting but doesn\u0026rsquo;t realy seem able to scale since the encoding of the architecture seems so direct. I belive HyperNEAT solves those issues.\nOther than this, the main task solving is based on optimizing an objective with a GA.\nBibliography Gomez, Faustino J., and Risto Miikkulainen. 1999. \"Solving Non-Markovian Control Tasks with Neuroevolution\". In IJCAI, 99:1356–61. Stanley, Kenneth O., and Risto Miikkulainen. June 2002. \u0026ldquo;Evolving Neural Networks through Augmenting Topologies\u0026rdquo;. Evolutionary Computation 10 (2):99–127. DOI.\n","title":"Evolving Neural Networks through Augmenting Topologies by Stanley, K. O., \u0026 Miikkulainen,...","url":"https://hugocisneros.com/notes/stanleyevolvingneuralnetworks2002/"}
    
    , 
    
    {"body":" source (Reinke, Etcheverry, and Oudeyer 2020)  Summary The authors address the problem of automated discovery of diverse self-organized patterns in high-dimensional and complex game-of-life types of dynamical systems. They conduct experiments on Lenia.\nTheir goal is to use an IMGEP algorithm to represent interesting patterns and discover them.\nProblem setting Goal: With a budget of \\(N\\) experiments, maximize diversity of observations.\nParameter space \\(\\Theta\\) of available parameters \\(\\theta\\). An observation space \\(O\\) of observations. A single observation (a time series of images from Lenia in the paper) is denoted \\(o\\). An unknown dynamic \\(D\\) maps parameters \\(\\Theta\\) to observations \\(O\\).\nA goal space \\(\\mathcal{T}\\) represents relevant features of an observation \\(o\\). \\(\\hat{g} = \\mathcal{R}(o)\\) (e.g. size or form of a pattern here).\nAlgorithm For \\(N\\) timesteps, the algorithm samples a goal \\(g\\) from the space of goals and infers the corresponding parameters \\(\\theta\\) with a parameter sampling policy \\(\\Pi = P(\\theta; g)\\) and simulate the corresponding experiment, and observation \\(o\\). \\((\\theta, o, \\mathcal{R}(o))\\) is then stored in the history.\nIn the paper, goals are sampled uniformly in a hyper-rectangle of \\(\\mathcal{T}\\).\nGoal space The goal-space is learned online during the procedure with a variational autoencoders. Every \\(K\\) epochs, the VAE is trained on all the history of observations. Importance sampling (50% from the \\(K\\) last iterations / 50% from the rest of the history) is used for training of the VAE.\nParameter sampling Parameters are sampled by selecting from the history which outcome is the closest to the sampled goal.\nParameter space The mapping between parameters and observations is also approximated by the model. For this, CPPNs are used.\nHistory The history is initialized with \\(N_{init}\\) observations and each new observation is added.\nEvaluation Diversity of patterns is measured by the spread of exploration of an analytic behavior space. The authors use a external evaluation space obtained by training a $β$-VAE to learn important features with a dataset of 42500 Lenia patterns and distill it into a 13-dimensional vector.\nThat 13-dim space is then partitioned into 7 equal bins on each dimension. 5 evaluations:\n Random exploration: \\(\\theta\\), including the initial grid state is sampled randomly IMGEP-HGS Goal exploration with hand-defined goal: This uses a goal space with 5 features defined in the Lenia paper IMGEP-PGL Goal exploration with pre-trained goal space: 558 Lenia patterns are used to pre-train the $β$-VAE used to encode the goal space; IMGEP-OGL Goal exploration with online learning of the goal space. IMGEP-RGS Goal exploration with a random goal space (the VAE has random weights)  Results Goal-based exploration enables better behavior diversity with less parameter diversity compared to random exploration.\nLearned goal-space methods seem more effective at finding a more diverse patterns.\nComments This approach to pattern discovery and exploration is interesting. I like this idea of learning goals and pattern representation jointly to add as few assumptions as possible within the model.\nLenia is a fun model but has a lot of moving part and parameters. It would have liked to see how this method does with \u0026ldquo;simpler\u0026rdquo; models such as ECA or 2D Cellular automata.\nBibliography Reinke, Chris, Mayalen Etcheverry, and Pierre-Yves Oudeyer. February 17, 2020. \"Intrinsically Motivated Discovery of Diverse Patterns in Self-Organizing Systems\". arXiv:1908.06663 [Cs, Stat]. http://arxiv.org/abs/1908.06663.","title":"Intrinsically Motivated Discovery of Diverse Patterns in Self-Organizing Systems by...","url":"https://hugocisneros.com/notes/reinkeintrinsicallymotivateddiscovery2020/"}
    
    , 
    
    {"body":" tags Convolutional neural networks, Neural network training source (Ye et al. 2020)  Summary This paper introduces so-called Network Deconvolution, advertised as a way to remove pixel-wise and channel-wise correlation in deep neural networks.\nThe authors base their new operator on the optimal configuration for \\(L_2\\) linear regression, where gradient descent converges in one single step if and only if:\n\\[ \\frac{1}{N}X^t X = I \\] where \\(X\\) is the feature matrix and \\(N\\) the number of samples.\nThis means that input features should be normalized and uncorrelated for gradient descent to converge the fastest. This can be achieved, either by correcting the gradient with the Hessian matrix, or manipulating input features so as to normalize them and remove correlations.\nAn algorithm to construct this deconvolution operator is introduced. \\(D \\approx (Cov + \\epsilon \\cdot I) ^{-\\frac{1}{2}}\\), where \\(Cov = \\frac{1}{N}(X-\\mu)^t (X-\\mu)\\).\nActual deconvolution operator approximation is done with some sampling to accelerate computations. After training, a running average of \\(D\\) is frozen and can be used for evaluation.\nDeconvolution is presented as a unification of commonly used normalization techniques such as channel-wise decorrelation or BatchNorm.\nThe authors report what looks like pretty consistent improvement over BatchNorm on image classification tasks. This improvement is not very large however (less than top-5 1% accuracy on ImageNet).\nComments This paper demonstrates what seems like a generalization of deep learning training acceleration techniques rooted in somewhat theoretically sound ideas. These theoretical ideas are based on the linear version of the problem however, which doesn\u0026rsquo;t translate well to deep networks most of the time. Reviews are positive overall, and the paper may set a new standard for these normalization techniques, although comparison with recent work apart from BatchNorm is lacking in the paper.\nThese acceleration techniques seem to only have empirical foundations for deep learning as of today, and may well be rendered useless by some new training algorithm someday.\nBibliography Ye, Chengxi, Matthew Evanusa, Hua He, Anton Mitrokhin, Tom Goldstein, James A Yorke, Cornelia Fermüller, and Yiannis Aloimonos. 2020. \"Network Deconvolution\", 20.","title":"Network Deconvolution by Ye, C., Evanusa, M., He, H., Mitrokhin, A., Goldstein, T., Yorke,...","url":"https://hugocisneros.com/notes/yenetworkdeconvolution2020/"}
    
    , 
    
    {"body":" tags NAS source (Floreano, Dürr, and Mattiussi 2008)  Summary Comments Bibliography Floreano, Dario, Peter Dürr, and Claudio Mattiussi. March 1, 2008. \"Neuroevolution: From Architectures to Learning\". Evolutionary Intelligence 1 (1):47–62. DOI.","title":"Neuroevolution: from architectures to learning by Floreano, D., Dürr, P., \u0026 Mattiussi, C....","url":"https://hugocisneros.com/notes/floreanoneuroevolutionarchitectureslearning2008/"}
    
    , 
    
    {"body":" source (Felleisen 1991) tags Programming languages resources PWL Conf talk  Summary Programming languages have different levels of expressiveness. While can be used to create for loops, binary if statements can implement multi-if statements, etc.\nTuring tarpit: once we get to programming languages that are universal, everything can be re-written into anything and the notion of \u0026ldquo;expressiveness\u0026rdquo; of programming languages doesn\u0026rsquo;t make much sense.\nFor a language \\(L\\) and \\(F + L\\) the addition of some features, can we say the second is more expressive than the first? Intuitively, this is related to some form of re-writing of programs into one another.\n\\(F + L\\) isn\u0026rsquo;t more expressive than \\(L\\) when a macro for \\(F\\) to \\(L\\) exists. This means that for all programs \\(P\\) in \\(L+F\\), \\(P_L\\) its extension in \\(L\\), the two programs are equal.\nWhen \\(F\\) is expressive relative to \\(L\\), you need to show that there cannot possibly exist such a macro.\nA definition of equality Equality is hard to define formally with programming languages. Is there a way in the language to tell them apart? If not, two things can be said to be equal within that language. But an even more general definition of equality: if for all contexts \\(C\\), \\(C[e_1]\\) halts iff \\(C[e_2]\\) halts (additional \u0026ldquo;trick\u0026rdquo;: programs with errors don\u0026rsquo;t terminate). The power of the definition comes from the fact that it has to hold for all contexts. This is called observational equivalence.\nWith this definition of equality, we can re-frame expressiveness. If we have of a language with more features, are all things previously considered equal still equal?\nKey theorem If we suppose \\(F\\) is written as a local macro, then for each terms that are equal under \\(L\\) they will be equal under \\(F+L\\). This means it hasn\u0026rsquo;t added power to \\(L\\).\nWith this, how do we show expressiveness? We show that we can find a context in \\(L + F\\) which makes two previously equal things distinguishable. \\(F\\) added power to the language \\(L\\).\nExamples With this one can show that a halts statement does add expressiveness to a language. Similarly, state gives the power to count compared to a pure functional language.\nConclusions Local vs global transformations, in all of the above, transformations were local. But things like state can for example be implemented in functional programming through store-passing style.\nWhen two languages are not as expressive, no local transformations can work.\nThis gives us two great definitions of equality and expressiveness.\nMacros in language can add expressiveness, but expressiveness isn\u0026rsquo;t always suitable because they break existing equalities. However they can help avoid global transformations when a feature is needed.\nBibliography Felleisen, Matthias. December 1, 1991. \"On the Expressive Power of Programming Languages\". Science of Computer Programming 17 (1):35–75. DOI.","title":"On the expressive power of programming languages by Felleisen, M. (1991)","url":"https://hugocisneros.com/notes/felleisenexpressivepowerprogramming1991/"}
    
    , 
    
    {"body":" tags Neural networks source (Greydanus 2020)  Summary This paper introduces a minimalist 1D version of the MNIST dataset for studying some basic properties of neural networks. The authors simplify the MNIST dataset by assigning a 1D glyph to each digit. These glyphs are padded, translated, sheared and blurred to build a dataset of multiple different objects.\nThe figure from the paper shown below illustrates this dataset\u0026rsquo;s construction:\n 1D simple MNIST   This dataset is shown to be a suitable tool to study very small neural networks and their properties. The authors discuss:\n Lottery tickets Double descent Metalearning The use of strong spatial priors such as translation invariance Pooling methods  Comments This is an interesting paper, which for once isn\u0026rsquo;t about getting bigger models or better results than the state of the art. The small MNIST dataset may lead to interesting insights into the functioning of neural networks but I\u0026rsquo;m not sure that will be enough for solving the big questions about deep learning. The secrets of those huge recent models might elude us for a while simply because we don\u0026rsquo;t have the resources (mathematical or computational) to study them.\nBibliography Greydanus, Sam. November 29, 2020. \"Scaling **down** Deep Learning\". arXiv:2011.14439 [Cs, Stat]. http://arxiv.org/abs/2011.14439.","title":"Scaling down Deep Learning by Greydanus, S. (2020)","url":"https://hugocisneros.com/notes/greydanusscalingdeeplearning2020/"}
    
    , 
    
    {"body":" tags Data representation  ","title":"PCA","url":"https://hugocisneros.com/notes/pca/"}
    
    , 
    
    {"body":" tags Evolution, Reinforcement learning, Search algorithms papers (Pugh, Soros, and Stanley 2016; Cully and Demiris 2017)  QD is about creating algorithms that favor diversity in searching the space. In QD, one needs to both:\n Measure the quality of a solution Have a way to describe the effect of a solution  Solutions in QD have to be good in the two above ways.\nQD is also a form of novelty search.\nBibliography Cully, Antoine, and Yiannis Demiris. 2017. \"Quality and Diversity Optimization: A Unifying Modular Framework\". IEEE Transactions on Evolutionary Computation 22 (2). IEEE:245–59. Pugh, Justin K., Lisa B. Soros, and Kenneth O. Stanley. 2016. \u0026ldquo;Quality Diversity: A New Frontier for Evolutionary Computation\u0026rdquo;. Frontiers in Robotics and AI 3. Frontiers. DOI.\n","title":"Quality diversity","url":"https://hugocisneros.com/notes/quality_diversity/"}
    
    , 
    
    {"body":" tags Machine learning  Definition Self supervised learning (SSL) is a learning paradigm based on the idea of using information contained within the training data to build better representations of it. Self-supervised models are usually trained to predict hidden parts of the input data from its visible parts.\nSSL in NLP Self-supervised learning has been used for a long time in NLP. In Language modeling, one tries to predict words from previous ones. Recent language deep learning models have introduced other techniques such as allowing a transformer to read words forward and backward but partially masking them (Devlin et al. 2019).\nWord vectors is another example of successful self-supervised learning which goal is to learn rich vector representations for words from their context.\nSLL in Computer vision In 2019 and 2020 self-supervised became more and more widespread in the vision community as the results on standard benchmarks started to match regular supervised learning.\nBibliography Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. May 24, 2019. \"BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding\". arXiv:1810.04805 [Cs]. http://arxiv.org/abs/1810.04805.","title":"Self-supervised learning","url":"https://hugocisneros.com/notes/self_supervised_learning/"}
    
    , 
    
    {"body":" tags Computability theory  The idea behind Turing degrees is similar to the notion of cardinality of infinite sets ($ℵ_0, ℵ_1, \u0026hellip;$) in the world of computation.\nA Turing degree is an equivalence class for the Turing equivalence. Being Turing equivalent for two sets \\(X\\) and \\(Y\\) means that a Turing machine can decide if an element belongs to the set \\(X\\) when it has an oracle for membership to \\(Y\\) (there is a way to formulate the membership problem for \\(X\\) as a problem for \\(Y\\)) and reciprocally.\nThe Turing degree \\(\\mathbf{0}\\) corresponds to all computable sets and is the smallest degree.\n","title":"Turing degree","url":"https://hugocisneros.com/notes/turing_degree/"}
    
    , 
    
    {"body":" tags Computability theory  A system is Turing complete if it can be used to simulate any Turing Machine.\nExamples of Turing complete systems  Some cellular automata Most Programming languages Lambda calculus Combinatory logic Others like Post-Turing Machines, formal grammar, formal language, etc. Some games (Minecraft, baba is you) and computational languages (markup languages like HTML+CSS)  ","title":"Turing-completeness","url":"https://hugocisneros.com/notes/turing_completeness/"}
    
    , 
    
    {"body":" papers (Stepney 2012)  Bibliography Stepney, Susan. 2012. \"Nonclassical Computation — a Dynamical Systems Perspective\". In Handbook of Natural Computing, edited by Grzegorz Rozenberg, Thomas Bäck, and Joost N. Kok, 1979–2025. Berlin, Heidelberg: Springer Berlin Heidelberg. DOI.","title":"Unconventional computing","url":"https://hugocisneros.com/notes/unconventional_computing/"}
    
    , 
    
    {"body":" tags Complexity metrics papers (Marshall et al. 2019)  This complexity metric is based on ideas similar to Logical depth, where instead of just looking at the general process that led to the creation of an object, we also look at the number of elementary steps in that process.\nBibliography Marshall, Stuart M, Douglas G Moore, Alastair R G Murray, and Sara I Walker. July 2019. \"Quantifying the Pathways to Life Using Assembly Spaces\", 30.","title":"Assembly theory","url":"https://hugocisneros.com/notes/assembly_theory/"}
    
    , 
    
    {"body":" tags Evolutionary algorithms  ","title":"CMA-ES","url":"https://hugocisneros.com/notes/cma_es/"}
    
    , 
    
    {"body":" tags Zuse\u0026rsquo;s thesis source (Schmidhuber 1999)  Summary Comments Bibliography Schmidhuber, Juergen. April 13, 1999. \"A Computer Scientist’s View of Life, the Universe, and Everything\". arXiv:Quant-Ph/9904050. http://arxiv.org/abs/quant-ph/9904050.","title":"A Computer Scientist's View of Life, the Universe, and Everything by Schmidhuber, J....","url":"https://hugocisneros.com/notes/schmidhubercomputerscientistview1999/"}
    
    , 
    
    {"body":" source (Sayama 1999) tags Cellular automata, Evolution  Summary This work presents a simple evolutionary system based on Langton\u0026rsquo;s self-reproducing loop. This is entirely done with a normal state-transition rule based CA. The initial structure of the loop was modified to catch variations. An interesting consequence of this system evolving is its natural tendency to evolve towards smaller loops despite no stochastic mutation being hard-coded.\nBibliography Sayama, H.. 1999. \"A New Structurally Dissolvable Self-Reproducing Loop Evolving in a Simple Cellular Automata Space\". Artificial Life 5 (4):343–65. DOI.","title":"A new structurally dissolvable self-reproducing loop evolving in a simple cellular...","url":"https://hugocisneros.com/notes/sayamanewstructurallydissolvable1999/"}
    
    , 
    
    {"body":" source (Tutum and Miikkulainen 2020) tags Meta-learning, Reinforcement learning, ALife 2020  Summary This work introduces the idea of Context-Skill networks for continuous RL tasks. Experiments are done on a Flappy bird like game.\nThe authors use a LSTM as a context network to make part of the prediction and a feed-forward neural network as a skill network. They are able to demonstrate that in that game, better performances are achieved by using both networks compared to a single one.\nBibliography Tutum, Cem, and Risto Miikkulainen. July 1, 2020. \"Adapting to Unseen Environments through Explicit Representation of Context\". Artificial Life Conference Proceedings 32 (July). MIT Press:581–88. DOI.","title":"Adapting to Unseen Environments through Explicit Representation of Context by Tutum, C., \u0026...","url":"https://hugocisneros.com/notes/tutumadaptingunseenenvironments2020/"}
    
    , 
    
    {"body":" tags Emergence, Life, Cellular automata source (Beer 2020)  Summary Constitution: \u0026ldquo;How emergent individuals are put together and maintained\u0026rdquo; Interaction: \u0026ldquo;How emergent individuals as a whole engage with the environment\u0026rdquo;\nUse Conway\u0026rsquo;s Game of Life as a toy model where each cell and update rule is like the Physics of the universe and this physics gives rise to a simple chemistry which can in turn support self-sustaining networks of reactions and some form of biology. Finally this biology engages with the environment in a wide range of interactions.\nIn (Beer 2015) the same author constructed a theory of constitution for simple gliders in GOL. A complete map of interactions was done in (Beer 2014) (mapping all the ways gliders can interact with the environment).\nThis allows the author to study the two processes in a very concrete way. He extends the glider constitution theory to add \u0026ldquo;unspecified\u0026rdquo; environments and have gliders that are not evolving in a vacuum. This allows studying processes where even after interaction with the environment, a glider stays a well defined glider.\nStarting from the theory of glider constitution (how glider is constituted in a vacuum) and a theory of gliders interactions with their environment. From a generalization of the glider organization, the author was able to derive the glider interaction graph.\nBibliography Beer, Randall D.. 2014. \"The Cognitive Domain of a Glider in the Game of Life\". Artificial Life 20 (2):183–206. DOI. ———. February 2015. \u0026ldquo;Characterizing Autopoiesis in the Game of Life\u0026rdquo;. Artificial Life 21 (1):1–19. DOI.\n———. July 1, 2020. \u0026ldquo;An Integrated Perspective on the Constitutive and Interactive Dimensions of Autonomy\u0026rdquo;. Artificial Life Conference Proceedings 32 (July). MIT Press:202–9. DOI.\n","title":"An Integrated Perspective on the Constitutive and Interactive Dimensions of Autonomy by...","url":"https://hugocisneros.com/notes/beerintegratedperspectiveconstitutive2020/"}
    
    , 
    
    {"body":" tags Cellular automata as CNNs source (Gilpin 2018)  Summary This is one of the only attempt to represent a CA rule as a CNN I have come across. The author uses a deep CNN to learn a rule and studies various information-theoretic quantities in the activation patterns to evaluate the complexity of the rules.\nComments I am personally very interested by the paper since it is an interesting direction for creating neural-network based rules that can be sampled and efficiently stored and applied. This work is also cited in (Mordvintsev et al. 2020).\nBibliography Mordvintsev, Alexander, Ettore Randazzo, Eyvind Niklasson, and Michael Levin. February 11, 2020. \"Growing Neural Cellular Automata\". Distill 5 (2):e23. DOI. Gilpin, William. September 9, 2018. \u0026ldquo;Cellular Automata as Convolutional Neural Networks\u0026rdquo;. arXiv:1809.02942 [Cond-Mat, Physics:Nlin, Physics:Physics]. http://arxiv.org/abs/1809.02942.\n","title":"Cellular automata as convolutional neural networks by Gilpin, W. (2018)","url":"https://hugocisneros.com/notes/gilpincellularautomataconvolutional2018/"}
    
    , 
    
    {"body":" source (Bender and Koller 2020) tags NLP, Artificial Intelligence, Evaluating NLP  Summary The main point of the article could be summarized like so:\n We argue that the language modeling task, because it only uses form as training data, cannot in principle lead to learning of meaning. We take the term language model to refer to any system trained only on the task of string prediction, whether it operates over characters, words or sentences, and sequentially or not. We take (linguistic) meaning to be the relation between a linguistic form and communicative intent.\n Several NLP papers (cited in the text) use overly confident claims about language models understanding a piece of text or knowledge.\nThe authors formalize meaning with a set of pairs \\(M \\subseteq E \\times I\\), \\((e, i)\\) representing natural language expressions and their communicative intent. In this framework, understanding means being able to retrieve \\(i\\) when given \\(e\\).\nThey also mention the concept of conventional meaning, i.e. the communicative potential \\(s\\) of a form \\(e\\) which is constant across contexts of use of the form \\(e\\).\nWhen communicating, a speaker has a prior intent \\(i\\), and has to choose a form \\(e\\) with the right potential \\(s\\) that fits \\(i\\). The argument of the paper is that there isn\u0026rsquo;t enough signal in a text corpus to learn the above relations in \\(M\\).\nA nice example is the Chinese room experiment, wherein a person is tasked with answering questions in Chinese by consulting a library of Chinese books according to fixed rules. Such a person would look intelligent without having any actual understanding of Chinese.\nA nice example is the problem of learning language models on Programming languages. No matter how good a LM is at learning the semantics of the language, it has no way of learning the relations between program inputs and outputs.\nThe authors provide more example why human-language acquisition is fundamentally different from the flawed language models.\nA good LM might learn to give meaningful answers, but will need to store infinite amount of data and will ultimately fail at dealing with the ever evolving set of forms humans use.\nComments Regarding the programming language example, one could argue that by learning the semantics of the language on a large corpus, a LM will eventually have to learn inputs/outputs mapping for intermediate functions in the larger programs, and could build understanding from these small building blocks. However, no explicit mechanisms in current language models allow for combining and re-using building blocks like that.\nThis is the same with language models, as long as we use neural networks trained with Gradient descent, it will probably never have this power humans have to re-use and create forms to manipulate meaning and deal with a changing world. In a way GPT-3 (Brown et al. 2020) has showed that we can get to a pretty impressive point with sentence prediction alone provided we have enough storage.\nBibliography Bender, Emily M., and Alexander Koller. July 2020. \"Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data\". In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 5185–98. Online: Association for Computational Linguistics. https://www.aclweb.org/anthology/2020.acl-main.463. Brown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al.. June 4, 2020. \u0026ldquo;Language Models Are Few-Shot Learners\u0026rdquo;. arXiv:2005.14165 [Cs]. http://arxiv.org/abs/2005.14165.\n","title":"Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data by Bender, E....","url":"https://hugocisneros.com/notes/benderclimbingnlumeaning2020/"}
    
    , 
    
    {"body":" tags Artificial life, Combinatory logic source (Kruszewski and Mikolov 2020)  Summary This is Kruszewski\u0026rsquo;s approach to artificial life, based on artificial chemistry. Combinatory logic is used as a basis for this system. Conservation laws are added on top of the set of rules that make combinatory logic Turing complete. This is then used to observe interesting dynamics and pre-life-like processes.\nComments Bibliography Kruszewski, Germán, and Tomas Mikolov. March 17, 2020. \"Combinatory Chemistry: Towards a Simple Model of Emergent Evolution\". arXiv:2003.07916 [Nlin, Q-Bio]. http://arxiv.org/abs/2003.07916.","title":"Combinatory Chemistry: Towards a Simple Model of Emergent Evolution by Kruszewski, G., \u0026...","url":"https://hugocisneros.com/notes/kruszewskicombinatorychemistrysimple2020/"}
    
    , 
    
    {"body":" tags Evolution, Complexity source (McShea 1991)  Summary Comments Bibliography McShea, Daniel W.. July 1991. \"Complexity and Evolution: What Everybody Knows\". Biology \u0026 Philosophy 6 (3):303–24. DOI.","title":"Complexity and evolution: What everybody knows by McShea, D. W. (1991)","url":"https://hugocisneros.com/notes/mcsheacomplexityevolutionwhat1991/"}
    
    , 
    
    {"body":" tags Reinforcement learning source (Pathak et al. 2017)  Summary This paper presents a curiosity-based method for training RL agents. These agents are given a reward \\(r_t\\) which is the sum of an intrinsic and an extrinsic rewards. The latter is mostly (if not always) 0, while the former is constructed progressively during exploration by an Intrisic Curiosity Module (ICM).\nThe module is illustrated below (figure from the paper).\n The left part of the figure represents a standard RL setup where actions are taken according to a policy and they affect the state of the agent.\nThe ICM module is a constantly evolving reward function composed of 3 sub-modules:\n A feature encoder \\(\\phi\\) which encodes the states into feature vectors. A forward model which tries to predict the encoded next states \\(\\phi(s_{t + 1})\\) from the current encoded state and action taken. An inverse model that predicts the action taken from both the previous state and next state.  The intrinsic reward is the scaled squared difference between estimated \\(\\hat{\\phi}(s_{t + 1})\\) and \\(\\phi(s_{t + 1})\\). This setup rewards exploration because large errors in the prediction of the next state\u0026rsquo;s feature encoding will lead to more exploration of that region of the environment. Moreover, parts of the environment that are completely unpredictable and unaffected by the actions will have no incentive in being encoded by the ICM. The model should therefore \u0026ldquo;distill\u0026rdquo; the current state to only its essential parts.\nResults are impressive, especially in the sparse and very sparse reward settings (see paper for details) where the model still learn significantly better policies than other methods in terms of extrinsic reward.\nComments Comment on generalization in RL from the paper:\n It is common practice to evaluate reinforcement learning approaches in the same environment that was used for training. However, we feel that it is also important to evaluate on a separate “testing set” as well. This allows us to gauge how much of what has been learned is specific to the training environment (i.e. memorized), and how much might constitute “generalizable skills” that could be applied to new settings.\n I think this research direction is extremely interesting. No/sparse-reward RL seems like a promising approach to construct agents that can efficiently explore and reach good performance on unseen environments.\nThe authors recognize a few issues with their method, but the overall principle seems solid. However, the component that still bothers me is the fact that the ICM, policy, etc. still rely on neural networks trained with gradient descent. This is in my opinion why they won\u0026rsquo;t really be able to do much more than what they\u0026rsquo;ve been trained to do and still suffer from the usual issues with neural networks. They won\u0026rsquo;t be able to learn things on the long term or re-use successful components or innovate significantly.\nThis issue with neural networks and gradient-based learning is illustrated in the paper by the following quote:\n In Mario our agent crosses more than 30% of Level-1 without any rewards from the game. One reason why our agent is unable to go beyond this limit is the presence of a pit at 38% of the game that requires a very specific sequence of 15-20 key presses in order to jump across it. If the agent is unable to execute this sequence, it falls in the pit and dies, receiving no further rewards from the environment. Therefore it receives no gradient information indicating that there is a world beyond the pit that could potentially be explored.\n Bibliography Pathak, Deepak, Pulkit Agrawal, Alexei A. Efros, and Trevor Darrell. July 2017. \"Curiosity-Driven Exploration by Self-Supervised Prediction\". In 2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 488–89. Honolulu, HI, USA: IEEE. DOI.","title":"Curiosity-Driven Exploration by Self-Supervised Prediction by Pathak, D., Agrawal, P.,...","url":"https://hugocisneros.com/notes/pathakcuriositydrivenexplorationselfsupervised2017/"}
    
    , 
    
    {"body":" tags Cellular automata source (Lehre and Haddow 2003)  Summary The approach of the paper is to use a genotype/phenotype distance correlation plot to study the complexity of a system that is determined by a genotype and exhibits som ephenotypic behavior. This is equivalent to simply plotting the distance of two phenotypes (Hamming of the state after 100 iteration starting from a single activated cell for CAs) against the distance between two genotypes (Hamming distance between the rules for a CA).\nComments The approach is interesting, and I also believe that a sensitivity analysis of the behavior of a CA w.r.t perturbations in its rule is worth looking at. However the distance correlation plot itself is very hard to interpret and read, which is probably the main drawback of the method. There is no clear interpretability.\nBibliography Lehre, P. K., and P. C. Haddow. December 2003. \"Developmental Mappings and Phenotypic Complexity\". In The 2003 Congress on Evolutionary Computation, 2003. CEC ’03., 1:62–68 Vol.1. DOI.","title":"Developmental mappings and phenotypic complexity by Lehre, P. K., \u0026 Haddow, P. C. (2003)","url":"https://hugocisneros.com/notes/lehredevelopmentalmappingsphenotypic2003/"}
    
    , 
    
    {"body":" source (Brant and Stanley 2020) tags Co-evolution, Evolutionary algorithms  Summary Comments Bibliography Brant, Jonathan C., and Kenneth O. Stanley. June 25, 2020. \"Diversity Preservation in Minimal Criterion Coevolution through Resource Limitation\". In Proceedings of the 2020 Genetic and Evolutionary Computation Conference, 58–66. Cancún Mexico: ACM. DOI.","title":"Diversity preservation in minimal criterion coevolution through resource limitation by...","url":"https://hugocisneros.com/notes/brantdiversitypreservationminimal2020/"}
    
    , 
    
    {"body":" tags Continual learning source (Hu et al. 2020)  Summary This paper focuses on the problem of (self-)supervised continual learning with deep neural networks. The Firehose dataset introduced by the authors is a large database of timestamped tweets. The goal is to learn a language model for each user from the dataset, which is called Personalized online language learning (POLL).\nThe authors also introduce a new extension of gradient descent for continual learning. It is based on a replay buffer to retain information about past examples and a validation buffer used to choose the ideal number of gradient steps at each steps.\nThis new gradient method called ConGraD outperforms Online GD on most settings studied in the paper.\nComments Because the authors are introducing a new dataset and online learning framework, it seems natural their method is not optimal and will be improved upon.\nI think the concept of continual learning is much more interesting than traditional supervised learning. It looks more adapted to real world situations where data is changing and unpredictable.\nHowever, we are still framing continual learning as a weird hybrid loss function taking into account the history of data and future data. It seems like the probabilistic-ally correct way of doing that but isn\u0026rsquo;t satisfying in my opinion. Nature, if seen as a learning process, doesn\u0026rsquo;t optimize for past examples, and keeps changing in response to the environment. Sure, it has the capability to retain information and pass it through time (e.g. successful evolutionary strategies) but it doesn\u0026rsquo;t seem to be optimizing for a hybrid loss function.\nBibliography Hu, Hexiang, Ozan Sener, Fei Sha, and Vladlen Koltun. November 1, 2020. \"Drinking from a Firehose: Continual Learning with Web-Scale Natural Language\". arXiv:2007.09335 [Cs, Stat]. http://arxiv.org/abs/2007.09335.","title":"Drinking from a Firehose: Continual Learning with Web-scale Natural Language by Hu, H.,...","url":"https://hugocisneros.com/notes/hudrinkingfirehosecontinual2020/"}
    
    , 
    
    {"body":" source (Pham et al. 2018)  Summary Like other papers, the controller is a RNN that generates each part of the architecture in sequence. The main contribution of this paper is to introduce parameter sharing in child models. For, this, it represents all possible architectures in a single DAG of operations and share weights between same operations. They explain how to design a RNN cell with their model, a convolutional network (and convolutional cell to build a CNN) and how to train. Training is done in two alternating steps: - Train paramters for a fixed policy: gradient are estimated by sampling architectures and averaage the gradients for each of them (apparently works when sampling only 1 architecture). - Train the policy (controller parameters) The authors present results on text and vision tasks.\nComments This approach seems more interesting than before, because the weight sharing gives a significant speedup. The task are however rather small compared to SOTA in 2018.\nBibliography Pham, Hieu, Melody Y. Guan, Barret Zoph, Quoc V. Le, and Jeff Dean. February 11, 2018. \"Efficient Neural Architecture Search via Parameter Sharing\". arXiv:1802.03268 [Cs, Stat]. http://arxiv.org/abs/1802.03268.","title":"Efficient Neural Architecture Search via Parameter Sharing by Pham, H., Guan, M. Y., Zoph,...","url":"https://hugocisneros.com/notes/phamefficientneuralarchitecture2018/"}
    
    , 
    
    {"body":" tags Cellular automata, Evolution source (Nehaniv 2003)  Summary This paper proposes a general asynchronous extension of CA rules and show that they can be made equivalent to the original CA rule. Applying this extension to H. Sayama\u0026rsquo;s Evoloop cellular automaton (Sayama 1999), the author creates the first asynchronous implementation of evolution of self-replicators.\nOne hope formulated by the author is that asynchronicity could help achieve fault-tolerance and self-repair.\nBibliography Nehaniv, Chrystopher L.. 2003. \"Evolution in Asynchronous Cellular Automata\". In Proceedings of the Eighth International Conference on Artificial Life, 65–73. Sayama, H.. 1999. \u0026ldquo;A New Structurally Dissolvable Self-Reproducing Loop Evolving in a Simple Cellular Automata Space\u0026rdquo;. Artificial Life 5 (4):343–65. DOI.\n","title":"Evolution in asynchronous cellular automata by Nehaniv, C. L. (2003)","url":"https://hugocisneros.com/notes/nehanivevolutionasynchronouscellular2003/"}
    
    , 
    
    {"body":" source (Pattee and Sayama 2019)  Summary Evolution need not have been inherently open-ended in nature, because from a simple cell evolving in a complex self-organising environment new mechanisms might have been created by the organisms themself, effectively rendering them \u0026ldquo;more\u0026rdquo; open-ended. Symbolic languages are a striking example of this phenomenon: an open-ended descriptive power where the complexity of the environment is not limiting because language can refer itself recursively to build on its complexity.\nBibliography Pattee, Howard H., and Hiroki Sayama. April 2019. \"Evolved Open-Endedness, Not Open-Ended Evolution\". Artificial Life 25 (1):4–8. DOI.","title":"Evolved Open-Endedness, Not Open-Ended Evolution by Pattee, H. H., \u0026 Sayama, H. (2019)","url":"https://hugocisneros.com/notes/patteeevolvedopenendednessnot2019/"}
    
    , 
    
    {"body":" source (Flageat and Cully 2020) tags ALife 2020, MAP-Elites, Quality diversity  Summary MAP-Elites can be problematic in face of uncertainty because:\n individuals can be unexpectedly lucky the behavior space can be hard to estimate and result in misplacing individuals.  Some mitigation techniques have been explored, e.g in (Justesen, Risi, and Mouret 2019) and this paper is about introducing another way of dealing with noisy domains without using sampling.\nHere the main idea is to replace the MAP-elites grid by a \u0026ldquo;deep grid\u0026rdquo; with another dimension. This other dimension is used to store a population of individuals instead of a single individual for each elite. For each mutation, a single individual from the population is selected.\n Slide from the Alife talk   Experiments show that deep grids are a data efficient extension of MAP-elites which enable reducing uncertainty on the behavior descriptors.\nBibliography Flageat, Manon, and Antoine Cully. July 1, 2020. \"Fast and Stable MAP-Elites in Noisy Domains Using Deep Grids\". Artificial Life Conference Proceedings 32 (July). MIT Press:273–82. DOI. Justesen, Niels, Sebastian Risi, and Jean-Baptiste Mouret. July 13, 2019. \u0026ldquo;MAP-Elites for Noisy Domains by Adaptive Sampling\u0026rdquo;. In Proceedings of the Genetic and Evolutionary Computation Conference Companion, 121–22. GECCO ’19. Prague, Czech Republic: Association for Computing Machinery. DOI.\n","title":"Fast and stable MAP-Elites in noisy domains using deep grids by Flageat, M., \u0026 Cully, A....","url":"https://hugocisneros.com/notes/flageatfaststablemapelites2020/"}
    
    , 
    
    {"body":" tags Evaluating NLP, Transformers, Minimum description length source (Voita and Titov 2020)  Summary Comments Bibliography Voita, Elena, and Ivan Titov. March 27, 2020. \"Information-Theoretic Probing with Minimum Description Length\". arXiv:2003.12298 [Cs]. http://arxiv.org/abs/2003.12298.","title":"Information-Theoretic Probing with Minimum Description Length by Voita, E., \u0026 Titov, I....","url":"https://hugocisneros.com/notes/voitainformationtheoreticprobingminimum2020/"}
    
    , 
    
    {"body":" tags NAS source (Zoph et al. 2018)  Summary This paper is more or less a follow up of (Zoph and Le 2017) where the search space get at the same time widened and more constraints are added (division between normal cell for processing and reduction cell for pooling/downsampling). Normal cells get stacked \\(N\\) times resulting in very big architectures. NASNet is created by searching for thos cells but the actual number of cells stacked and number of filters of the penultimate layer are searched separately.\nComments These models seem very impractical because very long and hard to produce. The indeed have SOTA results at the time of writing but with explicit mention of the size of the models and time of training. Improvement over random search is only 1%..\nBibliography Zoph, Barret, Vijay Vasudevan, Jonathon Shlens, and Quoc V. Le. April 11, 2018. \"Learning Transferable Architectures for Scalable Image Recognition\". arXiv:1707.07012 [Cs, Stat]. http://arxiv.org/abs/1707.07012. Zoph, Barret, and Quoc V. Le. February 15, 2017. \u0026ldquo;Neural Architecture Search with Reinforcement Learning\u0026rdquo;. arXiv:1611.01578 [Cs]. http://arxiv.org/abs/1611.01578.\n","title":"Learning Transferable Architectures for Scalable Image Recognition by Zoph, B., Vasudevan,...","url":"https://hugocisneros.com/notes/zophlearningtransferablearchitectures2018/"}
    
    , 
    
    {"body":" tags Genetic algorithms, Recurrent neural networks source (Wierstra, Gomez, and Schmidhuber 2005)  Summary Comments Bibliography Wierstra, Daan, Faustino J. Gomez, and Jürgen Schmidhuber. 2005. \"Modeling Systems with Internal State Using Evolino\". In Proceedings of the 2005 Conference on Genetic and Evolutionary Computation - GECCO ’05, 1795. Washington DC, USA: ACM Press. DOI.","title":"Modeling systems with internal state using evolino by Wierstra, D., Gomez, F. J., \u0026...","url":"https://hugocisneros.com/notes/wierstramodelingsystemsinternal2005/"}
    
    , 
    
    {"body":" tags Neural networks source (Maziarka et al. 2020)  Summary Comments Bibliography Maziarka, Łukasz, Tomasz Danel, Sławomir Mucha, Krzysztof Rataj, Jacek Tabor, and Stanisław Jastrzębski. February 19, 2020. \"Molecule Attention Transformer\". arXiv:2002.08264 [Physics, Stat]. http://arxiv.org/abs/2002.08264.","title":"Molecule Attention Transformer by Maziarka, Ł., Danel, T., Mucha, S., Rataj, K., Tabor,...","url":"https://hugocisneros.com/notes/maziarkamoleculeattentiontransformer2020/"}
    
    , 
    
    {"body":" tags NAS source (Zoph and Le 2017)  Summary This paper introduces the idea of using a RNN controller system to generate the operations of a neural network. In a first setting the authors use this method to construct CNNs. The controller samples an architecture, the architecture is built and trained and the controller is rewarded with the maximum validation accuracy of the last 5 epochs cubed (??).\nAnother experiment uses this exploration method to produce recurrent cell through a complicated model based on a tree of units, for each of which the controller samples an operation.\nComments There is a lot of hyperparameters everywhere, given without anything else. Learning rates, weights, scores and random operations. Overall, the paper shows that their method can produce architecture that give comparable performance to human-designed ones. However, there is nothing said about wether a random search could do the same or better. The lesson is maybe that all those tasks are pretty much solved once you have the right operations (convolutions for images and recurrent cell for penn treebank and LM).\nSearch is really expensive (22400 GPU-hours, 800 GPU for 28 days).\nBibliography Zoph, Barret, and Quoc V. Le. February 15, 2017. \"Neural Architecture Search with Reinforcement Learning\". arXiv:1611.01578 [Cs]. http://arxiv.org/abs/1611.01578.","title":"Neural Architecture Search with Reinforcement Learning by Zoph, B., \u0026 Le, Q. V. (2017)","url":"https://hugocisneros.com/notes/zophneuralarchitecturesearch2017/"}
    
    , 
    
    {"body":" source (Lechner et al. 2020) tags Neural networks  Summary This article introduces a type of RNN called Neural Circuit Policies (NCP). This architecture is said to be inspired from the wiring diagram of the C. elegans nematode.\nThe main building block is a Recurrent neural network called liquid time constant (LTC) introduced in (Hasani et al. 2020).\nLTC Neurons These neurons are bio-inspired. For a given neuron in state x_i(t), the continuous temporal evolution is described by an ODE: \\[ \\dot{x}_i = - \\left(\\frac{1}{\\tau_i} + \\frac{w_{ij}}{C_{m_i}} \\sigma_i(x_j) \\right) x_i + \\left( \\frac{x_{\\text{leak}_i}}{\\tau_i}+ \\frac{w_{ij}}{C_{m_i}} \\sigma_i(x_j) E_{ij} \\right) \\]\nwhere \\(w_{ij}\\) is a synaptic weight from neuron \\(i\\) to \\(j\\), \\(C_{m_i}\\) is the membrane capacitance of the neuron \\(i\\), and \\(\\sigma_i(x_j(t)) = 1/\\left( 1 + e^{-\\gamma_{ij}(x_j-\\mu_{ij})}\\right)\\). \\(x_{\\text{leak}_i}\\) is called the resting potential and \\(E_ij\\) is a reversal synaptic potential.\nMore details about the biological analogy for those quantities are given in (Hasani et al. 2020; Lechner et al. 2020).\nResults The authors reports good results on a car steering task compared to many RNN architectures, although not much better than LSTMs. The main advantages of this method according to the authors are:\n Better noise robustness Better interpret-ability Less parameters needed  Comments I was excited about this paper because it seemed to have found a way to train very small neural networks with an alternative learning mechanism, maybe akin to reservoir computing. However it appears to be based on the same principles as traditional supervised learning. The main innovation of this paper would therefore be the architecture it proposes, which I may not understand very deeply due to lack of knowledge in neuroscience.\nBibliography Hasani, Ramin, Mathias Lechner, Alexander Amini, Daniela Rus, and Radu Grosu. September 12, 2020. \"Liquid Time-Constant Networks\". arXiv:2006.04439 [Cs, Stat]. http://arxiv.org/abs/2006.04439. Lechner, Mathias, Ramin Hasani, Alexander Amini, Thomas A. Henzinger, Daniela Rus, and Radu Grosu. October 2020. \u0026ldquo;Neural Circuit Policies Enabling Auditable Autonomy\u0026rdquo;. Nature Machine Intelligence 2 (10):642–52. DOI.\n","title":"Neural Circuit Policies Enabling Auditable Autonomy by Lechner, M., Hasani, R., Amini, A.,...","url":"https://hugocisneros.com/notes/lechnerneuralcircuitpolicies2020/"}
    
    , 
    
    {"body":" tags Autoencoders source (Beckham et al. 2019)  Summary Comments Bibliography Beckham, Christopher, Sina Honari, Vikas Verma, Alex Lamb, Farnoosh Ghadiri, R. Devon Hjelm, Yoshua Bengio, and Christopher Pal. October 23, 2019. \"On Adversarial Mixup Resynthesis\". arXiv:1903.02709 [Cs, Stat]. http://arxiv.org/abs/1903.02709.","title":"On Adversarial Mixup Resynthesis by Beckham, C., Honari, S., Verma, V., Lamb, A., Ghadiri,...","url":"https://hugocisneros.com/notes/beckhamadversarialmixupresynthesis2019/"}
    
    , 
    
    {"body":" tags Reinforcement learning source (Khalifa et al. 2020)  Summary Comments Bibliography Khalifa, Ahmed, Philip Bontrager, Sam Earle, and Julian Togelius. January 24, 2020. \"PCGRL: Procedural Content Generation via Reinforcement Learning\". arXiv:2001.09212 [Cs, Stat]. http://arxiv.org/abs/2001.09212.","title":"PCGRL: Procedural Content Generation via Reinforcement Learning by Khalifa, A., Bontrager,...","url":"https://hugocisneros.com/notes/khalifapcgrlproceduralcontent2020/"}
    
    , 
    
    {"body":" tags Open-ended Evolution, Reinforcement learning source (Wang et al. 2019)  Summary This paper is about introducing the POET architecture. The core idea behind this framework is to build a system that can make agents learn complex behavior through joint evolution of agents and the environment. The better the agent, the more complex environment we can give it.\nThere are 3 main components to the algorithm: an evolutionary strategy (ES) for the environment itself, resembling genetic algorithm, another ES for the agents (although these agents might also be trained with RL), and a transfer mechanism whereby agents trained in a particular environment can be trained on another one.\nThe authors test this new framework on a 2D Bipedal Walker landscape example and show that their agents are able to learn to walk in very challenging settings. They also show that for complex environments, direct optimization is not enough to learn the needed complex behavior.\nComments I think this is an interesting curriculum learning paper that addresses the issue of learning continuously in an ever changing environment. However, the step towards open-endedness advertised in the paper seems really tiny.\nThe authors haven\u0026rsquo;t addressed the main issue which is having open-ended ever more complex environments. The genetic algorithm-based method might keep generating new combinations of obstacles but will never create a fundamentally new obstacle, or combine previous environments into a new one.\nThis is also not mentioning the fact that the complexity of the behavior of the agents are bounded if we only use neural networks as controllers. This framework would probably be the holy grail if we had both open-ended environment generation and open-ended learning complexity.\nThis confirms my initial thought about one of the authors that this group probably has the right motivations but doesn\u0026rsquo;t seem to be going in the right direction with this neural-network, RL-looking methods. Getting to open-endedness will likely require significant paradigm changes.\nBibliography Wang, Rui, Joel Lehman, Jeff Clune, and Kenneth O. Stanley. July 13, 2019. \"POET: Open-Ended Coevolution of Environments and Their Optimized Solutions\". In Proceedings of the Genetic and Evolutionary Computation Conference, 142–51. GECCO ’19. Prague, Czech Republic: Association for Computing Machinery. DOI.","title":"POET: open-ended coevolution of environments and their optimized solutions by Wang, R.,...","url":"https://hugocisneros.com/notes/wangpoetopenendedcoevolution2019/"}
    
    , 
    
    {"body":" tags Cellular automata, Reinforcement learning source (Horibe, Walker, and Risi 2021)  Summary The authors explore neural cellular automata (Mordvintsev et al. 2020) as a framework for growing soft robots.\nComments Bibliography Horibe, Kazuya, Kathryn Walker, and Sebastian Risi. February 7, 2021. \"Regenerating Soft Robots through Neural Cellular Automata\". arXiv:2102.02579 [Cs, Q-Bio]. http://arxiv.org/abs/2102.02579. Mordvintsev, Alexander, Ettore Randazzo, Eyvind Niklasson, and Michael Levin. February 11, 2020. \u0026ldquo;Growing Neural Cellular Automata\u0026rdquo;. Distill 5 (2):e23. DOI.\n","title":"Regenerating Soft Robots through Neural Cellular Automata by Horibe, K., Walker, K., \u0026...","url":"https://hugocisneros.com/notes/horiberegeneratingsoftrobots2021/"}
    
    , 
    
    {"body":" source (Jensen and Tufte 2020) tags Reservoir computing, Complex Systems  Summary This talk is about artificial spin ice. This model is based on a grid of coupled magnets that can be controlled with a magnetic field. The geometry of that grid can very greatly the kind of behavior one may observe in such systems.\nThe authors want to use the spin ice model for reservoir computing. They measure useful quantities such as kernel quality \\(K\\) (ability to separate inputs) and generalization capabilities \\(G\\) (how similar inputs yield similar results). Because both are needed for computation according to the authors, they also compute the computational capacity \\(Q = K - G\\).\nInput is a binary stream and is encoded in the following way: 0 is coded as and angle \\(\\phi_0\\) of the magnetic field and 1 is coded with \\(\\phi_1 = \\phi_0 + 90°\\). The bit streams are 100 bits, and for measuring \\(K\\) they use 220 random sequences and for \\(G\\) 220 sequences with 40 random bits and the rest never changes.\nThey show good results in term of computational capacity and possibility to coarse-grain by taking the mean value of magnets to create a large cell. It seems therefore that ASI are reasonably good computers according to those reservoir computing metrics and show evidence of slowly fading memory. The computational capacity is also scalable with the number of nodes and accessible at both the large and small scales.\nBibliography Jensen, Johannes H., and Gunnar Tufte. July 1, 2020. \"Reservoir Computing in Artificial Spin Ice\". Artificial Life Conference Proceedings 32 (July). MIT Press:376–83. DOI.","title":"Reservoir Computing in Artificial Spin Ice by Jensen, J. H., \u0026 Tufte, G. (2020)","url":"https://hugocisneros.com/notes/jensenreservoircomputingartificial2020/"}
    
    , 
    
    {"body":" tags ALife 2020, Cellular automata, Autopoiesis source (Cika et al. 2020)  Summary This paper is about the possible resistance of GoL patterns to perturbations and the structures that could enable this to happen. They also want to know if resilience is a universal property of computational systems.\nThey test two types of resilience:\n Additive (add one or two live cells to the pattern) Negative (\u0026ldquo;kill\u0026rdquo; one or two live cells from the pattern)  They use 3 metrics for resilience:\n Equality: is the resulting pattern identical? Inclusion: is the resulting pattern larger? Cosine: amount of overlap between the two patterns.  Still life patterns were ranked according to the similarity metric, and this showed that a still life that ranks high on one metric rarely rank high in other metrics. Moreover, no still life was most resilient to more than one type of perturbation.\nStill life seem to tend towards brittleness. Transient lengths were no longer than 2 steps most of the time. Symmetry was not found to help resilience, but patterns with density close to 1/2 seemed more resilient.\n Example pattern from the paper: green cells represent perturbations the pattern can resist to, and yellow cells to perturbations that will break the pattern.   Bibliography Cika, Arta, Elissa Cohen, Germán Kruszewski, Luther Seet, Patrick Steinmann, and Wenqian Yin. July 1, 2020. \"Resilient Life: An Exploration of Perturbed Autopoietic Patterns in Conway’s Game of Life\". Artificial Life Conference Proceedings 32 (July). MIT Press:656–64. DOI.","title":"Resilient Life: An Exploration of Perturbed Autopoietic Patterns in Conway's Game of Life...","url":"https://hugocisneros.com/notes/cikaresilientlifeexploration2020/"}
    
    , 
    
    {"body":" source (Grbic and Risi 2020) tags Meta-learning, Reinforcement learning, ALife 2020  Summary In RL an important goal is to find agents that can quickly adapt to changing environments while avoiding unsafe states. However, in deep RL, there is often noise added to explore the action space: this can lead to unsafe part of the state-action space.\n Slide from the Alife talk   The meta-learning setting of MAML is adapted to RL, with a policy network learning the policy in a standard way and a \u0026ldquo;instinctual network\u0026rdquo; which is fixed for a group of tasks and modulates the regular policy with its own action vector.\nThey show results on a navigation tasks with and without hazards and with and without instincts. It seems that instincts makes convergence slower when there are no hazards in the navigation task but allows to reach better fitness in the presence of hazards.\nBibliography Grbic, Djordje, and Sebastian Risi. May 6, 2020. \"Safe Reinforcement Learning through Meta-Learned Instincts\". arXiv:2005.03233 [Cs]. http://arxiv.org/abs/2005.03233.","title":"Safe Reinforcement Learning through Meta-learned Instincts by Grbic, D., \u0026 Risi, S. (2020)","url":"https://hugocisneros.com/notes/grbicsafereinforcementlearning2020/"}
    
    , 
    
    {"body":" tags Open-ended Evolution source (Sayama 2011)  Summary Comments Bibliography Sayama, Hiroki. April 2011. \"Seeking Open-Ended Evolution in Swarm Chemistry\". In 2011 IEEE Symposium on Artificial Life (ALIFE), 186–93. Paris, France: IEEE. DOI.","title":"Seeking open-ended evolution in Swarm Chemistry by Sayama, H. (2011)","url":"https://hugocisneros.com/notes/sayamaseekingopenendedevolution2011/"}
    
    , 
    
    {"body":" tags Chemical reaction network, Biological life source (Horowitz and England 2017)  Summary Comments Bibliography Horowitz, Jordan M., and Jeremy L. England. July 18, 2017. \"Spontaneous Fine-Tuning to Environment in Many-Species Chemical Reaction Networks\". Proceedings of the National Academy of Sciences 114 (29). National Academy of Sciences:7565–70. DOI.","title":"Spontaneous fine-tuning to environment in many-species chemical reaction networks by...","url":"https://hugocisneros.com/notes/horowitzspontaneousfinetuningenvironment2017/"}
    
    , 
    
    {"body":" tags Complexity, Complex Systems source (Simon 1962)  Complex systems  In such systems, the whole is more than the sum of the parts, not in an ultimate, metaphysical sense, but in the important pragmatic sense that, given the properties of the parts and the laws of their interaction, it is not a trivial matter to infer the properties of the whole. In the face of complexity, an in-principle reductionist may be at the same time a pragmatic holist.\n Complexity as hierarchy Hierarchy is one of the central structural schemes of complexity.\nStructures of a complex system are made of interrelated substructures, each of which are also made of subsystems, etc. Until some elementary particle level is reached.\n In most systems in nature, it is somewhat arbitrary as to where we leave off the partitioning, and what subsystems we take as elementary.\n Different things might be considered elementary depending on what is being studied. Ex: cells, stars, atoms can all be used as elementary subsystems for biology, astronomy and chemistry.\n Most physical and biological hierarchies are described in spatial terms. We detect the organelles in a cell in the way we detect the raisins in a cake \u0026mdash; they are \u0026ldquo;visibly\u0026rdquo; differentiated substructures localized spatially in the larger structure. On the other hand, we propose to identify social hierarchies not by observing who lives close to whom but by observing who interacts with whom. These two points of view can be reconciled by defining hierarchy in terms of intensity of interaction, but observing that in most biological and physical systems relatively intense interaction implies relative spatial propinquity.\n Complex systems and emergence through evolutionary processes  The \u0026ldquo;improbability\u0026rdquo; of evolution has nothing to do with this quantity of entropy, which is produced by every bacterial cell every generation. The irrelevance of quantity of information, in this sense, to speed of evolution can also be seen from the fact that exactly as much information is required to \u0026ldquo;copy\u0026rdquo; a cell through the reproductive process as to produce the first cell through evolution.\n It is much easier to create complex hierarchies with Evolution, because subsystems are stable stepping stones from which new larger system can emerge. On the other hand, creating a very complex system from scratch is very unlikely.\nMoreover, there is selectivity in the evolutionary process, mainly due to two causes:\n Building blocks are stable, and passively guide further evolution Reproduction is possible in many complex systems, allowing transmission of experience from past complex hierarchies.  The argument can be turned around by saying that predominance of hierarchies in complex systems is simply a result of properties of the evolutionary process.\nDynamic properties of hierarchically-organized systems Some systems are decomposable. This means that it can be seen as a sum of independent subsystems made of elementary particles. This is often not very accurate and we can also use the theory of nearly decomposable systems, where subsystems interact weakly.\nThis is often useful for separating high-frequency dynamics (usually within the subsystems) of a hierarchy from its low-frequency dynamics (interactions between subsystems).\nRelations between complex systems and their descriptions For nearly decomposable systems, little information is lost by representing them as hierarchies.\n If there are important systems in the world that are complex without being hierarchic, they may to a considerable extent escape our observation and our understanding. Analysis of their behavior would involve such detailed knowledge and calculation of the interactions of their elementary parts that it would be beyond our capacities of memory or computation.\n Complex systems often admit simple descriptions (relative to the initial complexity). One of the main simplification mechanism is redundancy.\n If genetic material is a program \u0026mdash; viewed in its relation to the organism \u0026mdash; it is a program with special and peculiar properties. First, it is a self-reproducing program ; we have already considered its possible copying mechanism. Second, it is a program that has developed by Darwinian evolution. On the basis of our watchmaker\u0026rsquo;s argument, we may assert that many of its ancestors were also viable programs \u0026mdash; programs for the subassemblies.\n Ontogeny recapitulates phylogeny: some problem can be reduced to previously solved problems. Evolution can take solutions to previous problems and use it to solve new problems.\n How complex or simple a structure is depends critically upon the way in which we describe it. Most of the complex structures found in the world are enormously redundant, and we can use this redundancy to simplify their description. But to use it, to achieve the simplification, we must find the right representation. The notion of substituting a process description for a state description of nature has played a central role in the development of modern science. Dynamic laws, expressed in the form of systems of differential or difference equations, have in a large number of cases provided the clue for the simple description of the complex. In the preceding paragraphs I have tried to show that this characteristic of scientific inquiry is not accidental or superficial. The correlation between state description and process description is basic to the functioning of any adaptive organism, to its capacity for acting purposefully upon its environment. Our present-day understanding of genetic mechanisms suggests that even in describing itself the multi-cellular organism finds a process description \u0026mdash; a genetically encoded program \u0026mdash; to be the parsimonious and useful representation.\n Bibliography Simon, Herbert A.. 1962. \"The Architecture of Complexity\". Proceedings of the American Philosophical Society 106 (6). American Philosophical Society:467–82. https://www.jstor.org/stable/985254.","title":"The Architecture of Complexity by Simon, H. A. (1962)","url":"https://hugocisneros.com/notes/simonarchitecturecomplexity1962/"}
    
    , 
    
    {"body":" tags Cellular automata source (Li, Packard, and Langton 1990)  Summary This foundational paper follows Langton\u0026rsquo;s work on chaos and the lambda parameter. It uses information-theoretic measures to try and understand the structure of the space of CA rules. The authors come up with a classification in 6 classes:\n Spatially homogeneous fixed points Spatially inhomogeneous fixed points Periodic behavior Locally chaotic behavior Chaotic behavior Complex behavior  Wolfram\u0026rsquo;s class I is equivalent to class 1, class II is equivalent to class 2, 3 and 4. Class III and IV are the same as class 5 and 6.\nComments This literature seems relevant to cellular automata classification. I\u0026rsquo;m still not sure about this and will need to think about it. This is certainly one of the first examples of work on these questions.\nBibliography Li, Wentian, Norman H. Packard, and Chris G. Langton. September 2, 1990. \"Transition Phenomena in Cellular Automata Rule Space\". Physica D: Nonlinear Phenomena 45 (1):77–94. DOI.","title":"Transition phenomena in cellular automata rule space by Li, W., Packard, N. H., \u0026 Langton,...","url":"https://hugocisneros.com/notes/litransitionphenomenacellular1990/"}
    
    , 
    
    {"body":" tags Neural networks, Machine learning  ","title":"Recurrent neural networks","url":"https://hugocisneros.com/notes/recurrent_neural_networks/"}
    
    , 
    
    {"body":"","title":"Algorithmic Information theory","url":"https://hugocisneros.com/notes/algorithmic_information_theory/"}
    
    , 
    
    {"body":" tags Neural networks  ","title":"Convolutional neural networks","url":"https://hugocisneros.com/notes/convolutional_neural_networks/"}
    
    , 
    
    {"body":" tags Logic resources Stanford encyclopedia of Philosophy  First incompleteness theorem Any consistent formal system F within which a certain amount of elementary arithmetic can be carried out is incomplete; i.e., there are statements of the language of F which can neither be proved nor disproved in F.\nPanu Raatikainen\n   This theorem was followed by several closely related theorems, such as Turing\u0026rsquo;s Halting problem\n","title":"Gödel's theorem","url":"https://hugocisneros.com/notes/godel_s_theorem/"}
    
    , 
    
    {"body":" tags Computability theory, Algorithmic Information theory, Halting problem  ","title":"Halting probability","url":"https://hugocisneros.com/notes/halting_probability/"}
    
    , 
    
    {"body":" tags Applied maths  Definition The KL divergence is not symmetric. For \\(P, Q\\) defined on the same probability space \\(\\mathcal{X}\\), KL of \\(Q\\) from \\(P\\) is \\[ KL(P, Q) = \\sum_{x \\in \\mathcal{X}} P(x) \\log\\left( \\frac{P(x)}{Q(x)} \\right) \\]\nIt has two main interpretations:\n It is the information gain from using the right probability distribution \\(P\\) instead of \\(Q\\) or the amount of information lost by approximating \\(P\\) with \\(Q\\). The average difference in code length for a sequence following \\(P\\) and using a code optimized for \\(Q\\) to encode it.  Forward and reverse KL Eric Jang\u0026rsquo;s blog has an interesting visual explanation of the difference between forward and backward KL.\n Difference between forward and backward KL    So in summary, minimizing forward-KL \u0026ldquo;stretches\u0026rdquo; your variational distribution \\(Q(Z)\\) to cover over the entire \\(P(Z)\\) like a tarp, while minimizing reverse-KL \u0026ldquo;squeezes\u0026rdquo; the \\(Q(Z)\\) under \\(P(Z)\\).\n ","title":"Kullback-leibler divergence","url":"https://hugocisneros.com/notes/kullback_leibler_divergence/"}
    
    , 
    
    {"body":"From Sara Walker\u0026rsquo;s keynote at Alife 2020: The Natural History of Information:\n Life is a process whereby information structures matter across space and time.\n Why should life be an emergent process? An answer from (Krakauer et al. 2020):\n The fact that physics and chemistry are universal—ongoing in stars, solar systems, and galaxies—whereas to the best of our knowledge biology is exclusively a property of earth, supports the view that life is emergent.\n Bibliography Krakauer, David, Nils Bertschinger, Eckehard Olbrich, Jessica C. Flack, and Nihat Ay. June 1, 2020. \"The Information Theory of Individuality\". Theory in Biosciences 139 (2):209–23. DOI.","title":"Life","url":"https://hugocisneros.com/notes/life/"}
    
    , 
    
    {"body":" tags Search, Neural networks  Neural architecture search (NAS) is a method for finding neural networks architectures. It is usually based on three main components:\n Search space Type of network that can be built. Search strategy The approach for exploring the space. Performance estimation strategy The way the performance of a constructed neural network is evaluated (without actually building it or training/running it).  Reinforcement learning-based NAS The original idea was called Neural architecture search and is based on the use of a RNN as a controller and generator of architectures. The search-space is pre-defined and explored in a rigid way. (Zoph and Le 2017).\nThe process of generating architectures from the first article was extremely lengthy and replaced later by a more constrained search. (Zoph et al. 2018).\nRecent ideas include the use of parameter sharing across architectures because the main bottleneck of previous techniques was essentially in the training of each child model. This results in significant speedup of RL-based NAS. (Pham et al. 2018)\nNeuroevolution This field is more focused on evolution neural network through evolutionary methods such as e.g genetic algorithms. One of the main work that made that field popular is NEAT (Stanley and Miikkulainen 2002).\nBibliography Pham, Hieu, Melody Y. Guan, Barret Zoph, Quoc V. Le, and Jeff Dean. February 11, 2018. \"Efficient Neural Architecture Search via Parameter Sharing\". arXiv:1802.03268 [Cs, Stat]. http://arxiv.org/abs/1802.03268. Stanley, Kenneth O., and Risto Miikkulainen. June 2002. \u0026ldquo;Evolving Neural Networks through Augmenting Topologies\u0026rdquo;. Evolutionary Computation 10 (2):99–127. DOI.\nZoph, Barret, Vijay Vasudevan, Jonathon Shlens, and Quoc V. Le. April 11, 2018. \u0026ldquo;Learning Transferable Architectures for Scalable Image Recognition\u0026rdquo;. arXiv:1707.07012 [Cs, Stat]. http://arxiv.org/abs/1707.07012.\nZoph, Barret, and Quoc V. Le. February 15, 2017. \u0026ldquo;Neural Architecture Search with Reinforcement Learning\u0026rdquo;. arXiv:1611.01578 [Cs]. http://arxiv.org/abs/1611.01578.\n","title":"Neural architecture search","url":"https://hugocisneros.com/notes/neural_architecture_search/"}
    
    , 
    
    {"body":" tags Machine learning, Language  NLP is about creating algorithms that can manipulate and use language. It is often thought that having functioning NLP algorithms that provably \u0026ldquo;understand\u0026rdquo; language would be equivalent to reaching human-level Artificial Intelligence.\nTasks Language modeling Text classification Question answering Data manipulation There are several ways to encode text data.\n One-hot encoding of characters One-hot encoding of words Byte-pair encoding which can be seen as being a compromise between the two  ","title":"NLP","url":"https://hugocisneros.com/notes/nlp/"}
    
    , 
    
    {"body":" tags Applied maths, Optimization  ","title":"Ordinary least squares","url":"https://hugocisneros.com/notes/ordinary_least_squares/"}
    
    , 
    
    {"body":" tags Coding  In-place batch file manipulation Delete the same line in many files Let\u0026rsquo;s start by creating a simple text file with three lines. This is what it looks like:\necho \u0026#34;Hello\\nto the\\nworld\u0026#34; \u0026gt; test.txt cat test.txt Hello to the world We use sed to remove lines in the file matching some regex. The -i.bak option ensures the file is modified in place.\nsed -i.bak \u0026#39;/to the/d\u0026#39; test.txt cat test.txt Hello world We get the file with the removed line in place of our original file. The same principle applies to several files and this allows batching.\n","title":"Sed utility","url":"https://hugocisneros.com/notes/sed_utility/"}
    
    , 
    
    {"body":" tags Artificial intelligence test  This is probably one of the most famous test for artificial intelligence. It was elaborated by Alan Turing.\n","title":"Turing test","url":"https://hugocisneros.com/notes/turing_test/"}
    
    , 
    
    {"body":"","title":"Writing","url":"https://hugocisneros.com/notes/writing/"}
    
    , 
    
    {"body":" tags Programming, Networking  An incredible resource for low-level network programming: Beej\u0026rsquo;s guide to network programming.\n","title":"Network programming","url":"https://hugocisneros.com/notes/network_programming/"}
    
    , 
    
    {"body":" tags Programming  ","title":"Networking","url":"https://hugocisneros.com/notes/networking/"}
    
    , 
    
    {"body":" tags Computer science  ","title":"Lambda calculus","url":"https://hugocisneros.com/notes/lambda_calculus/"}
    
    , 
    
    {"body":" tags Cellular automata, John Von Neumann  ","title":"Von Neumann's self-reproducing CA","url":"https://hugocisneros.com/notes/von_neumann_s_self_reproducing_ca/"}
    
    , 
    
    {"body":" tags Applied maths, Optimization  ","title":"Automatic differentiation","url":"https://hugocisneros.com/notes/automatic_differentiation/"}
    
    , 
    
    {"body":" source Link tags Artificial Intelligence, Coding author Marvin Minsky  What can computers do?  The fallacy under discussion is the widespread superstition that we can\u0026rsquo;t write a computer program to do something unless one has an extremely clear, precise formulation of what is to be done, and exactly how to do it.\n It is generally believed that computer programs cannot be more than a set of rules and instructions for what to do in a given computer state. While this is true, it falls into the common pitfall of thinking of the whole as the sum of its parts\n However, for more advanced processes, while \u0026ldquo;perfectly\u0026rdquo; true in one sense, it would be as correct to say that \u0026ldquo;houses are nothing but arrangements of construction materials\u0026rdquo; or \u0026ldquo;books are merely long strings of words.\u0026rdquo;\n Minsky discusses three ways to see a computer program\nA program as a sequence of instruction to be obeyed  The most common and simple-minded view is that a computer program is a sequence of clear-cut operations to be performed on some data.\n A program as a court of law The author now gives an example program that can accumulate facts from user input. A disambiguation \u0026ldquo;part\u0026rdquo; of the program acts as a court, weighing different facts against previously accumulated knowledge and adding it to its database.\nIn large programs with many such subprograms, it is clear that the whole isn\u0026rsquo;t behaving like a sequence anymore. The programmer only constructs the laws and rules that will guide those courts but usually cannot predict or understand the details of operations.\n For try as we may, we rarely can fully envision, in advance, all the details of [the subprograms'] interactions. For that, after all, is why we need computers.\n A program as a collection of statements of advice  The great illusion shared not only by all terrified humanists but also by most computer \u0026ldquo;experts,\u0026rdquo; that programming is an inherently precise and rigid medium of expression, is based on an elementary confusion between form and content. If poets were required to write in units of fourteen lines, it wouldn\u0026rsquo;t make them more precise; if composers had to use all twelve tones, it wouldn\u0026rsquo;t constrain the overall forms; if designers had to use only fourth order surfaces no ‑one would notice it much! It is humorous, then, to find such unanimity about how the rather stiff grammar of (the older) programming language makes for precision in describing processes.\n It is interesting to note that it seems that in Minsky\u0026rsquo;s mind, programming would have more flexible syntax in the future approaching natural language more accurately.\nI think the following quote, referring to a \u0026ldquo;missionaries and cannibal\u0026rdquo; solving program, is impressive. The program tries several solutions and prefers those making progress towards moving people to the other side of the river. An outsider can tell the program if its making progress or not. This sounds to me like machine learning, which was in its early days at the time.\n Some other function may have been modified so that, in certain situations, \u0026ldquo;progress\u0026rdquo; won\u0026rsquo;t get to evaluate the situation at all, and someone might get eaten anyway. If that happened, the outsider would try to guess why.\nHe would have the options (1) of thoroughly understanding the existing program and \u0026ldquo;really fixing\u0026rdquo; the trouble, or (2) of entering anew advice statement describing what he imagines to be the defective situation and telling the program not to move the missionary into the position of being eaten. When a program grows in power by an evolution of partially‑understood patches and fixes, the programmer begins to lose track of internal details and can no longer predict what will happen—and begins to hope instead of know, watching the program as though it were an individual of unpredictable behavior.\n Programming is more than a bunch of instructions  In each domain of uncertainty I am at liberty to specify (instead of particular procedures) procedure‑generators, selection rules, courts of advice concerning choices, etc. So the behavior can have wide ranges‑it need never twice follow the same lines, it can be made to cover roughly the same latitude of tolerance that lies in the author\u0026rsquo;s mind.\n A programmer, by giving instructions, is specifying a frame in which a program will develop. I believe most very interesting programs are actually creating something new that can be of interest to the programmer itself.\nData analysis is a simple form of this phenomenon. A programmer writes some code to extract word frequency from a piece of text, and get some insights he could not have got before. I believe that open-ended evolution would be the ultimate form of a program impressing the programmer. Though only evolving within the frame imposed by the programmer, such a program would create endless and more complex novelty.\n To take advantage of the unsurpassed flexibility of this medium requires tremendous skill‑technical, intellectual, and esthetic. To constrain the behavior of a program precisely to a range may be very hard, just as a writer will need some skill to express just a certain degree of ambiguity. A computer is like a violin. You can imagine a novice trying first a phonograph and then a violin. The latter, he says, sounds terrible. That is the argument we have heard from our humanists and most of our computer scientists. Computer programs are good, they say, for particular purposes, but they aren\u0026rsquo;t flexible. Neither is a violin, or a typewriter, until you learn how to use it.\n ","title":"Why programming is a good medium for expressing poorly understood and sloppily-formulated...","url":"https://hugocisneros.com/notes/why_programming_is_a_good_medium/"}
    
    , 
    
    {"body":" source Link tags Biological life, Evolution  ","title":"Article: Why Sex? Biologists Find New Explanations","url":"https://hugocisneros.com/notes/why_sex_biologists_find_new_explanations/"}
    
    , 
    
    {"body":" tags Computer science resources Wikipedia  It is an adage which states that software is getting slower more rapidly than hardware is becoming faster.\n","title":"Wirth's law","url":"https://hugocisneros.com/notes/wirth_s_law/"}
    
    , 
    
    {"body":" tags Logic  ","title":"3-SAT","url":"https://hugocisneros.com/notes/3_sat/"}
    
    , 
    
    {"body":" tags Mathematics, Computer science  ","title":"Graphs","url":"https://hugocisneros.com/notes/graphs/"}
    
    , 
    
    {"body":" tags Graph neural networks  ","title":"Message-passing graph networks","url":"https://hugocisneros.com/notes/message_passing_graph_networks/"}
    
    , 
    
    {"body":" tags Graph neural networks, Attention  ","title":"Attention graph networks","url":"https://hugocisneros.com/notes/attention_graph_networks/"}
    
    , 
    
    {"body":" Bottomless wonders spring from simple rules, which are repeated without end.\n \u0026mdash; Mandelbrot, ~1980\nWhen we talk about complex systems in time, we often used the term complex dynamical systems.\nExample of complex systems  The economy (Anderson and Evolutionary Paths of the Global Economy Workshop 1996) Boolean networks Cellular automata Neural networks  Can complex systems evolve? The biosphere is a striking example of very large and intricate complex system. One of its most impressive feature is the fact that it has allowed for intelligent life to develop through evolution.\nCan this kind of incredible events happen within other complex systems such as cellular automata?\nBibliography Anderson, Philip W., and Evolutionary Paths of the Global Economy Workshop, eds. 1996. _The Economy as an Evolving Complex System: The Proceedings of the Evolutionary Paths of the Global Economy Workshop, Held September, 1987 in Santa Fe, New Mexico_. 8. print. Santa Fe Institute Studies in the Sciences of Complexity 5. Reading, Mass.: Addison-Wesley Publ. Co.","title":"Complex Systems","url":"https://hugocisneros.com/notes/complex_systems/"}
    
    , 
    
    {"body":" tags Computer science  Compilation is the act of converting code from one programming language to another.\nSome compiled languages  C Programming language Rust C++  ","title":"Compilation","url":"https://hugocisneros.com/notes/compilation/"}
    
    , 
    
    {"body":" tags Coding, NLP  ","title":"Regular expressions","url":"https://hugocisneros.com/notes/regular_expressions/"}
    
    , 
    
    {"body":" tags Search  ","title":"Novelty search","url":"https://hugocisneros.com/notes/novelty_search/"}
    
    , 
    
    {"body":" tags Algorithm  ","title":"Search algorithms","url":"https://hugocisneros.com/notes/search_algorithms/"}
    
    , 
    
    {"body":" tags Open-ended Evolution, Artificial Intelligence speaker Kenneth Stanley source Youtube  Why should we care about open-endedness?  There is nothing you can point to that would be worth coming back to a billions year from now to see what happened. And yet, we are inside of such a system and such a system produced us.\n Evolution is a seemingly open-ended process for which we only have access to a single run\u0026rsquo;s current and past results. It is this algorithm capable of generating endless surprises over the course of billions of years.\nBut open-endedness also happens outside of \u0026ldquo;strict\u0026rdquo; evolution. It has been in the history of art, science, technology. We as humans are both a product of an open-ended process and also open-ended ourselves.\nHow to achieve it? No algorithm yet exists worth running forever. We haven\u0026rsquo;t been able to create open-endedness yet.\n Usually there is an objective function which means the algorithm converges or get stuck. Even other more innovative ideas end up reaching diminishing returns (co-evolution, self-play, GANs, Alife worlds) This is true for deep learning, optimization, evolution, etc.  So far, it seems we still don\u0026rsquo;t know something.\nEarly insights with NEAT What this algorithm tells us is: for a thing to be open-ended, it needs to be unbounded. It has to be possible to make more complex things.\nPicbreeder An experiment about letting people \u0026ldquo;breed\u0026rdquo; pictures (with NEAT evolving CPPNs under the hood).\nAn important fact is people were never actively looking for the final product when obtaining interesting pictures.\nNovelty search The idea is to do divergent search instead of convergent search and remove the objective function. It sometimes appear to solve better than optimization.\nThere is also a need for stepping stone collectors (SSCs). This is a process that store the results in a growing archive. The more stepping stones you have, the more places you can get to. In a way, picbreeder and natural evolution are stepping-stone collectors.\nThis eventually led to Quality diversity. This transition happened because there was still a need to communicate if the system is doing what we want.\nHowever, QD is certainly not one of those algorithms worth running for a billion years. The space of possibilities gets filled progressively and there is no new possibility arising.\nTowards achieving Earth\u0026rsquo;s creativity On Earth, evolution is simultaneously creating new opportunities and possibilities and searching through them.\nThis idea led to Minimal Criterion Co-evolution algorithms. They used the example of mazes and neural networks that drive robots through the mazes. Those two form two populations that can evolve. This is not really like what happens in nature where a tree is both a \u0026ldquo;problem\u0026rdquo; and a \u0026ldquo;solution\u0026rdquo;, but is OK in a machine learning context. There is a minimal criterion only:\n The maze has to be solved The solver has to solve mazes  When any of those pass the minimal criterion, they get to reproduce. This is inspired by Nature where the minimal criterion is reproduction.\nThis MCC seems to give algorithms worth running for several years.\nRecent work added a resource limitation:\n A maze can only be used a finite amount of time by maze solvers in order to solve the minimal criterion.\n This pushes towards diversity in a much better way than enforced speciation.\n","title":"Talk: The Importance of Open-Endedness in AI and Machine Learning","url":"https://hugocisneros.com/notes/talk_the_importance_of_open_endedness_in_ai_and_machine_learning/"}
    
    , 
    
    {"body":" tags Search, Open-ended Evolution  ","title":"Picbreeder","url":"https://hugocisneros.com/notes/picbreeder/"}
    
    , 
    
    {"body":" tags Applied maths  This method was introduced as a way to speed-up kernel machines in (Williams and Seeger 2001).\nBibliography Williams, Christopher, and Matthias Seeger. 2001. \"Using the Nyström Method to Speed up Kernel Machines\". In Advances in Neural Information Processing Systems, edited by T. Leen, T. Dietterich, and V. Tresp, 13:682–88. MIT Press. https://proceedings.neurips.cc/paper/2000/file/19de10adbaa1b2ee13f77f679fa1483a-Paper.pdf.","title":"Nyström method","url":"https://hugocisneros.com/notes/nystrom_method/"}
    
    , 
    
    {"body":" tags Kernel Methods  ","title":"Kernel Machine","url":"https://hugocisneros.com/notes/kernel_machine/"}
    
    , 
    
    {"body":" tags Neural networks  Transformers are a neural network architecture based on a mechanism called Attention.\nThey have been particularly successful for NLP applications and also penetrated other fields of machine learning such as Computer vision.\n","title":"Transformers","url":"https://hugocisneros.com/notes/transformers/"}
    
    , 
    
    {"body":" tags Neural networks, Optimization authors Francis Bach, Lénaïc Chizat source Francis Bach\u0026rsquo;s blog  In the rest, we use the mathematical definition of a neural network from Neural networks.\nTwo layer neural network Even simple neural network models are very difficult to analyze. This is primarily due to two difficulties:\n Non-linearity: the problem is typically non-convex, which in general is a bad thing in optimization. Overparametrization: there are often a lot of parameters, sometimes many more parameters than observations.  Results presented here are actually taking advantage of overparametrization, with \\(m\\rightarrow \\infty\\) and two key properties of the problem.\n Separability: The problem can be decomposed in a sum of terms independently parametrized in \\(\\omega_i = (a_i, b_i)\\), with \\(h = \\frac{1}{m} \\sum_{i=1}^m \\Phi(\\omega_i)\\) where \\(\\Phi : \\mathbb{R}^p \\rightarrow \\mathcal{F}\\) and \\(\\mathcal{F}\\) is a space of functions. Here, \\(p = d+1\\) and \\[ \\Phi(w)(x) = a (b^\\top x)_+. \\] This part is only true for two-layer neural networks however. Homogeneity: ReLU is positively homogeneous and \\(\\Phi\\) is 2-homogeneous, meaning that for \\(\\omega = (a, b)\\), \\(\\Phi(\\lambda\\omega) = \\lambda^2 \\Phi(\\omega)\\).  Infinitely wide neural network The goal is to minimize a functional \\(R\\) w.r.t function \\(h\\)\n\\[R(h) = \\mathbb{E}_{p(x, y)} \\left[ \\ell(y, h(x))\\right]\\]\nwith \\(\\ell(y, h(x))\\) the loss incurred by predicting \\(h(x)\\) when the true label was \\(y\\). \\(R\\) is assumed to be convex in its second argument, like least-square or logistic losses.\nWe re-use the two layer neural network formulation above to obtain\n\\[ G(W) = G(w_1,\\dots,w_m) = R \\Big( \\frac{1}{m} \\sum_{i=1}^m \\Phi(w_i) \\Big), \\]\nwhich can be seen as the minimization of\n\\[ F(\\mu) = R \\Big( \\int_{\\mathbb{R}^p} \\Phi(w) d\\mu(w) \\Big),\\]\nwith respect to a probability measure which is a sum of Dirac measures at \\(w_i\\), \\(\\mu = \\frac{1}{m} \\sum_{i = 1}^m \\delta(w_i)\\).\nThis makes the minimization problem much nicer since the set of measures is convex and \\(h = \\int_{\\mathbb{R}^p} \\Phi(w) d\\mu(w)\\) is linear in \\(\\mu\\). However, because the set of measures is infinite dimensional, the choice of new neurons to minimize \\(F\\) is very difficult (NP-hard for a threshold activation, polynomial but with very high complexity for ReLU). In practise, SGD is used.\nGradient flow The gradient flow is defined by\n\\[ \\dot{W} = - m \\nabla G(W) \\]\nOn a metric space \\(\\mathcal{X}\\), a gradient flow can be defined for a function \\(f\\) and seen a the limit of taking infinitesimal steps of length \\(\\gamma\\), defining a sequence \\((x_k)\\)\n\\[ x_{k+1} \\in \\arg\\min_{x\\mathcal{x}} f(x) + \\dfrac{1}{2\\gamma} d(x, x_k)^2 \\]\nThe smaller the step, the closer this sequence is to the actual gradient flow.\nEuler discretization In \\(\\mathbb{R}^d\\) and a continuously differentiable \\(f\\), \\(x_{k + 1} = x_k - \\gamma f'(x_k) + o(\\gamma)\\), we simply obtain Euler steps.\nVector space gradient flows on probability measures  Probability measures are a convex subset of measures with finite total variation, which is equal to the $ℓ_1$-norm between densities when the two probability measures have densities with respect to the same base measure. It is a normed vector space for which we could derive our first type of gradient flow, which can be seen as a continuous version of Frank-Wolfe algorithm, where atoms are added one by one, until convergence.\n However, the flow of measures cannot be approximated by the set of neurons of the network.\nWasserstein gradient flow on probability measures The Wasserstein distance is directly related to Optimal transport. For two empirical measures with the same number of points, it is the minimal sum of squared distances between pairs of point over all possible permutations.\nThe Wasserstein gradient flow is written\n\\[ \\dot{w}_i = \\ – \\nabla \\Phi(w_i) \\nabla R\\Big(\\int_{\\mathbb{R}^p} \\Phi d\\mu \\Big), \\]\nGlobal convergence Under two main assumptions (plus additional technical assumptions), if the Wasserstein gradient flow converges to a measure, it has to be the global minimum of the function \\(F\\) defined above.\nThe two assumptions are:\n Homogeneity of \\(\\Phi: \\mathbb{R}^p \\rightarrow \\mathcal{F}\\) $w_i$s are uniformly distributed on the sphere  The authors show on simple examples that for data generated with a neural network with \\(m_0 = 5\\) neurons. The result above suggest that with large \\(m\\) a neural network should converge to the original neurons. Surprisingly, relatively small $m$s are already very good at doing that.\n","title":"Gradient descent for wide two-layer neural networks – I : Global convergence","url":"https://hugocisneros.com/notes/gradient_descent_for_wide_two_layer_neural_networks_i_global_convergence/"}
    
    , 
    
    {"body":" tags Gradient descent, Optimization  The gradient flow for a model parametrized by parameters \\(w\\) and a loss function \\(L\\) is written:\n\\[ \\dot{w} = - \\nabla L (w(t)) \\]\n","title":"Gradient flow","url":"https://hugocisneros.com/notes/gradient_flow/"}
    
    , 
    
    {"body":" tags Neural network training  ","title":"Double descent","url":"https://hugocisneros.com/notes/double_descent/"}
    
    , 
    
    {"body":" tags Machine learning, Online privacy  This is a kind of machine learning where one wants to train a model or perform inference without transmitting sensitive information.\nThis information could leak because of data transmission to an untrusted computing server, or because the model itself reveals the structure of its training data (Ateniese et al. 2013; Song, Ristenpart, and Shmatikov 2017).\nBibliography Ateniese, Giuseppe, Giovanni Felici, Luigi V. Mancini, Angelo Spognardi, Antonio Villani, and Domenico Vitali. June 19, 2013. \"Hacking Smart Machines with Smarter Ones: How to Extract Meaningful Data from Machine Learning Classifiers\". arXiv:1306.4447 [Cs, Stat]. http://arxiv.org/abs/1306.4447. Song, Congzheng, Thomas Ristenpart, and Vitaly Shmatikov. September 22, 2017. \u0026ldquo;Machine Learning Models That Remember Too Much\u0026rdquo;. arXiv:1709.07886 [Cs]. http://arxiv.org/abs/1709.07886.\n","title":"Privacy-preserving machine learning","url":"https://hugocisneros.com/notes/privacy_preserving_machine_learning/"}
    
    , 
    
    {"body":" tags Cryptography resources Vitalik Buterin\u0026rsquo;s blog  Principle The idea of homomorphic encryption is to encrypt data in such a way that, given a function \\(f\\) and a message to encrypt \\(x\\), \\(\\text{enc}(f(x)) = f(\\text{enc}(x))\\).\nThis idea is similar in spirit to Privacy-preserving machine learning, or federated learning, where one wants to obfuscate data while still being able to use it in a learning model. Here, one considers arbitrary functions.\n","title":"Homomorphic encryption","url":"https://hugocisneros.com/notes/fully_homomorphic_encryption/"}
    
    , 
    
    {"body":" tags Machine learning  Two-layers neural network Mathematically, a simple two-layers neural network with relu non-linearities can be written like below. For an input vector \\(x \\in \\mathbb{R}^D\\), \\(\\mathbf{a} = (a_1, \\cdots, a_N)\\in \\mathbb{R}^M\\) are the output weights, \\(\\mathbf{b} = (b_1, \\cdots, b_N)\\in \\mathbb{R}^D\\) are the input weights\n\\[ h(x) = \\frac{1}{m} \\sum_{i=1}^m a_i \\max\\{ b_i^\\top x,0\\}, \\]\nUniversal approximation theorem Cybenko showed in 1989 that a neural network of arbitrary width with sigmoid activation function could approximate any continuous function (Cybenko 1989).\nBarron added rates of convergence by enforcing smoothness condition on the target function (Barron 1993).\nBibliography Barron, A. R.. May 1993. \"Universal Approximation Bounds for Superpositions of a Sigmoidal Function\". IEEE Transactions on Information Theory 39 (3):930–45. DOI. Cybenko, G.. December 1989. \u0026ldquo;Approximation by Superpositions of a Sigmoidal Function\u0026rdquo;. Mathematics of Control, Signals, and Systems 2 (4):303–14. DOI.\n","title":"Neural networks","url":"https://hugocisneros.com/notes/neural_networks/"}
    
    , 
    
    {"body":" tags Convolutional neural networks, Graph neural networks  ","title":"Graph convolutional networks","url":"https://hugocisneros.com/notes/graph_convolutional_networks/"}
    
    , 
    
    {"body":" tags Complexity  To study the complexity of various systems, researchers have come up with various metrics. They are based on several principles such as Information theory or Algorithmic Information theory. Many of these metrics are described in (Grassberger 1989).\nShannon entropy and Kolmogorov Complexity The paper (Grunwald and Vitanyi, n.d.) is a great description and analysis of two of the most important Complexity metrics:\n Shannon entropy Kolmogorov complexity  Information-theoretic metrics  Shannon entropy  AIT based metrics For a Universal computer \\(U\\) the algorithmic information of \\(S\\) relative to \\(U\\) is defined as the length of the shortest program that yields \\(S\\) on \\(U\\). \\[ C_U(S) = \\min_{Prog_U(S)} \\text{Len}[Prog_U(S)] \\]\nThis quantity is called algorithmic information, or Solomonoff–Kolmogorov–Chaitin complexity.\nCompression-based metrics It is not possible for a given sequence to estimate reliably its algorithmic information, because we cannot know if we have found the shortest description. A solution is to restrict the encoding method, and LZW algorithm complexity is one of them (Lempel and Ziv 1976).\nOthers  Epsilon machines Statistical complexity In (Cisneros, Sivic, and Mikolov 2019), we propose a complexity metric which is based on the compression quality of a local neural network based prediction model.  Bibliography Cisneros, Hugo, Josef Sivic, and Tomas Mikolov. December 2019. \"Evolving Structures in Complex Systems\". In 2019 IEEE Symposium Series on Computational Intelligence (SSCI), 230–37. Xiamen, China: IEEE. DOI. Grunwald, Peter, and Paul Vitanyi. n.d. \u0026ldquo;Shannon Information and Kolmogorov Complexity\u0026rdquo;, 51.\nLempel, A., and J. Ziv. January 1976. \u0026ldquo;On the Complexity of Finite Sequences\u0026rdquo;. IEEE Transactions on Information Theory 22 (1):75–81. DOI.\nGrassberger, Peter. 1989. \u0026ldquo;Randomness, Information, and Complexity\u0026rdquo;. In Proceedings of the 5th Mexican School on Statistical Physics. http://arxiv.org/abs/1208.3459.\n","title":"Complexity metrics","url":"https://hugocisneros.com/notes/complexity_metrics/"}
    
    , 
    
    {"body":" tags Complexity, Cellular automata  Measuring complexity created by cellular automata is a vast subject.\nUsing Entropy In (Wuensche 1999), the author uses the entropy of rule table lookup frequencies to evaluate the complexity of a CA.\nBibliography Wuensche, Andrew. 1999. \"Classifying Cellular Automata Automatically: Finding Gliders, Filtering, and Relating Space-Time Patterns, Attractor Basins, and the Z Parameter\". Complexity 4 (3):47–66. 3.0.CO;2-V](https://doi.org/10.1002/(SICI)1099-0526(199901/02)4:3%3C47::AID-CPLX9%3E3.0.CO;2-V)\"DOI.","title":"Complexity of cellular automata","url":"https://hugocisneros.com/notes/complexity_of_cellular_automata/"}
    
    , 
    
    {"body":" tags Cryptography resources How Rainbow tables work  ","title":"Rainbow tables","url":"https://hugocisneros.com/notes/rainbow_tables/"}
    
    , 
    
    {"body":" tags Complexity, Self-organization  An early example of artificial self-replication is Von Neumann\u0026rsquo;s self-reproducing CA which is a cellular automaton.\nSelf-replication in neural networks can be done with neural network quines (Chang and Lipson 2018).\nBibliography Chang, Oscar, and Hod Lipson. May 24, 2018. \"Neural Network Quine\". arXiv:1803.05859 [Cs]. http://arxiv.org/abs/1803.05859.","title":"Self-replication","url":"https://hugocisneros.com/notes/self_replication/"}
    
    , 
    
    {"body":"The dirichlet energy of a continuous function on \\(\\mathbb{R}^d\\) is the \\(L^2\\) norm of its gradient.\nIn the case of a 2D graph, such as a cellular automaton or hopfield network, this can be discretized as the \\(L^2\\) norm of the difference along each edge.\n","title":"Dirichlet energy","url":"https://hugocisneros.com/notes/dirichlet_energy/"}
    
    , 
    
    {"body":"The Hadamard product is a mathematical name for element-wise multiplication of matrices.\n","title":"Hadamard product","url":"https://hugocisneros.com/notes/hadamard_product/"}
    
    , 
    
    {"body":" tags Applied maths, Signal processing  Wavelets are functions with specific properties that make them useful when dealing with images. They are used for lossy image compression.\nTypes of wavelets Haar wavelets Daubechies wavelets ","title":"Wavelets","url":"https://hugocisneros.com/notes/wavelets/"}
    
    , 
    
    {"body":" tags Applied maths  ","title":"Signal processing","url":"https://hugocisneros.com/notes/signal_processing/"}
    
    , 
    
    {"body":" tags Applied maths, Signal processing  Scale an image with no interpolation Imagemagick documentation\nconvert source.[png|gif|...] -scale 400% target.[png|gif|...] The scale option can also take integer parameters (without the percent sign) to indicate the target size.\nRemove metadata from an image Useful for preserving Online privacy when publishing images. Pictures taken with smartphones and other modern devices often contain large amounts of data about location, time and date and device type.\nExiftool `exiftool -all= image.jpg`\n","title":"Image processing","url":"https://hugocisneros.com/notes/image_processing/"}
    
    , 
    
    {"body":" tags Biological life, Artificial Intelligence  ","title":"Neuroscience","url":"https://hugocisneros.com/notes/neuroscience/"}
    
    , 
    
    {"body":" tags Neural networks, Machine learning, Optimization  Neural network training as development in program space A neural network as a whole can be seen as a dynamical system. Its state is the collection of its parameters, and its evolution function is the optimization step taken when training the network.\nIn such a framework, the goal of training the neural network is to reach a form of attractor further optimization steps don\u0026rsquo;t change the state of the neural network.\nThis attractor should correspond to useful functional properties for the network, a measured by a cost function. Meta-learning corresponds to learning the evolution function itself to make the dynamical system converge to better attractors faster.\nProgram evolution A neural network is a program, an algorithm. Its parameters specify a sequence of steps from input data to output prediction. Training a neural network is like moving in the algorithmic space towards programs with better performance according to a given cost function.\n","title":"Neural network training","url":"https://hugocisneros.com/notes/neural_network_training/"}
    
    , 
    
    {"body":" tags Applied maths, Physics  ","title":"Dynamical systems","url":"https://hugocisneros.com/notes/dynamical_systems/"}
    
    , 
    
    {"body":" tags Algorithm  ","title":"Stable marriage problem","url":"https://hugocisneros.com/notes/stable_marriage_problem/"}
    
    , 
    
    {"body":" tags Cellular automata, Turing-completeness  Rule 110 Elementary cellular automaton rule 110 is universal (Cook 2004).\nGame of Life Conway\u0026rsquo;s Game of Life has also been show to be Turing-complete. Gliders can be used to implement logic gates.\nA working computer in Game of Life\nBibliography Cook, Matthew. 2004. \"Universality in Elementary Cellular Automata\". Complex Systems, 40.","title":"Turing completeness of cellular automata","url":"https://hugocisneros.com/notes/turing_completeness_of_cellular_automata/"}
    
    , 
    
    {"body":" tags Cellular automata  Second-order CA Block CA ","title":"Reversible cellular automata","url":"https://hugocisneros.com/notes/reversible_cellular_automata/"}
    
    , 
    
    {"body":" tags Artificial intelligence test  It is a visual test used to estimate abstract reasoning. The patterns are often between 2x2 and 6x6 matrices of symbols. One of these symbols is usually left blank and supposed to be deduced from the others.\nThe overall concept is very similar to the Abstraction and Reasoning Corpus but is much more tied to human vision. This makes the range of possible tasks much larger but also harder to integrate in an algorithm. You already need a powerful computer vision system that can convert the matrix into a usable representation before you even try to implement reasoning.\n","title":"Raven's progressive matrices","url":"https://hugocisneros.com/notes/raven_s_progressive_matrices/"}
    
    , 
    
    {"body":" tags Computability theory, Computer science resources Wikipedia  The machine was invented by Alan Turing in 1936.\nGeneral definition A Turing Machine is usually composed of four main components:\n A tape divided into cells. This tape is the way the machine reads inputs, writes outputs and manipulates information (storing it, moving it, etc.). Each cell can contain any symbol of a predefined alphabet. It is also often presented as infinitely long on both sides. A head that can read or write a symbol from the tape at its current position. A register storing the current state of the machine, usually with special start_state and end_state. A table of instructions mapping the current state and current tape symbol to a specific triple action (each of the steps is optional):  Read/write a symbol in current position Move the head left or right Change the state    ","title":"Turing Machine","url":"https://hugocisneros.com/notes/turing_machine/"}
    
    , 
    
    {"body":" tags Computer science, Artificial Intelligence, Cryptography  ","title":"Alan Turing","url":"https://hugocisneros.com/notes/alan_turing/"}
    
    , 
    
    {"body":" tags Mathematics, Applied maths  ","title":"Optimization","url":"https://hugocisneros.com/notes/optimization/"}
    
    , 
    
    {"body":" tags Recurrent neural networks, Unsupervised learning resources Scholarpedia  Principle An echo state network is usually a standard RNN with fixed random weights. The output from this RNN is used as a high dimensional feature map to be fed into a machine learning system.\n(Jaeger 2004, 2012; Jaeger, Maass, and Principe 2007)\nBibliography Jaeger, Herbert, Wolfgang Maass, and Jose Principe. April 2007. \"Special Issue on Echo State Networks and Liquid State Machines\". Neural Networks 20 (3):287–89. DOI. Jaeger, H.. April 2, 2004. \u0026ldquo;Harnessing Nonlinearity: Predicting Chaotic Systems and Saving Energy in Wireless Communication\u0026rdquo;. Science 304 (5667):78–80. DOI.\nJaeger, Herbert. February 1, 2012. \u0026ldquo;Long Short-Term Memory in Echo State Networks: Details of a Simulation Study\u0026rdquo;. Jacobs University Bremen.\n","title":"Echo-state networks","url":"https://hugocisneros.com/notes/echo_state_networks/"}
    
    , 
    
    {"body":" tags Machine learning  ","title":"Unsupervised learning","url":"https://hugocisneros.com/notes/unsupervised_learning/"}
    
    , 
    
    {"body":" tags Programming languages, Coding  Code tips Categories to one-hot This is a handy technique but can be very resource intensive for large arrays.\nimport numpy as np a = np.random.randrange(5, size=10) one_hot_a = np.eye(5)[a] Side-output for jupyter notebooks Insert the following block in a notebook cell and execute as code (From Twitter). This will put the output of each cell on the side of the code.\n%%html \u0026lt;style\u0026gt; #notebook-container {width: 100%; background-color: #EEE} .code_cell {flex-direction: row !important;} .code_cell .output_wrapper {width: 50%;background-color: #FFF} .code_cell .input {width: 50%;background-color: #FFF} \u0026lt;/style\u0026gt; Convert the code cell to markdown to cancel.\nDataclasses Dataclass can be used to automatically generate special methods like __init__() and __repr__() for a python class.\nfrom dataclasses import dataclass @dataclass class InventoryItem: \u0026#34;\u0026#34;\u0026#34;Class for keeping track of an item in inventory.\u0026#34;\u0026#34;\u0026#34; name: str unit_price: float quantity_on_hand: int = 0 def total_cost(self) -\u0026gt; float: return self.unit_price * self.quantity_on_hand Pathlib Pathlib is an extremely useful library for manipulating paths. It is less cumbersome than using os.path.join() repeatedly.\nfrom pathlib import Path p = Path(\u0026#39;/\u0026#39;) print(\u0026#34;List subdir:\u0026#34;, [x for x in p.iterdir() if x.is_dir()]) q = p / \u0026#39;init.d\u0026#39; / \u0026#39;reboot\u0026#39; print(q) print(q.resolve()) print(q.exists()) print(q.is_dir()) with q.open() as f: f.readline() ","title":"Python","url":"https://hugocisneros.com/notes/python/"}
    
    , 
    
    {"body":"Self-organization is an emergent phenomenon\nOpen questions in self-organization From (Gershenson et al. 2020)\nHow can self-organization be programmed? This question is fundamental. It is one thing to have systems that exhibit beautiful and surprising self-organization, but its a different thing to be able to steer it in the right direction and use it.\nCan the macroscopic outcomes of self-organization be predicted? What is the role of self-organization in the open problems of ALife? What are the theoretical and practical limits of self-organization? How can understanding of self-organization in ALife benefit other disciplines? Bibliography Gershenson, Carlos, Vito Trianni, Justin Werfel, and Hiroki Sayama. September 2020. \"Self-Organization and Artificial Life\". Artificial Life 26 (3):391–408. DOI.","title":"Self-organization","url":"https://hugocisneros.com/notes/self_organization/"}
    
    , 
    
    {"body":" tags Applied maths resources Book by Daniel Liberzon  Optimal control problem An typical optimal control problem starts with a control system \\[ \\dot{x} = f(t, x, u), \\quad x(t_0) = x_0 \\] where \\(x\\) is the state of the system, \\(t\\) represents time and \\(u\\) is the control input.\nThe goal of an OC problem is to minimize a cost functional of the form \\[ J(u) := \\int_{t_0}^{t_f}L(t, x(t), u(t))dt + K(t_f, x_f). \\]\n","title":"Optimal control","url":"https://hugocisneros.com/notes/optimal_control/"}
    
    , 
    
    {"body":" tags Artificial life, Artificial Intelligence  ","title":"Robotics","url":"https://hugocisneros.com/notes/robotics/"}
    
    , 
    
    {"body":" tags Artificial Intelligence  The most famous example is the Turing test.\n","title":"Artificial intelligence test","url":"https://hugocisneros.com/notes/artificial_intelligence_test/"}
    
    , 
    
    {"body":" tags Artificial intelligence test  ","title":"Chinese room experiment","url":"https://hugocisneros.com/notes/chinese_room_experiment/"}
    
    , 
    
    {"body":" tags Applied maths, Algorithm  The fast marching method can be seen as a way to improve the metric issue with Dijkstra\u0026rsquo;s algorithm (which actually computes the \\(\\ell_1\\) distance on a grid). The graph update is replaced with the Eikonal equation resolution in the FM method. This reduces the bias of using a grid and converges towards the underlying geodesic distance when the grid step size tends towards 0.\nThe FM algorithm replaces the graph update (\\(D_j \\leftarrow \\min_{k \\sim j} D_k + W_j\\)) with a local resolution of the Eikonal equation\n","title":"Fast Marching method","url":"https://hugocisneros.com/notes/fast_marching_method/"}
    
    , 
    
    {"body":" tags Applied maths, Algorithm  ","title":"Dijkstra's algorithm","url":"https://hugocisneros.com/notes/dijkstra_s_algorithm/"}
    
    , 
    
    {"body":" tags Coding  Hilbert curves can be used for an interesting trick involving 2D arrays indexing. Because of the way the Hilbert curve traverses the 2D space, indexing a 2D array this way can be a more cache-friendly solution when frequently accessing neighbors of an array element.\n Hilbert curve with different number of iterations   C implementation from Wikipedia to convert (x,y) coordinates to linear ones and vice versa:\n//convert (x,y) to d int xy2d (int n, int x, int y) { int rx, ry, s, d=0; for (s=n/2; s\u0026gt;0; s/=2) { rx = (x \u0026amp; s) \u0026gt; 0; ry = (y \u0026amp; s) \u0026gt; 0; d += s * s * ((3 * rx) ^ ry); rot(n, \u0026amp;x, \u0026amp;y, rx, ry); } return d; } //convert d to (x,y) void d2xy(int n, int d, int *x, int *y) { int rx, ry, s, t=d; *x = *y = 0; for (s=1; s\u0026lt;n; s*=2) { rx = 1 \u0026amp; (t/2); ry = 1 \u0026amp; (t ^ rx); rot(s, x, y, rx, ry); *x += s * rx; *y += s * ry; t /= 4; } } //rotate/flip a quadrant appropriately void rot(int n, int *x, int *y, int rx, int ry) { if (ry == 0) { if (rx == 1) { *x = n-1 - *x; *y = n-1 - *y; } //Swap x and y  int t = *x; *x = *y; *y = t; } } ","title":"Hilbert curve indexing","url":"https://hugocisneros.com/notes/hilbert_curve_indexing/"}
    
    , 
    
    {"body":" authors Kenneth Stanley tags Artificial Intelligence, Open-ended Evolution source Link  ","title":"Article: Open-endedness: The last grand challenge you’ve never heard of","url":"https://hugocisneros.com/notes/open_endedness_the_last_grand_challenge_you_ve_never_heard_of/"}
    
    , 
    
    {"body":"Ken Stanley is a researcher at OpenAI.\n","title":"Kenneth Stanley","url":"https://hugocisneros.com/notes/kenneth_stanley/"}
    
    , 
    
    {"body":" authors Melanie Mitchell, Jessica Flack source Aeon tags Complex Systems  This article is about adopting a complex systems-based view of societal phenomena. All human societies are a collective of individuals with coupled behaviors.\nAs a result, large-scale society-wide information and local behaviors are coupled. This can be appealing, but also leads to surprising behavior. In complex systems, noise feeding back onto itself can lead to transitions to orderly states. In practice, this means individual slightly random positive decisions can results in a society-scale negative behavior.\nThere is another issue with complex dynamical systems: their possible states are distributed according to a heavy-tailed distribution.\n But in collective settings where contagion shapes behaviour – a run on the banks, a scramble to buy toilet paper – the probability distributions for possible events are often heavy-tailed.\n Events from the long tail can in turn lead to more very rare events.\n What’s more, once a rare but hugely significant ‘tail’ event takes place, this raises the probability of further tail events. We might call them second-order tail events; they include stock market gyrations after a big fall, and earthquake aftershocks. The initial probability of second-order tail events is so tiny it’s almost impossible to calculate – but once a first-order tail event occurs, the rules change, and the probability of a second-order tail event increases.\n This uncertainty makes predicting the results of one\u0026rsquo;s actions very hard. Many fiascoes happened when central entities made bottom-up decisions from crude data and making easy conclusions about cause and effects.\n There are better ways to make consequential, society-wide decisions. As the mathematician John Allen Paulos remarked about complex systems: ‘Uncertainty is the only certainty there is. And knowing how to live with insecurity is the only security.’ Instead of prioritising outcomes based on the last bad thing that happened – applying laser focus to terrorism or inequality, or putting vast resources into healthcare – we might take inspiration from complex systems in nature and design processes that foster adaptability and robustness for a range of scenarios that could come to pass.\n Nature has come up with solutions to this uncertainty by using two strategies:\n  Robustness mechanisms\n  Timescale separation:\n The timescales on which a system’s processes run have critical consequences for its ability to predict and adapt to the future. Prediction is easier when things change slowly – but if things change too slowly, it becomes hard to innovate and respond to change. To solve this paradox, nature builds systems that operate on multiple timescales.\n This separation needs to be just right (not too large, not too small) and adaptable.\n  We are just at the dawn of using complex system science to study societal and environmental phenomena, but this could lead to great innovations in policy-making.\n","title":"Article: Uncertain times","url":"https://hugocisneros.com/notes/article_uncertain_times/"}
    
    , 
    
    {"body":" resources Medium article tags Cellular automata  ","title":"Crosshatch automata","url":"https://hugocisneros.com/notes/crosshatch_automata/"}
    
    , 
    
    {"body":" tags Ising model, Complex Systems source Quanta magazine  The Ising model is an example of very simply defined model that makes complex behavior emerge.\nOriginally introduced by Wilhelm Lenz and his graduate student Ernst Ising, its purpose was to understand why magnets lose their attractive power when heated past a certain temperature. The model was first tried in 1D, where it fails to show that a magnet stays magnetized, and therefore abandoned.\nMore than 20 years later, Lars Onsager tried to solve it again for the 2D case. The solution was published in 1944 but still did not attract a lot of interest.\nIn the 50s, when experimental measurements showed that the Ising model accurately predicted “critical exponents” of various gases, physicists eventually got interested.\n At the critical temperature, islands of all sizes coexist, from dots to continents. Here, one arrow can flip another, distant arrow, despite their not being neighbors — an indication that the system’s macroscopic properties have detached from its microscopic details. This detachment is the magic of universality. All systems with the same number of dimensions and the same symmetries go through identical phase transitions, regardless of whether their microscopic parts are iron atoms, water molecules or little arrows.\n A striking property of the model is it describes something that looks like a deep universal property of complex systems (composed of many components interacting locally with each other). This has been applied to Physics, Biology, and other fields. It also seems to indicate that complex systems are a relevant framework to analyze natural phenomena and try and reproduce some of its emergent properties.\n","title":"Article: The Cartoon Picture of Magnets That Has Transformed Science","url":"https://hugocisneros.com/notes/the_cartoon_picture_of_magnets_that_has_transformed_science/"}
    
    , 
    
    {"body":" source https://www.quantamagazine.org/the-end-of-the-rna-world-is-near-biochemists-argue-20171219/ tags Biological life  This article is about alternatives to the dominant RNA-world theories.\nObjections to RNA:\n Crucial processes that we consider part of life could not have been carried out by a single polymer, and particularly not RNA. This is because these chemical reactions have rates ranging across 20 orders of magnitude. RNA cannot explain the emergence of genetic code. It would have been too long for RNA alone to find the mapping rules from 64 three nucleotide sequences to 20 amino acids.  Possible solution according to Peter Wills and Charles Carter: this process could have been carried out with a peptide-RNA complex. There is not just RNA but also 20 so-called \u0026ldquo;loading\u0026rdquo; molecules which allow RNA to bond with specific amino acids.\nInteresting parallel with Gödel\u0026rsquo;s theorem: This RNA-peptides world is thought to be a good candidate by the two scientists because it has a tight feedback loop between the two kinds of compounds that they compare with the \u0026ldquo;incompleteness\u0026rdquo; theorem: that in any logical system that represents itself statements will inevitably arise that cannot be shown to be true or false within the system. There would be this kind of \u0026ldquo;inevitability\u0026rdquo; of life in their system.\nConclusion: “We should put only a few of our eggs in the RNA world basket”, Jannie Hofmeyr.\n","title":"Article: The End of the RNA World Is Near, Biochemists Argue","url":"https://hugocisneros.com/notes/the_end_of_the_rna_world_is_near_biochemists_argue/"}
    
    , 
    
    {"body":" tags Life resources (Krakauer et al. 2020) source Quanta Magazine   “In a way, [biology] is a science of individuality,” said Melanie Mitchell, a computer scientist at the Santa Fe Institute.\nAnd yet, the notion of what it means to be an individual often gets glossed over. “So far we have a concept of ‘individual’ that’s very much like the concept of ‘pile,’” said Maxwell Ramstead, a postdoctoral researcher at McGill University. “If there’s a pile of sand, you intuitively know this is a pile of sand. But a pile is not a precisely defined thing. It’s not like after 13 grains, it moves from a collection to a pile.”\n We tend to see individuals as entities separated from an environment. However, this is far from the only possible definition.\n “I always say, if Darwin was a microbiologist, we’d have a very different theory of evolution,” said David Krakauer, an evolutionary theorist and president of the Santa Fe Institute. “You wouldn’t have started with the survival of the fittest organism. It would have been a very different premise.”\n A scientist from the Santa Fe Institute name Jessica Flack has been working on another definition, based on temporal aspects of individuality instead of spatial aspects. In this definition, organisms aren\u0026rsquo;t fixed objects but processes or information flows.\n Krakauer and Flack, in collaboration with colleagues such as Nihat Ay of the Max Planck Institute for Mathematics in the Sciences, realized that they’d need to turn to information theory to formalize their principle of the individual “as kind of a verb.” To them, an individual was an aggregate that “preserved a measure of temporal integrity,” propagating a close-to-maximal amount of information forward in time.\n   Their formalism, [\u0026hellip;] is based on three axioms. One is that individuality can exist at any level of biological organization, from the subcellular to the social. A second is that individuality can be nested — one individual can exist inside another. The most novel (and perhaps most counterintuitive) axiom, though, is that individuality exists on a continuum, and entities can have quantifiable degrees of it.\n According to this new definition, there are three distinct types of individuality. The first one is\n Organismal individual, an entity that is shaped by environmental factors but is strongly self-organizing. Nearly all of the information that defines such an individual is internal and based on its own prior states. “This is a lens that, if you wore it, would allow you to see humans and mammals and birds,” Krakauer said.\n The second\n Colonial form, which involves a more complicated relationship between internal and external factors. Individuals in this category might include an ant colony or a spiderweb — distributed systems that are “partially scaffolded” by their environment but still maintain some structure on their own.\n The third\n Driven almost entirely by the environment. “If you remove the scaffolding, the [entity] would fall apart,” Krakauer said. It’s like a tornado, which dissipates under the wrong temperature and moisture conditions. The very first life to arise on Earth was probably like this, Krakauer added.\n This view of life, the authors argue, could reconcile the complex systems view of many systems (cities, networks, companies, colonies) and a non biological life interpretation.\nThese concepts of individuality can be very useful, to interpret individuality of molecules in a cell, of ecosystems, of our planet in the Solar system.\nBibliography Krakauer, David, Nils Bertschinger, Eckehard Olbrich, Jessica C. Flack, and Nihat Ay. June 1, 2020. \"The Information Theory of Individuality\". Theory in Biosciences 139 (2):209–23. DOI.","title":"Article: What Is an Individual? Biology Seeks Clues in Information Theory.","url":"https://hugocisneros.com/notes/what_is_an_individual_biology_seeks_clues_in_information_theory/"}
    
    , 
    
    {"body":" resources Website  She has worked at the Santa Fe Institute and studies Complex Systems, Artificial Intelligence.\n","title":"Melanie Mitchell","url":"https://hugocisneros.com/notes/melanie_mitchell/"}
    
    , 
    
    {"body":" tags Complexity metrics papers (Crutchfield and Young 1989)  One interpretation of the statistical complexity is that it is the minimum amount of historical information required to make optimal forecasts of bits in \\(x\\) at the error rate \\(h_\\mu\\).\nFor periodic sequences, \\(C_\\mu(x) = 0\\) and for ideal random sequences \\(C_\\mu(x) = 0\\) too.\nSeveral researchers have tried to capture the properties of statistical complexity with practical alternatives. The resulting complexity metrics include:\n Logical depth Effective measure complexity Pathway assembly  Bibliography Crutchfield, James P., and Karl Young. July 10, 1989. \"Inferring Statistical Complexity\". Physical Review Letters 63 (2):105–8. DOI.","title":"Statistical complexity","url":"https://hugocisneros.com/notes/statistical_complexity/"}
    
    , 
    
    {"body":" tags Life, ALife 2020  Complex molecules are bio-signatures, they are the sign of complex (evolutionary?) processes that have been going on.\nAssembly theory Exploring complexity: Lee is showing some theoretical idea about a complexity metric. Like many other metrics, he starts from the observation that neither entropy nor Kolmogorov complexity are suitable for considering the history of an object.\nInstead of thinking in terms of disorder or complexity, why not ask simply about \u0026ldquo;how has this object been assembled?\u0026rdquo;. This leads to some other question \u0026ldquo;How likely is it that the object formed by chance?\u0026rdquo;\nThis is what he calls Object assembly, or assembly theory. The principle is not detailed in the talk but is based on identifying building blocks of an object and quantifying the number of move in the \u0026ldquo;object\u0026rdquo; space.\nThis is not detailed more in the talk but I feel would need more explanation. It seems this metric depends a lot on the space you choose for the \u0026ldquo;building blocks\u0026rdquo; of the object. It seems from the talk that chemistry is especially suited as a subject for this complexity metric, because the object space emerges naturally from experimental mass spectrography results.\nBottom-up ALife Cronin\u0026rsquo;s team started working on chemical droplet systems with the possibility to vary many parameters and studied how this could lead to some form of evolution.\nThe first step is the cell. Probably chemistry is relatively dumb until it can create pockets that are separated from the rest.\nTop-down Alife in chemistry Recent work on open-endedness in CAs prompted Cronin to try and create such a thing in chemistry, by building a chemical computer that works like a CA. (Adams et al. 2017).\nBibliography Adams, Alyssa, Hector Zenil, Paul C. W. Davies, and Sara Imari Walker. April 20, 2017. \"Formal Definitions of Unbounded Evolution and Innovation Reveal Universal Mechanisms for Open-Ended Evolution in Dynamical Systems\". Scientific Reports 7 (1):997. DOI.","title":"Talk: Alife 2020 keynote Lee Cronin - A Top Down Chemically Embodied Artificial Life...","url":"https://hugocisneros.com/notes/talk_alife_2020_keynote_lee_cronin_a_top_down_chemically_embodied_artificial_life_computation/"}
    
    , 
    
    {"body":"","title":"Urban science","url":"https://hugocisneros.com/notes/urban_science/"}
    
    , 
    
    {"body":" tags Mathematics resources Wikipedia  ","title":"Fractional calculus","url":"https://hugocisneros.com/notes/fractional_calculus/"}
    
    , 
    
    {"body":" tags Life  The problem of defining life Definitions of life have always been elusive.\n Life does not exist.\n \u0026mdash; Andrew Ellington (American Chemical Society 2012).\n as one focuses experimentally on any of the \u0026lsquo;defining\u0026rsquo; properties of \u0026lsquo;life\u0026rsquo;, the sharp boundary seems to blur, splitting into finer and finer sub-divisions\n \u0026mdash; Jack Szostak (J. Biomolecular Struc. Dyn. 29.4 (2012) : 599-600.)\nWhen looking at matter down to the chemical level, it\u0026rsquo;s hard to tell what is fundamentally different between living and non-living matter. Reductionist approaches to understanding life don\u0026rsquo;t work.\nLife might actually not exist physically, meaning it has nothing to do with measurable properties of matter, but rather:\n \u0026ldquo;Life\u0026rdquo; is the software of reality.\n What is life?  how can the events in space and time which take place *within the spatial boundary of a living organism be accounted for by Physics and Chemistry?\n   \u0026hellip; living matter, while not eluding the \u0026ldquo;laws of physics\u0026rdquo; as established up to date, is likely to involve \u0026ldquo;other laws of physics\u0026rdquo; hitherto unknown\n \u0026mdash; E. Schrödinger. What is life? Cambridge University Press, 1944.\nIn many simulations of life, and in biology, we always think of life as structures, emergent patterns. It might be we are unable to discover life because we look for things like cellular structures and patterns. But we are not really understanding how living systems are processing information around them and involved in constructing those patterns.\nExample emergent processes Walker takes the example of satellites launched in space and the conditions of our Universe for these things to happen. We can list several:\n We need a technological (or intelligent?) civilization It has to understand the laws of Physics Etc.  Such a civilization can launch satellites because the information exists in the physical space.\nAnother example is the complex heavy elements that we only know about because of technology.\nLife is what? Life ≠ alive This is what Walker thinks life is about: A process with the ability to do things with the Universe. Therefore, this notion is different from being \u0026ldquo;alive\u0026rdquo; in the traditional sense.\nA bottle or a computer are certainly examples of life. They depend on an evolutionary process which has led us here and enabled us to construct such objects. Alive things are actively involved in information processing and constructing the reality around them.\nA transition between non-living and living physics There is a threshold in the kind of objects one can obtain. In chemical space, this corresponds to the boundary between object spontaneous appearing and object that needed active processing by an \u0026ldquo;alive\u0026rdquo; being to exist since they couldn\u0026rsquo;t have been created through random search or random assembly of modules.\nWith this new approach, the quote saying that life is the software of reality becomes slightly clearer: it is the software that runs on top of reality and actively modifies it in the process, creating what we observe as \u0026ldquo;living\u0026rdquo; systems.\nTowards quantifying life - Abstracting universal biochemistry  Life is a process where information structures matter across space and time.\n So far, people have been mostly focusing on the \u0026ldquo;building blocks\u0026rdquo; of life. With life on earth, everything shares a common basic biochemistry. General building blocks of life are understood with this sample 1 bias of earth\u0026rsquo;s biochemistry. Life emerging from ALife systems might work very differently.\nUniversality:\n In biochemistry this means that all life on earth shares a sort of common basic details In physics it is more about some macroscopic properties of a system. If very different systems share a common macro-property, the property is considered universal.  Can we find a universality class for life? We can think of information processing as a general property we can study. Walker focuses on the restricted problem of finding a universality class in patterns that emerge from biochemistry alone.\nLife in the chemical space The chemical space is extremely large (possible combinations of molecules). But because it is so large, there are a lot of chemical elements that require information about how to make them for them to have appeared in the first place and for the Universe to produce them in any abundance. For example, large proteins couldn\u0026rsquo;t have emerged through random processes.\nEarth as a large ensemble of biochemical networks When looking at Earth, organisms can be seen as partitions of the global biochemistry. The cell is probably not the right boundary to be looking at because cells are interacting through chemical reactions with an environment and modifying it, thereby defining a larger \u0026ldquo;network\u0026rdquo; that can be defined as living.\nMeasuring scaling behavior Walker\u0026rsquo;s group sampled ensembles of biochemical networks that exist across different scales of the biosphere(species, ecosystems, biosphere) and tried to look for global patterns and universality classes.\nThe experiments were based on comparing properties of these networks and scaling properties against random chemistry examples.\nIt seems from these experiments that there are well behaved scaling laws that work across individuals, ecosystems and the biosphere. It also seems that they are significantly different from randomly sampled, similarly sized chemical networks. However, the behavior was reproduced with frequency based sampling.\nThere is a large fraction of reactions and compounds that is shared across all domains of life on earth.\nCoarse-graining to find universal properties of chemical reactions The idea here is that although all living things might not share the same chemistry as Earth\u0026rsquo;s, there might be patterns and regularities that are common at higher coarse-grained scales.\nEnzyme commission numbers is a readily available classification of chemical reactions that is hierarchical.\n Slide from Sara Walker\u0026#39;s talk   At the coarsest level (EC1, EC2, etc.), more or less regular scaling behavior is observed for each of them across multiple life scales.\nEC1 has very consistent super-linear scaling laws that can be fitted to it and EC6 has sub-linear scaling.\nUniversality classes (scaling behavior) observed are not explained by the presence of these enzymes in all biochemical reactions.\nIt is likely that these neat scaling behaviors cannot exist at the smallest level of EC. What scale does universality appear at and what does this mean for life and emergence?\nAt the second level (ECx.x), the scaling behavior is still very much present.\nScaling behavior has also been observed in % of chiral molecules within networks.\nModels of LUCA also fit the scaling behavior previously mentioned.\n","title":"Talk: Alife 2020 keynote Sara Walker - The Natural History of Information","url":"https://hugocisneros.com/notes/talk_alife_2020_keynote_sara_walker_the_natural_history_of_information/"}
    
    , 
    
    {"body":" tags Algorithm  Graham scan is an algorithm to find the convex hull of a set of points in 2D. It runs with a time complexity of \\(\\mathcal{O}(n\\log n)\\).\nThe algorithm is relatively simple. It starts by selecting the point with lowest $y$-coordinate. At each step of the algorithm, remaining points are sorted by increasing order of the angle they and the last added point make. Then, if this new point is\n Graham scan algorithm demo   ","title":"Graham scan","url":"https://hugocisneros.com/notes/graham_scan/"}
    
    , 
    
    {"body":" tags Computer science, Coding  Program synthesis is the task of writing programs automatically for a given tasks. This is widely considered a very hard problem in the general case, as the computational languages we manipulate as human are hard to manipulate \u0026ldquo;smoothly\u0026rdquo;.\nCompilation is a type of program synthesis where both the source language and the target language are well defined. A compiler is written for a given source language/target language pair and is therefore doing well specified program synthesis. This allows doing complex operations such as code optimization.\nGeneral purpose program synthesis would start from a higher level language, more like natural language.\n","title":"Program synthesis","url":"https://hugocisneros.com/notes/program_synthesis/"}
    
    , 
    
    {"body":"Epistasis is about interactions between mutations in an evolving systems.\n No epistasis corresponds to mutation effects \u0026ldquo;stacking\u0026rdquo; without any particular kind of interaction. Positive epistasis happens when the combined effect of the two mutations is more positive than the sum of their contributions. Negative epistasis is the same principle with negative effects.   Cancer is an example negative epistasis where the addition of a lot of mutations is needed to obtain a cancerous cell.\nThese interactions make the biological systems so complicated to study and understand.\n","title":"Epistasis","url":"https://hugocisneros.com/notes/epistasis/"}
    
    , 
    
    {"body":" tags Statistics, Applied maths  ","title":"Noise","url":"https://hugocisneros.com/notes/noise/"}
    
    , 
    
    {"body":" tags Quality diversity, Reinforcement learning papers (Mouret and Clune 2015; Cully et al. 2015)  MAP-Elites are an example of QD algorithm. The behavior space is discretized in cells and during exploration, only the best \u0026ldquo;elite\u0026rdquo; for each cell is kept.\nIndividuals are added to the grid if they:\n fill an empty space are better than an existing elite  Bibliography Cully, Antoine, Jeff Clune, Danesh Tarapore, and Jean-Baptiste Mouret. May 2015. \"Robots That Can Adapt like Animals\". Nature 521 (7553). Nature Publishing Group:503–7. DOI. Mouret, Jean-Baptiste, and Jeff Clune. April 19, 2015. \u0026ldquo;Illuminating Search Spaces by Mapping Elites\u0026rdquo;. arXiv:1504.04909 [Cs, Q-Bio]. http://arxiv.org/abs/1504.04909.\n","title":"MAP-Elites","url":"https://hugocisneros.com/notes/map_elites/"}
    
    , 
    
    {"body":" tags Complex Systems  ","title":"NK model","url":"https://hugocisneros.com/notes/nk_model/"}
    
    , 
    
    {"body":" tags Evolution  ","title":"Co-evolution","url":"https://hugocisneros.com/notes/co_evolution/"}
    
    , 
    
    {"body":" tags Programming languages  ","title":"Assembly language","url":"https://hugocisneros.com/notes/assembly_language/"}
    
    , 
    
    {"body":" tags Emergence, Biological life, ALife 2020  How do organisms store information and are able to pass it down through very profound structural changes (from a caterpillar to a butterfly, when cutting a flatworm in multiple pieces, etc.)?\nEmbryogenesis is a reliable self-assembly. It relies on stem cell differentiation but that\u0026rsquo;s not enough: some tumor (Teratoma) are differentiated but don\u0026rsquo;t have the right 3D spatial organisation.\nWhere is the large-scale pattern specified? Everything has to be in the right shape with the right organization. The typical answer is DNA. However DNA is really just protein structure specification and not a blueprint for anatomy.\nHow do cell groups know what to make and where to stop?\nCan we control the process to repair and edit, and can we build arbitrary things with that process?\nCurrent anatomy paradigm Gene regulatory networks (turn genes on and off). Some genes become effector proteins that interact via physics and all of this happens in parallel and an organism emerges.\nHowever it is very difficult to figure out the inverse transformation: figure out the molecules to tweak to get a particular organism.\nThe process is reliable but very adaptive (not hardwired). It can regulate itself after drastic perturbation such as splitting an embryo in two gives twins. We can also aggregate embryo into a single organism.\nMany organisms can also do that at the adult stage (e.g. axolotl regenerate limbs, eyes, jaws, etc.).\nOne can graft a tail to the leg of a salamander and it can remodel itself into an arm.\nPlanarians are really great at that. When cutting in the middle, cells from that middle position will make very different choices and regrow the right part. These organisms are immortal.\nRegeneration is not just for these organisms: human liver, deer regenerate bones and skin every year, human children can regenerate fingertips.\nThe body is very plastic, it can go towards specific anatomical states through self-assembly. It is not a local behavior, there is a collective decision in cell swarms.\nIndividual cells can be very competent, and with cooperation they became even more competent.\nTadpoles transform into correct frogs even when all the organs are misplaced. The anatomy program is very robust and able to react to unexpected situations and correct errors.\nIt is possible there might be a homeostatic set-point (or pattern memory). Then if we understand it we might be able to edit it and control the blueprint without touching the cells themselves. The endgame would be an anatomical compiler, in which we could design the overall layout of the target organism and let it develop according to the blueprint.\nFor now we are good at understanding gene regulatory networks, but ultimately we would wand to understand how this can get us to organs.\nInteresting parallel with the computer science revolution, we historically focused on hardware but later turned to the actual algorithms and software going higher and higher up in the abstractions. If biology is a programmable hardware, we should be able to program it.\nNon-neural bio-electricity In the brain, genes specify electrical circuits, ion channels and synapses (this is the hardware). The software is all the activations within these neurons which lead to pattern recognition, memory, etc.\nBut actually, all cells have ion channels and a form and electrical synapses therefore there is a developmental \u0026ldquo;software\u0026rdquo; to be discovered too.\nThe speaker\u0026rsquo;s group have developed tools to control the bio-electric network in vivo by using molecular actions on the synapses and ion channels. This enables coherent large-scale changes to the anatomy. The authors can build an eye anywhere in an organism. . Different developmental states in flat worms correspond to different attractor state of the electrical circuits which can be controlled without touching the genome. Because of these different attractors, one can direct development into an attractor evolution doesn\u0026rsquo;t use.\nThis can be used for reconstruction. Example of tadpoles with mutated gene which prevent the from growing a brain. By controlling bioelectric signals one can regrow the brain despite the mutation.\nPattern memory By editing the bioelectric patterns one can make a planarian grow as two-headed. Therefore, the bioelectric pattern isn\u0026rsquo;t an indicator of what\u0026rsquo;s happening now in the anatomy, it encodes the pattern that will guide anatomy if it is cut.\nWhat about when we don\u0026rsquo;t actively perturb the bioelectric pattern? Shouldn\u0026rsquo;t the two-headed worm go back to normal if cut again? Actually, because the other attractor exists in the electric network, the work can keep regrowing two heads in perpetuity, or steered back to its normal form. This has all the properties of memory.\nIn this space of networks, one can see the memory of particular anatomical state as attractors, or basins of attractions of the neural net dynamics.\n Slide from Michael Levin\u0026#39;s talk   DNA encodes an excitable medium with symmetry-breaking dynamics (the system does something if nobody disturbs it) which is re-writable because software is modular and controls anatomy.\nMulti-scale organization and ALife Cognitive agents are made of parts. Bodies are swarms of cells, and morphogenesis is a great framework for studying it.\nMolecular networks give cells which give organs which give organisms and finally societies. Autonomy happens at those multiple scales. And because of this organisms are evolvable.\n","title":"Talk: Alife 2020 keynote Michael Levin - Robot Cancer","url":"https://hugocisneros.com/notes/talk_alife_2020_keynote_michael_levin_robot_cancer/"}
    
    , 
    
    {"body":" tags Machine learning  ","title":"Federated learning","url":"https://hugocisneros.com/notes/federated_learning/"}
    
    , 
    
    {"body":" tags Christopher Langton, Cellular automata  ","title":"Langton's loop","url":"https://hugocisneros.com/notes/langton_s_loop/"}
    
    , 
    
    {"body":" tags Computer science  PL I use or have used:\n Python C Programming language C++ Javascript Rust Scala Java Ruby ELisp Haskell  ","title":"Programming languages","url":"https://hugocisneros.com/notes/programming_languages/"}
    
    , 
    
    {"body":" tags Computer science, Coding  Example of functional programming languages  Lisp Haskell  ","title":"Functional programming","url":"https://hugocisneros.com/notes/functional_programming/"}
    
    , 
    
    {"body":" tags Programming languages, Coding  ","title":"Haskell","url":"https://hugocisneros.com/notes/haskell/"}
    
    , 
    
    {"body":" tags Neural networks, Algorithm  Adaptive computation time (ACT) was introduced in (Graves 2017) as a way to make computations in RNN adaptive. The network learns how many computational steps to use before emitting an output.\nThis is done by outputting an extra halting probability at each update step, and considering two timelines:\n the input timeline which plays the role of an outer loop, at each of those step, a new input symbol is fed to the RNN. This step outputs a single output vector. the internal processing timeline, this is the inner loop being run at each of the input steps. This runs until the cumulative halting probability is above a threshold and emits as many output values as steps..  Bibliography Graves, Alex. February 21, 2017. \"Adaptive Computation Time for Recurrent Neural Networks\". arXiv:1603.08983 [Cs]. http://arxiv.org/abs/1603.08983.","title":"Adaptive Computation Time","url":"https://hugocisneros.com/notes/adaptive_computation_time/"}
    
    , 
    
    {"body":" tags Life  ","title":"Autopoiesis","url":"https://hugocisneros.com/notes/autopoiesis/"}
    
    , 
    
    {"body":" tags Artificial life, Evolution  ","title":"Tierra","url":"https://hugocisneros.com/notes/tierra/"}
    
    , 
    
    {"body":" tags Complex Systems, Physics  ","title":"Santa Fe Institute","url":"https://hugocisneros.com/notes/santa_fe_institute/"}
    
    , 
    
    {"body":" tags Statistics  ","title":"Simpson's paradox","url":"https://hugocisneros.com/notes/simpson_s_paradox/"}
    
    , 
    
    {"body":" tags Philosophy  The simulation argument Nick Bostrom proposed a trilemma in 2003:\n  \u0026ldquo;The fraction of human-level civilizations that reach a posthuman stage (that is, one capable of running high-fidelity ancestor simulations) is very close to zero\u0026rdquo;, or \u0026ldquo;The fraction of posthuman civilizations that are interested in running simulations of their evolutionary history, or variations thereof, is very close to zero\u0026rdquo;, or \u0026ldquo;The fraction of all people with our kind of experiences that are living in a simulation is very close to one.\u0026rdquo;   The simulation hypothesis is very similar to Zuse\u0026rsquo;s thesis, with the addition of a form of anthropic reasoning to argue that it has to be one of the three solutions above.\nA corollary of this hypothesis is that AI is an achievable goal, because we have been created. Therefore it would be possible to think we could create one.\n","title":"The Simulated reality hypothesis","url":"https://hugocisneros.com/notes/the_simulated_reality_hypothesis/"}
    
    , 
    
    {"body":" tags Philosophy  ","title":"Nick Bostrom","url":"https://hugocisneros.com/notes/nick_bostrom/"}
    
    , 
    
    {"body":" tags Artificial intelligence test  ","title":"Bongard problems","url":"https://hugocisneros.com/notes/bongard_problems/"}
    
    , 
    
    {"body":" tags Natural language processing  Language model evaluation Perplexity For a given word sequence \\(\\mathbf{w} = (w_1, \u0026hellip;, w_n)\\), perplexity (PPL) is defined \\[ PPL = 2^{-\\frac{1}{n} \\sum_{i=1}^n \\log_2 P(w_i | w_{i-1} \u0026hellip; w_1 )} \\] It can be seen as the cross-entropy between an empirical distribution of test words and the predicted conditional word distribution. A language model that would encode each word with an average 8 bits has a perplexity of 256 (\\(2^8\\)).\nIt is often used as an evaluation of language models, probably for two main reasons:\n Because it yields an easier to remember and reason about number than the average bits per word value (easier to compare 155 and 128 than 7.27 bits and 7 bits). Because a language model with the lowest possible perplexity would be the closest to the \u0026ldquo;true\u0026rdquo; model that generated the data.  Because of its connection with entropy, there is also a clear connection between perplexity and Compression, and finding the best language model for a given task is equivalent to finding the best compressor for the data (Mahoney 1999).\nPerplexity is the dominant metric for Language model evaluation. However, it has a few drawbacks:\n Perplexity is computed assuming perfect history, which might not always be the case when using previously generated data to generate a new word. Perplexity improvements can be misleading, since a fixed perplexity improvement is exponentially harder the closest it is to zero. Therefore, it is advantageous to report a sub-optimal baseline to maximize the value of perplexity improvement, while the actual entropy improvement might be small.  Winograd Schema Challenge This challenge (Levesque, Davis, and Morgenstern, n.d.), part of the GLUE benchmark is specifically about sentences that are hard to deal with for computers: there are implicit and ambiguous references within the sentence that can only be solved with contextual knowledge of the things being talked about. To me this is a very hard challenge that we are nowhere near solving. GPT-2\u0026rsquo;s 70% accuracy on this task is impressive but still doesn\u0026rsquo;t convince me we are on the right track of solving it.\nThis seems like a good way of testing a artificially intelligent system.\nExample:\nI poured water from the bottle into the cup until it was full. It is not sufficient to learn this sentence structure because when we change only a word the meaning changes significantly.\nI poured water from the bottle into the cup until it was empty. If a machine solves this ambiguous reference, can we say that it has learned some meaningful concept about a bottle or a cup?\n When AI can\u0026rsquo;t determine what \u0026lsquo;it\u0026rsquo; refers to in a sentence, it\u0026rsquo;s hard to believe that it will take over the world.\nOren Etzioni, Allen Institute for AI\n Bibliography Levesque, Hector, Ernest Davis, and Leora Morgenstern. n.d. \"The Winograd Schema Challenge\", 10. Mahoney, Matthew V. 1999. \u0026ldquo;Text Compression as a Test for Artificial Intelligence\u0026rdquo;. In Proceedings of AAAI-1999, 3.\n","title":"Evaluating NLP","url":"https://hugocisneros.com/notes/evaluating_nlp/"}
    
    , 
    
    {"body":" tags Artificial intelligence test  ","title":"Abstraction and Reasoning Corpus","url":"https://hugocisneros.com/notes/abstraction_and_reasoning_corpus/"}
    
    , 
    
    {"body":" tags Artificial life  ALife 2020 ","title":"ALife Conference","url":"https://hugocisneros.com/notes/alife_conference/"}
    
    , 
    
    {"body":" tags Complexity, Algorithmic Information theory  ","title":"Algorithmic probability","url":"https://hugocisneros.com/notes/algorithmic_probability/"}
    
    , 
    
    {"body":" tags Mathematics  ","title":"Applied maths","url":"https://hugocisneros.com/notes/applied_maths/"}
    
    , 
    
    {"body":" tags Complex Systems  Evolutionary algorithms and CAs Evolutionary algorithms have been used to find Cellular automata rules with specific behavior (Mitchell et al. 1996; Sapin, Bailleux, and Jean-Jacques 2003) . The objective is to optimize a fitness function (majority of cells, presence of gliders and periodic patterns, etc.).\nBibliography Mitchell, Melanie, Hyde Park Road, Rajarshi Das, and P O Box. 1996. \"Evolving Cellular Automata with Genetic Algorithms: A Review of Recent Work\". In Proceedings of the First International Conference on Evolutionary Computation and Its Applications, 14. Sapin, Emmanuel, Olivier Bailleux, and Chabrier Jean-Jacques. 2003. \u0026ldquo;Research of a Cellular Automaton Simulating Logic Gates by Evolutionary Algorithms\u0026rdquo;. In Genetic Programming, edited by Conor Ryan, Terence Soule, Maarten Keijzer, Edward Tsang, Riccardo Poli, and Ernesto Costa, 2610:414–23. Berlin, Heidelberg: Springer Berlin Heidelberg. DOI.\n","title":"Automated discovery in complex systems","url":"https://hugocisneros.com/notes/automated_discovery_in_complex_systems/"}
    
    , 
    
    {"body":" tags Recurrent neural networks  Regular RNNs process input in sequence. When applied to a language modeling task, one tries to predict a word given the previous ones. For example, with the sentence The quick brown fox jumps over the lazy, a classical RNN will initialize and internal state \\(s_0\\) and process each word in sequence, starting from The and updating its internal state with each new word in order to make a final prediction.\nA backward RNN reverses this idea, building it internal state starting from the last word lazy (the one we can expect to have the most information for prediction) and process the sentence backward. It should be simpler for such network to learn to properly select meaningful information rather than starting from the first word which might not be useful at all.\nA variant of this idea, would be to use the same principle and apply it forward in a transformer-like language model training situation. To predict fox in The quick brown \u0026lt;?\u0026gt; jumps over the lazy dog, the network would start by looking at brown and jumps, and then quick and over, etc.\n","title":"Backward RNN","url":"https://hugocisneros.com/notes/backward_rnn/"}
    
    , 
    
    {"body":"Berry\u0026rsquo;s paradox is a sentence of the form \u0026ldquo;The smallest positive integer not definable in under sixty letters\u0026rdquo; (a phrase with fifty-seven letters).\nAn argument very similar to Berry\u0026rsquo;s paradox is used in the proof of uncomputability of Kolmogorov complexity.\nResolution An interesting study and resolution of Berry\u0026rsquo;s paradox\n","title":"Berry's paradox","url":"https://hugocisneros.com/notes/berry_s_paradox/"}
    
    , 
    
    {"body":" tags Statistics  ","title":"Causal inference","url":"https://hugocisneros.com/notes/causal_inference/"}
    
    , 
    
    {"body":" tags Logic papers (Cardone and Hindley, n.d.)  It was independently invented by Moses Schönfinkel, John Von Neumann and Haskell Curry.\nA Turing-complete basis of operators is:\n \\(If\\quad\\triangleright\\quad f\\) \\(Kfg \\quad\\triangleright\\quad f\\) \\(Sfgx \\quad\\triangleright\\quad fx(gx)\\)  Bibliography Cardone, Felice, and J Roger Hindley. n.d. \"History of Lambda-Calculus and Combinatory Logic\", 95.","title":"Combinatory logic","url":"https://hugocisneros.com/notes/combinatory_logic/"}
    
    , 
    
    {"body":"","title":"Computability theory","url":"https://hugocisneros.com/notes/computability_theory/"}
    
    , 
    
    {"body":" tags Applied maths  ","title":"Cryptography","url":"https://hugocisneros.com/notes/cryptography/"}
    
    , 
    
    {"body":"","title":"Economics","url":"https://hugocisneros.com/notes/economics/"}
    
    , 
    
    {"body":" tags Image processing  Canny edge detection Canny edge detection in the most famous edge detection algorithm, originally developed by John Canny in 1986.\nThe algorithm has 5 steps:\n Smooth the image with Gaussian filtering. Intensity gradients. First derivative in the horizontal (\\(\\mathbf{G}_x\\)) and vertical (\\(\\mathbf{G}_y\\)) directions are computed. Gradient intensity \\(\\mathbf{G} = \\sqrt{\\mathbf{G}_x^2 + \\mathbf{G}_y^2}\\) and direction \\(\\mathbf{\\Theta} = \\text{atan2}(\\mathbf{G}_y, \\mathbf{G}_x)\\) are then computed. Edge thinning to reduce blurring from the first two steps. Only largest edge intensity with respect to negative and positive gradient directions are preserved. Double threshold to remove remaining edges caused by noise or color variation. Edge pixels are marked either as strong edge, weak edge or removed with two thresholds. Only weak edge pixels connected to strong edge pixels are kept.  ","title":"Edge detection","url":"https://hugocisneros.com/notes/edge_detection/"}
    
    , 
    
    {"body":" tags Complexity metrics  ","title":"Effective measure complexity","url":"https://hugocisneros.com/notes/effective_measure_complexity/"}
    
    , 
    
    {"body":"ELisp is a dialect of the Lisp programming language.\n","title":"ELisp","url":"https://hugocisneros.com/notes/elisp/"}
    
    , 
    
    {"body":" tags Coding  Emacs uses ELisp to write configuration code and for scripting.\nTips Delete buffers in helm view In helm buffer list view, individual buffers can be selected with C-Space. Once the buffers you want to delete are selected, M-D will delete them and close helm.\n","title":"Emacs","url":"https://hugocisneros.com/notes/emacs/"}
    
    , 
    
    {"body":" tags Machine learning resources K. Bailey\u0026rsquo;s blog post  ","title":"Gaussian Processes","url":"https://hugocisneros.com/notes/gaussian_processes/"}
    
    , 
    
    {"body":" tags Computability theory  ","title":"Halting problem","url":"https://hugocisneros.com/notes/halting_problem/"}
    
    , 
    
    {"body":"","title":"Haskell Curry","url":"https://hugocisneros.com/notes/haskell_curry/"}
    
    , 
    
    {"body":"","title":"Information theory","url":"https://hugocisneros.com/notes/information_theory/"}
    
    , 
    
    {"body":" tags Programming languages, Coding  ","title":"Java","url":"https://hugocisneros.com/notes/java/"}
    
    , 
    
    {"body":" tags Programming languages, Coding  ","title":"Javascript","url":"https://hugocisneros.com/notes/javascript/"}
    
    , 
    
    {"body":" tags Economics, Climate resources (York and McGee 2016; Polimeni et al. 2015), Wikipedia, Real climate economics blog posts (Jim Barrett)  Definition Jevons Paradox is used to describe the situation where an increase in resource efficiency triggered by technological innovation has the counter-intuitive effect of raising the demand and increasing the overall consumption.\nIt was first described in W. S. Jenvons' book The Coal question in 1865.\nIt is closely to another paradox well known in road planning (Downs–Thomson paradox) and Wirth\u0026rsquo;s law in software engineering.\nBibliography Polimeni, John M, Kozo Mayumi, M Giampietro, and Blake Alcott. 2015. _The Jevons’ Paradox and the Myth of Resource Efficiency Improvements_. York, Richard, and Julius Alexander McGee. January 2, 2016. \u0026ldquo;Understanding the Jevons Paradox\u0026rdquo;. Environmental Sociology 2 (1):77–87. DOI.\n","title":"Jevons paradox","url":"https://hugocisneros.com/notes/jevons_paradox/"}
    
    , 
    
    {"body":"","title":"John Von Neumann","url":"https://hugocisneros.com/notes/john_von_neumann/"}
    
    , 
    
    {"body":" tags Climate  Definition It was developed by Japanese economist Yoichi Kaya.\n\\(F\\) is global CO2 emissions from human sources, \\(P\\) is global population, \\(G\\) is GPD, \\(E\\) is global energy consumption. \\[ F = P \\times \\frac{G}{P} \\times \\frac{E}{G} \\times \\frac{F}{E} \\]\nThe fractional terms correspond to well studied quantities:\n \\(G/P\\) is the GDP per capita \\(E/G\\) is the energy intensity of the GDP \\(F/E\\) is the carbon footprint of energy  Interpretation This identity is simply a rewrite of \\(F=F\\) in terms of commonly used quantities to highlight several levers one could act on to reduce CO2 emissions. According to this identity, to reduce CO2 emissions one could either:\n Reduce the population (e.g. through family planning, or birth planning programs like China\u0026rsquo;s one-child policy). Policies directly acting on demographics are often regarded as invasive and too restrictive, particularly in liberal democracies. Reduce GDP per capita. This corresponds to a recession, and probably impoverishment of parts of population. Western democracies are also generally against the idea of limited or negative growth. Energy intensity of GDP is a tricky quantity, influenced by many factors. These factors range from general standards of living and weather to technological advancement, energy mix and economic specificity of a country. It is probably where politician can act the most, but also where it is the hardest to predict the result of any given policy. Carbon footprint of energy corresponds to the amount of CO2 emitted to produce energy. It depends on the source of energy. Fossil fuels such as oil, coal and natural gas have high carbon footprints while solar energy, wind energy and nuclear energy have much lower carbon footprints \u0026mdash; but other types of footprints possibly relevant to a policymaker.  ","title":"Kaya identity","url":"https://hugocisneros.com/notes/kaya_identity/"}
    
    , 
    
    {"body":" resources Juergen Schmidhuber\u0026rsquo;s page  In 1941, he constructed the first fully functional programmable computer, the Z3.\nHe suggested in 1967 in his book Calculating space that the universe is running on a Cellular automaton. This is now known as Zuse\u0026rsquo;s thesis.\n","title":"Konrad Zuse","url":"https://hugocisneros.com/notes/konrad_zuse/"}
    
    , 
    
    {"body":"","title":"Language","url":"https://hugocisneros.com/notes/language/"}
    
    , 
    
    {"body":"","title":"Logic","url":"https://hugocisneros.com/notes/logic/"}
    
    , 
    
    {"body":" tags Complexity metrics references (Bennett 1995)  Logical depth can be defined as the run time of the Turing Machine that uses the minimal representation for an input \\(x\\), \\(M_{\\min}(x)\\) \u0026mdash; which is also its Kolmogorov complexity . It is therefore uncomputable (because the minimal representation is uncomputable).\nBibliography Bennett, Charles H.. 1995. \"Logical Depth and Physical Complexity\". In The Universal Turing Machine a Half-Century Survey, edited by Rolf Herken, 2:207–35. Vienna: Springer Vienna. DOI.","title":"Logical depth","url":"https://hugocisneros.com/notes/logical_depth/"}
    
    , 
    
    {"body":"","title":"Mathematics","url":"https://hugocisneros.com/notes/mathematics/"}
    
    , 
    
    {"body":" speaker Andrea Montanari tags Neural networks  Two layers Neural nets to Wasserstein gradient flows Classical Supervised learning setting\n**\n","title":"Mean field theory of neural networks (talk)","url":"https://hugocisneros.com/notes/mean_field_theory_of_neural_networks/"}
    
    , 
    
    {"body":" tags Biological life, Physics  ","title":"Morphogenesis","url":"https://hugocisneros.com/notes/morphogenesis/"}
    
    , 
    
    {"body":"IP Addresses In (Mishra et al. 2020), the authors analyze a set of users' internet traffic for more than 100 days. They observed a little more than 11% of the 34,488 IP addresses they collected were present for more than a month. Many of them were reused throughout the whole experience, making long-term tracking of users possible.\nThe study also shows that 93% of users had a unique fixed set of IP addresses during the whole experiment, making it easy to track them between home, work, etc.\nIt seems from this analysis that IP address-based tracking of users is still relevant in 2020 and not defended against systematically.\nThe only easy way that comes to mind for the general public to prevent IP tracking is a VPN. But it is certainly not perfect either, and not sufficient to avoid all forms of online tracking.\nBibliography Mishra, Vikas, Pierre Laperdrix, Antoine Vastel, Walter Rudametkin, Romain Rouvoy, and Martin Lopatka. 2020. \"Don’t Count Me out: On the Relevance of IP Addresses in the Tracking Ecosystem\", 9.","title":"Online privacy","url":"https://hugocisneros.com/notes/online_privacy/"}
    
    , 
    
    {"body":" tags Evolution, Biological life link Wikipedia  This is a generalization principle in biology stating that stages of development of an organism often resemble some of its ancestors.\n","title":"Ontogeny recapitulates phylogeny","url":"https://hugocisneros.com/notes/ontogeny_recapitulates_phylogeny/"}
    
    , 
    
    {"body":" tags Cryptography  RSA Diffie-Hellman Elliptic curve cryptography ","title":"Public key encryption","url":"https://hugocisneros.com/notes/public_key_encryption/"}
    
    , 
    
    {"body":" tags Neural networks, Data representation  Autoencoders and PCA The relation between Autoencoders and PCA is strong. In particular, a very small autoencoder with only linear activations seems intuitively very close to PCA decomposition. (Bourlard and Kamp 1988) gives an interesting analysis of the uselessness of the activation functions in the encoding layers of an autoencoder when there is no activations in the output layers. In that case, autoencoding is closely related to a sinigular value decomposition of the input data. Quoting Elad Plaut:\n It is well known that an autoencoder with a single fully-connected hidden layer, a linear activation function and a squared error cost function trains weights that span the same subspace as the one spanned by the principal component loading vectors, but that they are not identical to the loading vectors.\n The above quote is from (Plaut 2018) where it is demonstrated that autoencoder weights contain all the information of the loading vectors of the SVD.\nBibliography Bourlard, H., and Y. Kamp. September 1988. \"Auto-Association by Multilayer Perceptrons and Singular Value Decomposition\". Biological Cybernetics 59 (4-5):291–94. DOI. Plaut, Elad. December 28, 2018. \u0026ldquo;From Principal Subspaces to Principal Components with Linear Autoencoders\u0026rdquo;. arXiv:1804.10253 [Cs, Stat]. http://arxiv.org/abs/1804.10253.\n","title":"Autoencoders","url":"https://hugocisneros.com/notes/autoencoders/"}
    
    , 
    
    {"body":" tags Programming languages  Lisp has been a popular set of language for Artificial Intelligence research, from the 1970s to the 1990s.\n","title":"Lisp","url":"https://hugocisneros.com/notes/lisp/"}
    
    , 
    
    {"body":" tags Physics, Morphogenesis  ","title":"Reaction-diffusion","url":"https://hugocisneros.com/notes/reaction_diffusion/"}
    
    , 
    
    {"body":" tags Theory of computation  Finite automata Finite state transducers Implementations  States machines in Rust: link. In Python: python-statemachine  ","title":"Finite state machines","url":"https://hugocisneros.com/notes/finite_state_machines/"}
    
    , 
    
    {"body":" tags Computer science  ","title":"Theory of computation","url":"https://hugocisneros.com/notes/theory_of_computation/"}
    
    , 
    
    {"body":" tags Computer science, Coding  ","title":"Algorithm","url":"https://hugocisneros.com/notes/algorithm/"}
    
    , 
    
    {"body":"","title":"Computer science","url":"https://hugocisneros.com/notes/computer_science/"}
    
    , 
    
    {"body":" tags Machine learning  Data Input/output example pairs: \\[ \\{(x_i, y_i)\\}_{i\\leq n} \\sim_{iid} \\mathbb{P}, \\quad \\mathbb{P} \\in \\mathcal{P}(\\mathcal{X} \\times \\mathcal{Y}) \\text{ unknown} \\]\nMapping We search for a mapping \\(f: \\mathcal{X} \\rightarrow \\mathcal{Y}\\). It is also common to parameterize this mapping with a parameter \\(\\theta \\in \\mathbb{R}^d\\) and write \\(h: \\mathcal{X} \\times \\mathbb{R}^d \\rightarrow \\mathcal{Y}\\).\nThe prediction \\(\\hat{y}\\) is written\n\\[ \\hat{y} = f(x) = h(x, \\theta) \\]\nObjective The goal is to find the above mapping such as to minimize an objective. For example, the objective can be the expectation quadratic loss below: \\[ R(f) = \\mathbb{E}\\left\\{ \\frac{1}{2}(y_{new} - f(x_{new}))^2 \\right\\}, \\quad (y_{new}, x_{new}) \\sim \\mathbb{P} \\]\nIn general we write\n\\[ R(f) = \\mathbb{E}_\\mathbb{P} \\left[ \\ell(y, f(x)) \\right]\\]\nUsually, because this objective cannot be minimized directly \u0026mdash; we don\u0026rsquo;t have access to infinitely many new samples \u0026mdash; minimization on the set of available examples is done instead: this is Empirical risk minimization (ERM).\nEmpirical risk minimization For the above \\(R\\) with least-square loss, ERM is written \\[ \\text{minimize}\\quad \\hat{R}_n(\\theta) := \\frac{1}{2n}\\sum_{i=1}^n(y_i - f(x_i;\\theta))^2, \\] \\[ \\text{subj. to } f(\\cdot;\\theta) : \\mathbb{R}^d \\rightarrow \\mathbb{R}, \\quad \\theta \\in \\Theta \\subseteq \\mathbb{R}^p \\]\nThis minimization problem can be solved using Optimization methods. Gradient descent is one of them. Its stochastic variant is written as follows for the problem above.\n\\[ \\theta^{k+1} = \\theta^k - \\frac{\\epsilon}{2} \\nabla_\\theta(y_{I(k)} - f(x_{I(k)}; \\theta^k))^2 \\] \\[ I(k) \\sim \\text{Unif}([n]) \\]\nExpected risk minimization This other quantity measures the generalization performance of our model , the expectation below is taken with respect to unseen data and thus cannot be computed. This is the setting of a single pass optimization or online learning, and gives the best generalization guarantees.\n\\[ R(f) = \\mathbb{E}_\\mathbb{P} \\left[ \\ell(y, f(x)) \\right]\\]\nUsual losses In general, the loss as the form \\(\\ell: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}\\) Several losses are usually used in the two most common supervised learning settings:\nRegression The quadratic loss is most often used: \\[ \\frac{1}{2} (y - f(x))^2 \\]\nClassification With classification, the prediction \\(y\\) is in \\(\\{ -1, 1 \\}\\), and we usually take \\(\\hat{y} = \\text{sign}(f(x))\\)\nAn \u0026ldquo;ideal\u0026rdquo; loss would be \\(\\ell(y\\cdot f(x)) = 1_{y\\cdot f(x) \u0026lt; 0}\\). Usually, this is substituted for convex losses:\n Hinge loss \\(\\max(0, - y \\cdot f(x) + 1)\\) Square loss \\(\\frac{1}{2}(1- y \\cdot f(x))^2\\) Logistic loss \\(\\log ( 1 + \\exp (- y \\cdot f(x)))\\)  Learning A learning algorithm in the supervised setting can be reduced down to a mapping between the initial set of input/output pairs and a prediction function:\n\\[ L: (\\mathcal{X} \\times \\mathcal{Y})^n \\rightarrow (f: \\mathcal{X} \\rightarrow \\mathcal{Y}) \\]\n","title":"Supervised learning","url":"https://hugocisneros.com/notes/supervised_learning/"}
    
    , 
    
    {"body":"","title":"Rice’s theorem","url":"https://hugocisneros.com/notes/rice_s_theorem/"}
    
    , 
    
    {"body":" tags Biological life  ","title":"RNA-world","url":"https://hugocisneros.com/notes/rna_world/"}
    
    , 
    
    {"body":" tags Programming languages, Coding  ","title":"Rust","url":"https://hugocisneros.com/notes/rust/"}
    
    , 
    
    {"body":" link Reddit comment  Karl Popper famously said: “All life is problem solving.” No theory of consciousness is necessary to define the objectives of a general problem solver. From an AGI point of view, consciousness is at best a by-product of a general problem solving procedure.\nI must admit that I am not a big fan of Tononi\u0026rsquo;s theory. The following may represent a simpler and more general view of consciousness. Where do the symbols and self-symbols underlying consciousness and sentience come from? I think they come from data Compression during problem solving. Let me plagiarize what I wrote earlier [1,2]:\nWhile a problem solver is interacting with the world, it should store the entire raw history of actions and sensory observations including reward signals. The data is ‘holy’ as it is the only basis of all that can be known about the world. If you can store the data, do not throw it away! Brains may have enough storage capacity to store 100 years of lifetime at reasonable resolution [1].\nAs we interact with the world to achieve goals, we are constructing internal models of the world, predicting and thus partially compressing the data history we are observing. If the predictor/compressor is a biological or artificial recurrent neural network (RNN), it will automatically create feature hierarchies, lower level neurons corresponding to simple feature detectors similar to those found in human brains, higher layer neurons typically corresponding to more abstract features, but fine-grained where necessary. Like any good compressor, the RNN will learn to identify shared regularities among different already existing internal data structures, and generate prototype encodings (across neuron populations) or symbols for frequently occurring observation sub-sequences, to shrink the storage space needed for the whole (we see this in our artificial RNNs all the time). Self-symbols may be viewed as a by-product of this, since there is one thing that is involved in all actions and sensory inputs of the agent, namely, the agent itself. To efficiently encode the entire data history through predictive coding, it will profit from creating some sort of internal prototype symbol or code (e. g. a neural activity pattern) representing itself [1,2]. Whenever this representation becomes activated above a certain threshold, say, by activating the corresponding neurons through new incoming sensory inputs or an internal ‘search light’ or otherwise, the agent could be called self-aware. No need to see this as a mysterious process — it is just a natural by-product of partially compressing the observation history by efficiently encoding frequent observations.\n[1] Schmidhuber, J. (2009a) Simple algorithmic theory of subjective beauty, novelty, surprise, interestingness, attention, curiosity, creativity, art, science, music, jokes. SICE Journal of the Society of Instrument and Control Engineers, 48 (1), pp. 21–32.\n[2] J. Schmidhuber. Philosophers \u0026amp; Futurists, Catch Up! Response to The Singularity. Journal of Consciousness Studies, Volume 19, Numbers 1-2, pp. 173-182(10), 2012.\n","title":"Schmidhuber on Consciousness","url":"https://hugocisneros.com/notes/schmidhuber_on_consciousness/"}
    
    , 
    
    {"body":" tags Applied maths resources Wikipedia  Simplest form The SIR model is defined for a population \\(N\\), \\(S\\) the number of susceptible persons, \\(I\\) the number of infected people and \\(R\\) the number of poeple who have recovered. The following system of differential equations governs the evolution of those three variables:\n\\[ \\frac{dS}{dt} = - \\frac{\\beta I S}{N} \\] \\[ \\frac{dI}{dt} = \\frac{\\beta I S }{N}- \\gamma I \\] \\[ \\frac{dR}{dt} = \\gamma I \\]\nThe basic reproduction number \\(R_0\\) is defined by \\[ R_0 = \\frac{\\beta}{\\gamma} \\]\n","title":"SIR model","url":"https://hugocisneros.com/notes/sir_model/"}
    
    , 
    
    {"body":" tags Physics, Statistics  ","title":"Statistical physics","url":"https://hugocisneros.com/notes/statistical_physics/"}
    
    , 
    
    {"body":" tags Applied maths  ","title":"Statistics","url":"https://hugocisneros.com/notes/statistics/"}
    
    , 
    
    {"body":"","title":"C Programming language","url":"https://hugocisneros.com/notes/c_programming_language/"}
    
    , 
    
    {"body":" tags Programming languages, Coding  ","title":"C++","url":"https://hugocisneros.com/notes/c/"}
    
    , 
    
    {"body":" tags Turing-completeness source Gwern Branwen\u0026rsquo;s website  Turing-completeness is common  TC [Turing-completeness], [\u0026hellip;] is [\u0026hellip;] weirdly common: one might think that such universality as a system being smart enough to be able to run any program might be difficult or hard to achieve, but it turns out to be the opposite and it is difficult to write a useful system which does not immediately tip over into TC.\n I\u0026rsquo;ve often been amazed at how common TC can be in sufficiently complicated systems. Because it is so common, Gwern decides to distinguish Accidentally Turing complete systems from Surprisingly Turing complete ones.\nAccidentally Turing complete systems aren\u0026rsquo;t very interesting. They\u0026rsquo;re usually the result of too much complexity built into a game / standard / system / etc.\nSurprisingly Turing-complete The other list is made of systems where one of the primitive is powerful enough to make the whole thing Turing complete. They are really not supposed to be TC; naturally, they are very inefficient, often achieving TC via implementation of a CA construction.\nImplications for computer security Beyond the interest these unexpectedly TC systems represent, security implications can be problematic.\n Why this effort to make a language in which many programs can’t be written? Because TC is intimately tied to Gödel\u0026rsquo;s incompleteness theorem \u0026amp; Rice’s theorem, allowing TC means that one is forfeiting all sorts of provability properties: in a non-TC language, one may be able to easily prove all sorts of useful things to know; for example, that programs terminate, that they are type-safe or not, that they can be easily converted into a logical theorem, that they consume a bounded amount of resources, that one implementation of a protocol is correct or equivalent to another implementation, that there are a lack of side-effects and a program can be transformed into a logically-equivalent but faster version\n ","title":"Surprisingly Turing-Complete","url":"https://hugocisneros.com/notes/surprisingly_turing_complete/"}
    
    , 
    
    {"body":" tags Cryptography  ","title":"Symmetric encryption","url":"https://hugocisneros.com/notes/symmetric_encryption/"}
    
    , 
    
    {"body":" presenter Melanie Mitchell source Youtube  Talk at the Santa Fe Institute on Nov 13, 2019.\nWhat is Artificial Intelligence? Many different things fall under the name AI (self-driving cars, chess playing machines, image classifier, video game AIs, etc.).\n [Building] machines that perform tasks normally requiring human intelligence. \u0026mdash; Nils Nilsson, 1971\n Chess was thought to be the pinnacle of intelligence until a brute-force approach was found to beat any human intelligent approach.\n The study of the common sense world and how a system can find out how to achieve its goals. \u0026mdash; John McCarthy, 1988\n   An anarchy of methods. \u0026mdash; (Lehman, Clune, and Risi 2014)\n This anarchy involves:\n Logic: make computer \u0026ldquo;reason\u0026rdquo; with logical propositions. But it is very brittle, and it is hard to learn or prove something new, never seen before. Statistics: learn form data, collections of data points. Biology: \u0026ldquo;Simulate the brain\u0026rdquo;, this approach has not been successful but recently took over the field.  Machine learning was not the dominant part of the field in 1950s-80s, and deep learning was very tiny. In the 90s, machine learning took over, but deep learning stayed small. But in the 2010s, deep learning took over machine learning.\nDeep learning Image recognition Impressive achievements like facial recognition, image classification, etc.\nImagenet story: between 2011 and 2017, we\u0026rsquo;ve gone from 28% error rate to less than 5% thanks to CNNs. It was reported we\u0026rsquo;ve surpassed human performance, but this is only based on Andrej Karpathy\u0026rsquo;s performance on a randomly sampled subset of the 500k test images.\nSelf-driving cars We also got very impressive claims from the media about self-driving cars everywhere, etc.\nDeep RL Deepmind used algorithms to play Atari games, play Go.\nWhat do these machines actually learn? According to the media, these machines could learn anything.\nBut these machine don\u0026rsquo;t learn like humans at all. The amount of training, of labeled data or replay needed to learn is very much larger in machine learning. Also, humans are designing those neural networks very carefully, etc. but they cannot learn that on their own.\nEdge cases are a particular flaw of these machine learning systems. For example, what counts as an obstacle for a self-driving car (plastic bag or rock, birds, broken glass)?\nHumans use common sense to deal with those edge cases.\nIn machine learning, the system will learn what is in the data to fulfill the objective, not what we think it should learn.\nAdversarial attacks on deep learning Researchers discovered it is possible to add very small perturbations to a deep neural network\u0026rsquo;s input and make it classify the image as anything.\nThis has also been shown to work for facial recognition software.\nMeaning and machine learning  I wonder whether or when AI will ever crash the barrier of meaning.\n\u0026mdash; Gian-Carlo Rota, 1985\n We don\u0026rsquo;t have good definitions for concepts we are trying to approach, reproduce and simulate \u0026mdash; things like \u0026ldquo;understanding\u0026rdquo;, \u0026ldquo;intelligence\u0026rdquo;, \u0026ldquo;reasoning\u0026rdquo;, \u0026ldquo;common sense\u0026rdquo; are not well understood. We don\u0026rsquo;t know how our brains work. But if we want these things to come into our live, we are going to need to understand them.\nThe barrier of meaning Give machines common sense? Example of the Winograd challenge to evaluate NLP systems.\nWe are far from the common sense of a 18 months old baby. Interesting paradox between impressive superhuman performances for some tasks and complete lack of understanding of very basic things.\nA computer needs knowledge about the world to interact with it. We have intuitive physics, biology, psychology. It also needs a mental model of causes and effects and capability to abstract from world-knowledge.\nWhat is a concept and how can we teach it to a machine?\n Without concepts there can be no thoughts, and without analogies there can be no concepts.\n\u0026mdash; D. Hofstadter \u0026amp; E. Sander, Surfaces and essences (2013)\n   How to form and fluidly use concepts is the most important open problem in AI.\n Bibliography Lehman, Joel, Jeff Clune, and Sebastian Risi. 2014. \"An Anarchy of Methods: Current Trends in How Intelligence Is Abstracted in Ai\". IEEE Intelligent Systems 29 (6). IEEE:56–62.","title":"Talk: Artificial Intelligence: A Guide for Thinking Humans","url":"https://hugocisneros.com/notes/talk_artificial_intelligence_a_guide_for_thinking_humans/"}
    
    , 
    
    {"body":" presenter Michal Rolinek tags Combinatorics, Machine learning  The goal is to merge combinatorial optimization and deep learning.\nMake use of strong battle tested optimization methods. Some of those can find almost-optimal solutions to NP-hard problems in ~quadratic time.\nGoal is to cover many combinatorial problems, TSP multi-cut, etc.\n fast backward pass theoretically sound easy to use  But the goal is not to take a combinatorial problem but just relax it to make it differentiable, because there is often a huge price to pay for this.\nMany think that it is essential to extend classical deep learning with combinatorics for AI.\nPipeline:\nWe get an input -\u0026gt; learn a representation with deep learning -\u0026gt; use existing solver for features and maybe pass this output in another layer of deep learning\nA solve is a function taking continuous inputs and returns a discrete output (TSP: graph nodes coordinates -\u0026gt; shortest path).\nAlthough objectives are often linear, this is usually still a huge cost. Many classical problems fall into this category. The main difficulty is often the gradient of this black-box optimizer. Usually those solvers are contrary to general opinion perfectly differentiable, actually piece-wise constant. -\u0026gt; problem the gradient is almost always 0. Estimating the \u0026ldquo;real\u0026rdquo; gradient doesn\u0026rsquo;t help at all.\nSome non-solutions:\n Sample finite differences Apply smoothing Use some zero-order method?  But these methods need a lot a samples to be accurate, and the samples are potentially very expensive because the solver is expensive.\n\\(x \\rightarrow \u0026hellip; \\rightarrow w \\rightarrow y \u0026hellip; \\rightarrow L\\) Let\u0026rsquo;s consider \\(L(w)\\), sometimes a function \\(f(w)\\) can be representative.\nInterpolate \\(L(w)\\) to \\(L^\\lambda(w)\\) where lambda controls \u0026ldquo;locality\u0026rdquo; of interpolation. But the interpolation is implicit, and the gradient of this interpolated function can be estimated with only one evaluation of the solver. This exploits the fact that the solver minimizes a linear objective.\nInput \\(dL/dy\\) and output \\(dL/dw\\)\nLambda shifts \u0026ldquo;islands\u0026rdquo; of constant values and linear slope appears in between them.\n","title":"Talk: Differentiation of black-box combinatorial solvers","url":"https://hugocisneros.com/notes/talk_differentiation_of_black_box_combinatorial_solvers/"}
    
    , 
    
    {"body":" tags Neural network training resources The AI podcast papers (Frankle and Carbin 2018)  When training very large neural networks, the obtained net might have a lot of unused neurons. It is possible, through neural network pruning, to remove a lot of those unused connections to make the overall architecture lighter and faster to run on some hardware.\nHowever, once you have the pruned architecture, it will often not be able to learn anything interesting when it is trained from scratch. The lottery ticket hypothesis is about the reason some of these randomly initialized neurons became more important than others. It is possible that random initialization is actually very important for a neuron to be useful after training, and the lottery ticket hypothesis is about finding this \u0026ldquo;magic\u0026rdquo; initialization to use it on small networks.\nFrom (Frankle and Carbin 2018):\n The Lottery Ticket Hypothesis. A randomly-initialized, dense neural network contains a subnetwork that is initialized such that \u0026mdash; when trained in isolation \u0026mdash; it can match the test accuracy of the original network after training for at most the same number of iterations.\n It turns out restarting pruned small network training from the exact initialization the initial network started from achieves excellent results. However, this hypothesis holds mostly for small neural networks. In larger networks, the pruned network is usually found more early in training.\nBibliography Frankle, Jonathan, and Michael Carbin. March 9, 2018. \"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks\". arXiv:1803.03635 [Cs]. http://arxiv.org/abs/1803.03635.","title":"The Lottery ticket hypothesis","url":"https://hugocisneros.com/notes/the_lottery_ticket_hypothesis/"}
    
    , 
    
    {"body":" tags Economics  ","title":"Decentralization","url":"https://hugocisneros.com/notes/decentralization/"}
    
    , 
    
    {"body":" tags Applied maths  ","title":"Optimal transport","url":"https://hugocisneros.com/notes/optimal_transport/"}
    
    , 
    
    {"body":"","title":"Physics","url":"https://hugocisneros.com/notes/physics/"}
    
    , 
    
    {"body":" tags Machine learning  Data representation is about finding compact representation of high dimensional data (such as images, videos, 3D shapes, etc.)\nSeveral methods have been developed for this purpose such as PCA, Neural networks-based representation, Autoencoders.\n","title":"Data representation","url":"https://hugocisneros.com/notes/data_representation/"}
    
    , 
    
    {"body":" tags Artificial life, Life  ","title":"Evolution","url":"https://hugocisneros.com/notes/evolution/"}
    
    , 
    
    {"body":"","title":"Downs–Thomson paradox","url":"https://hugocisneros.com/notes/downs_thomson_paradox/"}
    
    , 
    
    {"body":" tags Economics  Definition The weekly newspaper The Economist is often described as having economic liberalism among its political alignment.\nDecentralization, globalization and economic liberalism Many economic liberalism advocates consider that economic decision should follow some natural tendencies. This, to me, is related to some energy minimization principles where letting everything go normally should lead to the optimal configuration.\nIn the case of Decentralization, an almost immediate effect is the decrease of prices of some common goods which usually make people happier. However, it is clear that it is not the only effect, and the loss of jobs that results from decentralization might in turn cost the society more in unemployment benefits (among other things) that the net benefit of having some goods be cheaper.\n","title":"Economic liberalism","url":"https://hugocisneros.com/notes/economic_liberalism/"}
    
    , 
    
    {"body":" tags Physics, Statistical physics  Boltzmann brain Boltzmann brain is an interesting concept offered initially in response to one of Ludwig Boltzmann\u0026rsquo;s explanation for the low-entropy state of the Universe. He hypothesized that even a fully random universe would fluctuate towards lower-entropy states. The issue is that many phenomena such as evolved life on Earth are so far from equilibrium it looks like they were extremely unlikely to have happened. In particular, it is much more likely that a single brain would emerge out of the void from random fluctuations than the present state of Earth in terms of distance to equilibrium.\nThis question of going against equilibrium is interesting and poses some deep questions about the evolution of life on Earth. One obvious objection that comes to mind when relating this to complexity measures and studies of emergence is the fact that simple distance to equilibrium is not a sufficient measure of the complexity of a system and the number of paths leading to this state is also meaningful. Emergence of complexity is happening constantly, but the only tiny fraction of it that is conserved does it because it builds on smaller stable components that it will keep building on (see (Simon 1962)). In the brain vs. humans example, humans where probably more likely to appear because given the local conditions on Earth enabling Evolution, higher complexity was bound to emerge. On the other hand, a single brain popping from the void is a an event that could only result from pure luck and the miraculous alignment of infinitely many unlikely events.\nAnother thing related to the study of Cellular automata and Evolution is the fact that right now we are more or less searching for a Boltzmann brain inside automata by just sampling them and letting them run. The key is probably, in a similar fashion than humans aren\u0026rsquo;t a Boltzmann brain, to create the conditions for complexity to keep increasing without being subjected to random fluctuations of the universe.\nBibliography Simon, Herbert A.. 1962. \"The Architecture of Complexity\". Proceedings of the American Philosophical Society 106 (6). American Philosophical Society:467–82. https://www.jstor.org/stable/985254.","title":"Boltzmann brain","url":"https://hugocisneros.com/notes/boltzmann_brain/"}
    
    , 
    
    {"body":" tags Unconventional computing  ","title":"Chaos computing","url":"https://hugocisneros.com/notes/chaos_computing/"}
    
    , 
    
    {"body":"","title":"Climate","url":"https://hugocisneros.com/notes/climate/"}
    
    , 
    
    {"body":" tags Mathematics  ","title":"Combinatorics","url":"https://hugocisneros.com/notes/combinatorics/"}
    
    , 
    
    {"body":" tags Mathematics  ","title":"John Conway","url":"https://hugocisneros.com/notes/john_conway/"}
    
    , 
    
    {"body":"","title":"Marvin Minsky","url":"https://hugocisneros.com/notes/marvin_minsky/"}
    
    , 
    
    {"body":" tags Neural networks papers (LeCun, Denker, and Solla 1990; Hassibi and Stork 1993; Han et al. 2015; Li et al. 2016)  Bibliography Han, Song, Jeff Pool, John Tran, and William Dally. 2015. \"Learning Both Weights and Connections for Efficient Neural Network\". In Advances in Neural Information Processing Systems, 1135–43. Hassibi, Babak, and David G. Stork. 1993. \u0026ldquo;Second Order Derivatives for Network Pruning: Optimal Brain Surgeon\u0026rdquo;. In Advances in Neural Information Processing Systems, 164–71.\nLeCun, Yann, John S. Denker, and Sara A. Solla. 1990. \u0026ldquo;Optimal Brain Damage\u0026rdquo;. In Advances in Neural Information Processing Systems, 598–605.\nLi, Hao, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. 2016. \u0026ldquo;Pruning Filters for Efficient Convnets\u0026rdquo;. arXiv Preprint arXiv:1608.08710.\n","title":"Neural network pruning","url":"https://hugocisneros.com/notes/neural_network_pruning/"}
    
    , 
    
    {"body":" tags Programming languages, Coding  ","title":"Ruby","url":"https://hugocisneros.com/notes/ruby/"}
    
    , 
    
    {"body":" tags Programming languages, Coding  ","title":"Scala","url":"https://hugocisneros.com/notes/scala/"}
    
    , 
    
    {"body":" tags Machine learning, Neural networks  Adversarial examples in Reinforcement learning ","title":"Adversarial examples","url":"https://hugocisneros.com/notes/adversarial_examples/"}
    
    , 
    
    {"body":" tags Cellular automata resources Wikipedia  ","title":"Abelian sandpile model","url":"https://hugocisneros.com/notes/abelian_sandpile_model/"}
    
    , 
    
    {"body":" tags Mathematics  ","title":"Hyperbolic geometry","url":"https://hugocisneros.com/notes/hyperbolic_geometry/"}
    
    , 
    
    {"body":" tags Complexity  ","title":"Emergence","url":"https://hugocisneros.com/notes/emergence/"}
    
    , 
    
    {"body":" tags Physics  Chaos is a striking example of emergence. Deterministic equations of motions lead to completely unpredictable over time. Randomness has emerged from these deterministic laws.\nFrom (Crutchfield 1994):\n Where in the determinism did the randomness come from? The answer is that the effective dynamic, which maps from initial conditions to states at a later time, becomes so complicated that an observer can neither measure the system accurately enough nor compute with sufficient power to predict the future behavior when given an initial condition. The emergence of disorder here is the product of both the complicated behavior of nonlinear dynamical systems and the limitations of the observer.\n Bibliography Crutchfield, James P.. August 1, 1994. \"The Calculi of Emergence: Computation, Dynamics and Induction\". Physica D: Nonlinear Phenomena 75 (1):11–54. DOI.","title":"Chaos","url":"https://hugocisneros.com/notes/chaos/"}
    
    , 
    
    {"body":" resources Page of Pablo Funes' PhD thesis  What is complexity? What is complexity?: The question is very much too vast to be answered in something smaller than a whole book. I am planning on dedicating an entire post about measuring complexity with a range of metrics that people have come up with in the past. A big question I\u0026rsquo;m asking myself is: \u0026ldquo;How much does complexity depend on subjectivity and the observer?\u0026rdquo;\nComplexity is about studying systems and models which components interact in multiple ways and according to local rules. This very general framework is often called complex systems.\nComplexity has various meanings depending on the fields and therefore can be applied to a wide range of systems.\nHowever, its lack of clear definition makes it difficult to measure and estimate. The concept of complexity is hard to study in practice for a given system.\nComplex Systems Complex systems are systems made of many components that interact together. They usually exhibit behaviors that can be labeled as complex.\nComplexity and order A.N. Whitehead on “Ideal Opposites” in Process and Reality:\n Order is not sufficient. What is required, is something much more complex. It is order entering upon novelty; so that the massiveness of order does not degenerate into mere repetition; and so that the novelty is always reflected upon a background of system.\n Emergence and Self-organization The study of complexity is often linked to the study of emergence and self-organization. They terms often refer to the spontaneous apparition of complex structures in a system made of simpler components.\nFeatures of a complex process From (Grassberger 1989)\n Between disorder and order. Hard to describe and not just random structures. Often involve hierarchies Feeback loops, for example from lower levels of the hierarchy. Higher-level concepts arise without being put in explicitely. Complex systems are composed of many parts with strong and non-trivial correlations between these parts. Are they spontaneous or do they need to be encoded? (GOL glider gun vs. spontaneous spaceships in some rules) Correlations between the object and its environment. Examples: complexity of DNA exists because of its correlation with the reading machinery, and the protein building machinery, etc. up to the whole organism. It has meaning, meaning that only some of the features of the system are essentials, and one can create a compressed on more \u0026ldquo;intelligent\u0026rdquo; description. Therefore this could be related to compressibility.  Complexity growth in living systems Complexity doesn\u0026rsquo;t have to grow in living systems. And believing that living organisms evolve towards greater complexity is a common fallacy in the study of biological evolution.\n First, living systems do not evolve in response to environmental changes, and Earth\u0026rsquo;s history has shown that going extinct is for instance a much more common response to environmental changes. Species survive environmental changes because they happen to have some parts of its population with an evolutionary advantage compared to other species. According to some, complexity therefore does not necessarily increase in living organisms that evolve, because the path to survival to environmental change might actually be a decrease in complexity (e.g number of bones in the jaw see this link). This is not the opinion supported by many older works as explained in (McShea 1991) .  Bibliography Grassberger, Peter. 1989. \"Randomness, Information, and Complexity\". In Proceedings of the 5th Mexican School on Statistical Physics. http://arxiv.org/abs/1208.3459. McShea, Daniel W.. July 1991. \u0026ldquo;Complexity and Evolution: What Everybody Knows\u0026rdquo;. Biology \u0026amp; Philosophy 6 (3):303–24. DOI.\n","title":"Complexity","url":"https://hugocisneros.com/notes/complexity/"}
    
    , 
    
    {"body":" tags Coding  Make is a build automation tool.\nDon\u0026rsquo;t deal with tabs I have been annoyed with tabs in Makefiles many times. Some editors or copy-pasting functions automatically convert tabs to space and vice-versa and this can break your Makefile.\nWith GNU Make 4.0 or later, it is possible to set the prefix to some other fixed token. To use \u0026gt; as a prefix, put this at the beginning of your Makefile:\nifeq ($(origin .RECIPEPREFIX), undefined) $(error \u0026#34;This Make does not support .RECIPEPREFIX. \\ Please use GNU Make 4.0 or later\u0026#34;) endif .RECIPEPREFIX = \u0026gt; Document a make file for a user Large Makefiles with lots of recipes can be overwhelming for someone trying your software for the first time. Many conventions exist about which standard recipes should be there, but it is also efficient to document them. This can be done by adding the following recipe to the Makefile (which will be run by default, to change this behavior, remove the first line):\n.DEFAULT_GOAL := help .PHONY: help help: @grep -E \u0026#39;^[a-zA-Z0-9_-]+:.*?## .*$$\u0026#39; $(MAKEFILE_LIST) \\  | sed -n \u0026#39;s/^\\(.*\\): \\(.*\\)##\\(.*\\)/\\1|\\3/p\u0026#39; \\  | column -t -s \u0026#39;|\u0026#39; ","title":"Make","url":"https://hugocisneros.com/notes/make/"}
    
    , 
    
    {"body":" tags Cellular automata, Finite state machines  From (Hanson and Crutchfield 1997):\n Finite state machines are appropriate for investigating pattern dynamics of CAs for a number of reasons, among which we may note the following:\n FAs encompass the full range of behavior types from periodic to complex to random; Characterization of patterns using FAs makes possible a definition of pattern complexity which is both natural and computable in practice; Ensemble evolution in the space of regular languages is closed under the CA rule; The CA update rule is itself an FST; Automated inference techniques exist for reconstructing FAs from experimental data   Bibliography Hanson, James E., and James P. Crutchfield. April 15, 1997. \"Computational Mechanics of Cellular Automata: An Example\". Physica D: Nonlinear Phenomena, Lattice Dynamics, 103 (1):169–89. DOI.","title":"Cellular automata as regular languages","url":"https://hugocisneros.com/notes/cellular_automata_as_regular_languages/"}
    
    , 
    
    {"body":" tags Complex Systems  ","title":"Chemical reaction network","url":"https://hugocisneros.com/notes/chemical_reaction_network/"}
    
    , 
    
    {"body":" tags Machine learning  ","title":"Kernel Methods","url":"https://hugocisneros.com/notes/kernel_methods/"}
    
    , 
    
    {"body":"","title":"NEAT","url":"https://hugocisneros.com/notes/neat/"}
    
    , 
    
    {"body":" tags Network authentication, Cryptography resources Main page, Computerphile video  Kerberos is a centralized authentication protocol that uses Symmetric encryption as its main way of ensuring Online privacy on a network with a trusted central entity (e.g. a corporate network).\nA central server must have long term keys for every user on the network. It uses these keys to securely issue session keys with other devices on the network thanks to a Ticket-granting server (TGS).\nThe protocol goes something like this:\n New user A on the network with long term key shared with the authentication server  Sends a TGS request to the authentication server S. If S does have a key with A, \\(K_{\\mathtt{AS}}\\), it generates a key \\(K_{\\mathtt{A,TGS}}\\) and sends back two messages.  A message containing \\(K_{\\mathtt{A,TGS}}\\) encrypted with \\(K_{\\mathtt{AS}}\\) to be read by A. Another message encrypted with S and TGS shared key containing \\(K_{\\mathtt{A,TGS}}\\) to be read by TGS.   Therefore, A now has a key to communicate with the TGS and a unreadable ticket-granting ticket that TGS will decrypt and use to communicate with A.   User A wants to communicate with user B  A sends a request to TGS encrypted with \\(K_{\\mathtt{A,TGS}}\\) to communicate with B. If B is known to TGS, it sends back a message encrypted with \\(K_{\\mathtt{A,TGS}}\\) containing a generated session key \\(K_{\\mathtt{AB}}\\) and another message containing the same key but encrypted with \\(K_{\\mathtt{B,TGS}}\\). A forwards the message encrypted with \\(K_{\\mathtt{B,TGS}}\\) to B and may begin communicating securely with B.    This is an interesting protocol, which doesn\u0026rsquo;t use Public key encryption at all. It also uses only a key per device on the network, which is a lot less than a key per pair of devices.\nSome of its drawbacks include the fact that its a single point of failure system, because every user relies on a central entity to communicate. It the TGS gets compromised or is taken down, communication is not possible anymore.\n","title":"Kerberos","url":"https://hugocisneros.com/notes/kerberos/"}
    
    , 
    
    {"body":"Protocols Password authentication This is one of the simplest authentication method. The idea is just to send a pair (username, password) to the server. It is obviously vulnerable to man-in-the-middle attacks.\nKerberos ","title":"Network authentication","url":"https://hugocisneros.com/notes/network_authentication/"}
    
    , 
    
    {"body":"","title":"Philosophy","url":"https://hugocisneros.com/notes/philosophy/"}
    
    , 
    
    {"body":" tags NLP  (Minaee et al. 2020)\nBibliography Minaee, Shervin, Nal Kalchbrenner, Erik Cambria, Narjes Nikzad, Meysam Chenaghlu, and Jianfeng Gao. April 5, 2020. \"Deep Learning Based Text Classification: A Comprehensive Review\". arXiv:2004.03705 [Cs, Stat]. http://arxiv.org/abs/2004.03705.","title":"Text classification","url":"https://hugocisneros.com/notes/text_classification/"}
    
    , 
    
    {"body":" tags Unconventional computing papers (Abelson et al. 2000) resources Wikipedia, CSAIL\u0026rsquo;s website   From (Abelson et al. 2000):\nA colony of cells cooperates to form a multicellular organism under the direction of a genetic program shared by the members of the colony. A swarm of bees cooperates to construct a hive. Humans group together to build towns, cities, and nations.\n Amorphous computing was coined by Abelson, Knight, Sussman et al. It refers to computational systems composed of a large number of identical parallel devices (processors) with limited computational capacity. The processors interact locally, without particular knowledge of their position in the medium.\n [\u0026hellip;] this paper argues that now is an opportune time to tackle the engineering of emergent order: to identify the engineering principles and languages that can be used to observe, control, organize, and exploit the behavior of programmable multitudes.\n Cellular automata can be seen as a kind of elementary amorphous computing device.\nBibliography Abelson, Harold, Don Allen, Daniel Coore, Chris Hanson, George Homsy, Thomas F. Knight Jr, Radhika Nagpal, Erik Rauch, Gerald Jay Sussman, and Ron Weiss. 2000. \"Amorphous Computing\". Communications of the ACM 43 (5). ACM New York, NY, USA:74–82.","title":"Amorphous computing","url":"https://hugocisneros.com/notes/amorphous_computing/"}
    
    , 
    
    {"body":" tags Complex Systems, Physics  ","title":"Ising model","url":"https://hugocisneros.com/notes/ising_model/"}
    
    , 
    
    {"body":"Optimal control Bellman J*(x) = min_u {c(x, u) + J*(F(x, u))} == Dynamic programming equation\nWe define the Q fn as such J*(x) = min_u Q*(x, u)\n","title":"2021-10-27","url":"https://hugocisneros.com/notes/2021-10-27/"}
    
]
