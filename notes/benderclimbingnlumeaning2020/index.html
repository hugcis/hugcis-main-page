<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1">
  <title>Notes on: Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data by Bender, E. M., & Koller, A. (2020) - Hugo Cisneros - Personal page</title>
  <meta property="og:title" content="Notes on: Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data by Bender, E. M., &amp; Koller, A. (2020) - Hugo Cisneros - Personal page">
  <meta property="og:type" content="article">
  <meta property="og:image" content="/img/main.jpeg">
  <meta property="og:url" content="https://hugocisneros.com/notes/benderclimbingnlumeaning2020/">
  <meta property="og:description" content="Notes about Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data by Bender, E. M., &amp; Koller, A. (2020)">
  <meta name="Description" property="description" content="Notes about Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data by Bender, E. M., &amp; Koller, A. (2020)">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@cisne_hug">
  <meta name="twitter:creator" content="@cisne_hug">
  <link rel="stylesheet" href="https://hugocisneros.com/css/main.min.914a9407ca164cc303752993663b9b622d3922262de606128ff489937b2e2dd7.css" media="all" type="text/css">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="theme-color" content="#ffffff">
  <link rel="webmention" href="https://webmention.io/hugocisneros.com/webmention">
  <link rel="pingback" href="https://webmention.io/hugocisneros.com/xmlrpc">
</head>
<body>
  <div class="wrapper">
    <header class="header">
      <nav class="nav">
        <div class="nav-main">
          <a href="https://hugocisneros.com/" class="nav-title">Hugo Cisneros - Personal page</a>
        </div>
        <ul class="nav-links">
          <li>
            <a href="/about/">About</a>
          </li>
          <li>
            <a href="/blog/">Blog</a>
          </li>
          <li>
            <a href="/notes/">Notes</a>
          </li>
          <li>
            <a href="/resume/">Resume</a>
          </li>
        </ul>
      </nav>
    </header>
    <main class="content" role="main">
      <article class="article h-entry" itemprop="mainEntity" itemscope itemtype="http://schema.org/BlogPosting">
        <div class="single-note note-container">
          <h1 class="article-title p-name" itemprop="name">Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data by Bender, E. M., & Koller, A. (2020)</h1>
          <div class="article-content e-content p-name" itemprop="articleBody">
            <dl>
              <dt>source</dt>
              <dd>
                (<a href="#org26e7183">Bender and Koller 2020</a>)
              </dd>
              <dt>tags</dt>
              <dd>
                <a href="/notes/nlp/">NLP</a>, <a href="/notes/artificial_intelligence/">Artificial Intelligence</a>, <a href="/notes/evaluating_nlp/">Evaluating NLP</a>
              </dd>
            </dl>
            <h2 id="summary">Summary</h2>
            <p>The main point of the article could be summarized like so:</p>
            <blockquote>
              <p>We argue that <em>the language modeling task, because it only uses form as training data, cannot in principle lead to learning of meaning</em>. We take the term <em>language model</em> to refer to any system trained only on the task of string prediction, whether it operates over characters, words or sentences, and sequentially or not. We take (linguistic) <em>meaning</em> to be the relation between a linguistic form and communicative intent.</p>
            </blockquote>
            <p>Several NLP papers (cited in the text) use overly confident claims about <a href="/notes/language_modeling/">language models</a> <em>understanding</em> a piece of text or knowledge.</p>
            <p>The authors formalize <em>meaning</em> with a set of pairs \(M \subseteq E \times I\), \((e, i)\) representing natural language expressions and their <em>communicative intent</em>. In this framework, <em>understanding</em> means being able to retrieve \(i\) when given \(e\).</p>
            <p>They also mention the concept of conventional meaning, i.e. the communicative potential \(s\) of a form \(e\) which is constant across contexts of use of the form \(e\).</p>
            <p>When communicating, a speaker has a prior intent \(i\), and has to choose a form \(e\) with the right potential \(s\) that fits \(i\). The argument of the paper is that there isn’t enough signal in a text corpus to learn the above relations in \(M\).</p>
            <p>A nice example is the <a href="/notes/chinese_room_experiment/">Chinese room experiment</a>, wherein a person is tasked with answering questions in Chinese by consulting a library of Chinese books according to fixed rules. Such a person would <em>look</em> intelligent without having any actual understanding of Chinese.</p>
            <p>A nice example is the problem of learning language models on <a href="/notes/programming_languages/">Programming languages</a>. No matter how good a LM is at learning the semantics of the language, it has no way of learning the relations between program inputs and outputs.</p>
            <p>The authors provide more example why human-language acquisition is fundamentally different from the flawed language models.</p>
            <p>A good LM might learn to give meaningful answers, but will need to store infinite amount of data and will ultimately fail at dealing with the ever evolving set of forms humans use.</p>
            <h2 id="comments">Comments</h2>
            <p>Regarding the programming language example, one could argue that by learning the semantics of the language on a large corpus, a LM will eventually have to learn inputs/outputs mapping for intermediate functions in the larger programs, and could build understanding from these small building blocks. However, no explicit mechanisms in current language models allow for combining and re-using building blocks like that.</p>
            <p>This is the same with language models, as long as we use <a href="/notes/neural_networks/">neural networks</a> trained with <a href="/notes/gradient_descent/">Gradient descent</a>, it will probably never have this power humans have to re-use and create forms to manipulate meaning and deal with a changing world. In a way GPT-3 (<a href="#org2fbcdf7">Brown et al. 2020</a>) has showed that we can get to a pretty impressive point with sentence prediction alone provided we have enough storage.</p>
            <h2 id="bibliography">Bibliography</h2>
            <p><a id="org26e7183"></a><span itemscope itemtype="https://schema.org/ScholarlyArticle"><span itemprop="author"><span itemprop="author">Bender, Emily M.</span>, and <span itemprop="author">Alexander Koller</span></span>. <span datetime="2020" itemprop="datePublished">July 2020</span>. “<span itemprop="name">Climbing Towards NLU: On Meaning, Form, and Understanding in the Age of Data</span>”. In <span itemprop="isPartOf" itemscope itemtype="https://schema.org/Periodical"><i itemprop="name">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</i></span>, 5185–98. Online: Association for Computational Linguistics.</span></p>
            <p><a id="org2fbcdf7"></a><span itemscope itemtype="https://schema.org/ScholarlyArticle"><span itemprop="author"><span itemprop="author">Brown, Tom B.</span>, <span itemprop="author">Benjamin Mann</span>, <span itemprop="author">Nick Ryder</span>, <span itemprop="author">Melanie Subbiah</span>, <span itemprop="author">Jared Kaplan</span>, <span itemprop="author">Prafulla Dhariwal</span>, <span itemprop="author">Arvind Neelakantan</span>, et al.</span>. <span datetime="2020" itemprop="datePublished">June 2020</span>. “<span itemprop="name">Language Models Are Few-Shot Learners</span>”. <span itemprop="isPartOf" itemscope itemtype="https://schema.org/Periodical"><i itemprop="name">arXiv:2005.14165 [Cs]</i></span>, June.</span></p>
          </div>
          <div class="note-footer">
            Last changed <a class="u-url" href="https://hugocisneros.com/notes/benderclimbingnlumeaning2020/"><time itemprop="datePublished" class="dt-published" datetime="2021-03-25T09:57:00+0100">25/03/2021</time></a> | authored by <a href="https://hugocisneros.com/" rel="author" class="p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Hugo Cisneros</span></a>
          </div>
        </div>
      </article><br>
      <a href="/notes#benderclimbingnlumeaning2020"><b>← Back to Notes</b></a>
      <hr>
    </main>
    <footer class="footer">
      <ul class="footer-links">
        <li>
          <a class="rss-link" href="/blog/index.xml" type="application/rss+xml" target="_blank">Blog <img class="rss-icon" src="/img/RSS.svg" alt="RSS feed icon"></a>
        </li>
        <li>
          <a href="https://github.com/hugcis/natrium-custom">Code</a>
        </li>
        <li>© Hugo Cisneros 2021</li>
      </ul>
    </footer>
  </div>
  <script>
  MathJax = {
     tex: {
         inlineMath: [['$','$'], ['\\(', '\\)']],
         tags: 'ams'
     }
  };
  </script> 
  <script type="text/javascript" rel="preconnect" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
