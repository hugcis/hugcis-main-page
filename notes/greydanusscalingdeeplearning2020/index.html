<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1">
  <title>Notes on: Scaling down Deep Learning by Greydanus, S. (2020) - Hugo Cisneros</title>
  <meta property="og:title" content="Notes on: Scaling down Deep Learning by Greydanus, S. (2020) - Hugo Cisneros">
  <meta property="og:type" content="article">
  <meta property="og:image" content="/img/main.jpeg">
  <meta property="og:url" content="https://hugocisneros.com/notes/greydanusscalingdeeplearning2020/">
  <meta property="og:description" content="Notes about Scaling down Deep Learning by Greydanus, S. (2020)">
  <meta name="Description" property="description" content="Notes about Scaling down Deep Learning by Greydanus, S. (2020)">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@cisne_hug">
  <meta name="twitter:creator" content="@cisne_hug">
  <link rel="stylesheet" href="https://hugocisneros.com/css/main.min.css" media="all" type="text/css">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="theme-color" content="#ffffff">
  <link rel="webmention" href="https://webmention.io/hugocisneros.com/webmention">
  <link rel="pingback" href="https://webmention.io/hugocisneros.com/xmlrpc">
</head>
<body>
  <div class="wrapper">
    <header class="header">
      <nav class="nav">
        <div class="nav-main">
          <a href="https://hugocisneros.com/" class="nav-title">Hugo Cisneros</a>
        </div>
        <ul class="nav-links">
          <li>
            <a href="/blog/">Blog</a>
          </li>
          <li>
            <a href="/notes/">Notes</a>
          </li>
          <li>
            <a href="/projects/">Projects</a>
          </li>
          <li>
            <a href="/resume/">Resume</a>
          </li>
          <li>
            <a href="/contact/">Contact</a>
          </li>
        </ul>
      </nav>
    </header>
    <main class="content" role="main">
      <article class="article h-entry" itemprop="mainEntity" itemscope itemtype="http://schema.org/BlogPosting">
        <div class="single-note note-container">
          <h1 class="article-title p-name" itemprop="name">Scaling down Deep Learning by Greydanus, S. (2020)</h1>
          <div class="article-content e-content p-name" itemprop="articleBody">
            <dl>
              <dt>tags</dt>
              <dd>
                <a href="/notes/neural_networks/">Neural networks</a>
              </dd>
              <dt>source</dt>
              <dd>
                (<a href="#greydanusScalingDeepLearning2020"><cite itemprop="citation" itemscope itemid="key:greydanusScalingDeepLearning2020">Greydanus 2020</cite></a>)
              </dd>
            </dl>
            <h2 id="summary">Summary</h2>
            <p>This paper introduces a minimalist 1D version of the MNIST dataset for studying some basic properties of neural networks. The authors simplify the MNIST dataset by assigning a 1D glyph to each digit. These glyphs are padded, translated, sheared and blurred to build a dataset of multiple different objects.</p>
            <p>The figure from the paper shown below illustrates this dataset’s construction:</p>
            <p>{{&lt; img src="/img/greydanusScalingDeepLearning2020.jpg" title=“1D simple MNIST” width=600 alt=“1D simple MNIST” class=“center” &gt;}}</p>
            <p>This dataset is shown to be a suitable tool to study very small neural networks and their properties. The authors discuss:</p>
            <ul>
              <li>
                <a href="/notes/the_lottery_ticket_hypothesis/">Lottery tickets</a>
              </li>
              <li>
                <a href="/notes/double_descent/">Double descent</a>
              </li>
              <li>Metalearning</li>
              <li>The use of strong spatial priors such as translation invariance</li>
              <li>Pooling methods</li>
            </ul>
            <h2 id="comments">Comments</h2>
            <p>This is an interesting paper, which for once isn’t about getting bigger models or better results than the state of the art. The small MNIST dataset may lead to interesting insights into the functioning of neural networks but I’m not sure that will be enough for solving the big questions about deep learning. The secrets of those huge recent models might elude us for a while simply because we don’t have the resources (mathematical or computational) to study them.</p>
            <h2 id="bibliography">Bibliography</h2>
            <ol class="biblio-list">
              <li itemprop="citation" itemscope itemtype="https://schema.org/ScholarlyArticle" id="greydanusScalingDeepLearning2020">
                <span itemprop="author">Greydanus, Sam</span>. <time datetime="2020" itemprop="datePublished">November 29, 2020</time>. "<span itemprop="name">Scaling *down* Deep Learning</span>". <span itemprop="isPartOf" itemscope itemtype="https://schema.org/Periodical"><i itemprop="name">Arxiv:2011.14439 [cs, Stat]</i></span>. <a itemprop="sameAs" href="http://arxiv.org/abs/2011.14439">http://arxiv.org/abs/2011.14439</a>.
              </li>
            </ol>
          </div>
          <div class="bl-section">
            <h2>Links to this note</h2>
            <div class="backlinks">
              <ul>
                <li>
                  <a href="/notes/greydanusscalingdeeplearning2020/">Notes on: Scaling down Deep Learning by Greydanus, S. (2020)</a>
                </li>
              </ul>
            </div>
          </div>
          <div class="note-footer">
            Last changed <a class="u-url" href="https://hugocisneros.com/notes/greydanusscalingdeeplearning2020/"><time itemprop="datePublished" class="dt-published" datetime="2021-03-25T09:58:00+0100">25/03/2021</time></a> | authored by <a href="https://hugocisneros.com/" rel="author" class="p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Hugo Cisneros</span></a>
          </div>
        </div>
      </article>
      <h3>Comments</h3>
      <script data-isso="//comment.hugocisneros.com/" data-isso-require-author="true" data-isso-vote="true" src="//comment.hugocisneros.com/js/embed.min.js"></script>
      <section id="isso-thread"></section><br>
      <a href="/notes#greydanusscalingdeeplearning2020"><b>← Back to Notes</b></a>
      <hr>
    </main>
    <footer class="footer">
      <ul class="footer-links">
        <li>
          <a class="rss-link" href="/blog/index.xml" type="application/rss+xml" target="_blank">Blog <img class="rss-icon" src="/img/RSS.svg" alt="RSS feed icon"></a>
        </li>
        <li>
          <a href="https://github.com/hugcis/natrium-custom">Code</a>
        </li>
        <li>© Hugo Cisneros 2022</li>
      </ul>
    </footer>
  </div>
  <link rel="stylesheet" href="/js/katex/katex.min.css">
  <script src="/js/katex/katex.min.js"></script> 
  <script src="/js/katex/contrib/auto-render.min.js"></script> 
  <script>

    document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        delimiters: [
            {left: "\\[", right: "\\]", display: true},
            {left: "$$", right: "$$", display: true},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "$", right: "$", display: false},
            {left: "\\(", right: "\\)", display: false},
        ]
  })
    });
  </script>
</body>
</html>
