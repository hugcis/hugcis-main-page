<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1">
  <title>Reinforcement learning - Hugo Cisneros - Personal page</title>
  <meta property="og:title" content="Reinforcement learning - Hugo Cisneros - Personal page">
  <meta property="og:type" content="article">
  <meta property="og:image" content="/img/main.jpeg">
  <meta property="og:url" content="https://hugocisneros.com/notes/reinforcement_learning/">
  <meta property="og:description" content="Notes about Reinforcement learning">
  <meta name="Description" property="description" content="Notes about Reinforcement learning">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@cisne_hug">
  <meta name="twitter:creator" content="@cisne_hug">
  <link rel="stylesheet" href="https://hugocisneros.com/css/main.min.eade29d17a79794f2a5f343f06dc6de3418db15c7eaf7b7d0250936a1e792b8d.css" media="all" type="text/css">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="theme-color" content="#ffffff">
  <link rel="webmention" href="https://webmention.io/hugocisneros.com/webmention">
  <link rel="pingback" href="https://webmention.io/hugocisneros.com/xmlrpc">
</head>
<body>
  <div class="wrapper">
    <header class="header">
      <nav class="nav">
        <div class="nav-main">
          <a href="https://hugocisneros.com/" class="nav-title">Hugo Cisneros - Personal page</a>
        </div>
        <ul class="nav-links">
          <li>
            <a href="/about/">About</a>
          </li>
          <li>
            <a href="/blog/">Blog</a>
          </li>
          <li>
            <a href="/notes/">Notes</a>
          </li>
          <li>
            <a href="/resume/">Resume</a>
          </li>
        </ul>
      </nav>
    </header>
    <main class="content" role="main">
      <article class="article h-entry" itemprop="mainEntity" itemscope itemtype="http://schema.org/BlogPosting">
        <div class="single-note note-container">
          <h1 class="article-title p-name" itemprop="name">Reinforcement learning</h1>
          <div class="article-content e-content p-name" itemprop="articleBody">
            <dl>
              <dt>tags</dt>
              <dd>
                <a href="/notes/machine_learning/">Machine learning</a>
              </dd>
            </dl>
            <p>In reinforcement learning, agents take actions within an environment. Usually, both the agent and environment states change in reaction to this action. A reward is given to the agent to tell it if the action was positive or negative.</p>
            <p>The goal of a learning agent is to act so as to maximize that reward.</p>
            <p>An agent can be anything from a fixed set of <code>if-else</code> statements to a deep <a href="/notes/neural_networks/">neural network</a>.</p>
          </div>
          <div class="bl-section">
            <h2>Links to this note</h2>
            <div class="backlinks">
              <ul>
                <li>
                  <a href="/notes/adversarial_examples/">Adversarial examples</a>
                </li>
                <li>
                  <a href="/notes/map_elites/">MAP-Elites</a>
                </li>
                <li>
                  <a href="/notes/neural_architecture_search/">Neural architecture search</a>
                </li>
                <li>
                  <a href="/notes/tutumadaptingunseenenvironments2020/">Notes on: Adapting to Unseen Environments through Explicit Representation of Context by Tutum, C., & Miikkulainen, R. (2020)</a>
                </li>
                <li>
                  <a href="/notes/pathakcuriositydrivenexplorationselfsupervised2017/">Notes on: Curiosity-Driven Exploration by Self-Supervised Prediction by Pathak, D., Agrawal, P., Efros, A. A., & Darrell, T. (2017)</a>
                </li>
                <li>
                  <a href="/notes/khalifapcgrlproceduralcontent2020/">Notes on: PCGRL: Procedural Content Generation via Reinforcement Learning by Khalifa, A., Bontrager, P., Earle, S., & Togelius, J. (2020)</a>
                </li>
                <li>
                  <a href="/notes/wangpoetopenendedcoevolution2019/">Notes on: POET: open-ended coevolution of environments and their optimized solutions by Wang, R., Lehman, J., Clune, J., & Stanley, K. O. (2019)</a>
                </li>
                <li>
                  <a href="/notes/horiberegeneratingsoftrobots2021/">Notes on: Regenerating Soft Robots through Neural Cellular Automata by Horibe, K., Walker, K., & Risi, S. (2021)</a>
                </li>
                <li>
                  <a href="/notes/grbicsafereinforcementlearning2020/">Notes on: Safe Reinforcement Learning through Meta-learned Instincts by Grbic, D., & Risi, S. (2020)</a>
                </li>
                <li>
                  <a href="/notes/quality_diversity/">Quality diversity</a>
                </li>
              </ul>
            </div>
          </div>
          <div class="note-footer">
            Last changed <a class="u-url" href="https://hugocisneros.com/notes/reinforcement_learning/"><time itemprop="datePublished" class="dt-published" datetime="2021-03-25T09:58:00+0100">25/03/2021</time></a> | authored by <a href="https://hugocisneros.com/" rel="author" class="p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Hugo Cisneros</span></a>
          </div>
        </div>
      </article><br>
      <a href="/notes#reinforcement_learning"><b>← Back to Notes</b></a>
      <hr>
    </main>
    <footer class="footer">
      <ul class="footer-links">
        <li>
          <a class="rss-link" href="/blog/index.xml" type="application/rss+xml" target="_blank">Blog <img class="rss-icon" src="/img/RSS.svg" alt="RSS feed icon"></a>
        </li>
        <li>
          <a href="https://github.com/hugcis/natrium-custom">Code</a>
        </li>
        <li>© Hugo Cisneros 2021</li>
      </ul>
    </footer>
  </div>
  <script>
  MathJax = {
     tex: {
         inlineMath: [['$','$'], ['\\(', '\\)']],
         tags: 'ams'
     }
  };
  </script> 
  <script type="text/javascript" rel="preconnect" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
