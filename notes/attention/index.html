<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1">
  <title>Attention - Hugo Cisneros - Personal page</title>
  <meta property="og:title" content="Attention - Hugo Cisneros - Personal page">
  <meta property="og:type" content="article">
  <meta property="og:image" content="/img/main.jpeg">
  <meta property="og:url" content="https://hugocisneros.com/notes/attention/">
  <meta property="og:description" content="Notes about Attention">
  <meta name="Description" property="description" content="Notes about Attention">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@cisne_hug">
  <meta name="twitter:creator" content="@cisne_hug">
  <link rel="stylesheet" href="https://hugocisneros.com/css/main.min.css" media="all" type="text/css">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="theme-color" content="#ffffff">
  <link rel="webmention" href="https://webmention.io/hugocisneros.com/webmention">
  <link rel="pingback" href="https://webmention.io/hugocisneros.com/xmlrpc">
</head>
<body>
  <div class="wrapper">
    <header class="header">
      <nav class="nav">
        <div class="nav-main">
          <a href="https://hugocisneros.com/" class="nav-title">Hugo Cisneros - Personal page</a>
        </div>
        <ul class="nav-links">
          <li>
            <a href="/about/">About</a>
          </li>
          <li>
            <a href="/blog/">Blog</a>
          </li>
          <li>
            <a href="/notes/">Notes</a>
          </li>
          <li>
            <a href="/resume/">Resume</a>
          </li>
        </ul>
      </nav>
    </header>
    <main class="content" role="main">
      <article class="article h-entry" itemprop="mainEntity" itemscope itemtype="http://schema.org/BlogPosting">
        <div class="single-note note-container">
          <h1 class="article-title p-name" itemprop="name">Attention</h1>
          <div class="article-content e-content p-name" itemprop="articleBody">
            <dl>
              <dt>tags</dt>
              <dd>
                <a href="/notes/neural_networks/">Neural networks</a>
              </dd>
            </dl>
            <h2 id="implementation">Implementation</h2>
            <p>Self-attention is a weighted average of all input elements from a sequence, with a weight proportional to a similarity score between representations. The input \(x \in \mathbb{R}^{L \times F}\) is projected by matrices \(W_Q \in \mathbb{R}^{F \times D}\), \(W_K \in \mathbb{R}^{F\times D}\) and \(W_V \in \mathbb{R}^{F\times M}\) to representations \(Q\) (<em>queries</em>), \(K\) (<em>keys</em>) and \(V\) (<em>values</em>).</p>
            <p>\[ Q = xW_Q\] \[ K = xW_K\] \[ V = xW_V\]</p>
            <p>Output for all positions in a sequence \(x\), is written</p>
            <p>\[A(x) = V' = \text{softmax}\left( \dfrac{QK^{T}}{\sqrt{D}} \right) V.\]</p>
            <p>The softmax is applied row-wise in the equation above.</p>
            <h2 id="possible-interpretation">Possible interpretation</h2>
            <p>Keys and queries have a relatively simple interpretation. The keys are embeddings of tokens that expose some useful information about them:</p>
            <p>The key \(K_3\) associated with <code>cat</code> should probably encode some information about the fact that it’s a noun, that it refers to a living entity, an animal, etc. On the other hand, the key \(K_2\) encodes the fact that <code>pretty</code> is an adjective, and is used to denote some positive things about the subject’s appearance. That key is probably close to keys for <code>beautiful</code> and <code>nice</code>.</p>
            <figure>
              <img src="/ox-hugo/contour.png">
            </figure>
            <p>The query encodes another type of information about what types of keys would be useful for that particular token. In the case of query \(Q_3\) it is probably useful to attend to any adjective-like key that could show something interesting about the current word. Therefore, the quantity \(\text{softmax}\left( \dfrac{QK^{T}}{\sqrt{D}} \right)\) will be larger and will contribute more heavily in the resulting vector \(V'\). This is illustrated in the graph above with heavier edges.</p>
            <h2 id="is-it-necessary">Is it necessary?</h2>
            <p>Maybe not (<a href="#orgbbe52c1">Zhai et al. 2021</a>).</p>
            <h2 id="bibliography">Bibliography</h2>
            <p><a id="orgbbe52c1"></a><span itemprop="citation" itemscope itemtype="https://schema.org/ScholarlyArticle"><span itemprop="author"><span itemprop="author">Zhai, Shuangfei</span>, <span itemprop="author">Walter Talbott</span>, <span itemprop="author">Nitish Srivastava</span>, <span itemprop="author">Chen Huang</span>, <span itemprop="author">Hanlin Goh</span>, <span itemprop="author">Ruixiang Zhang</span>, and <span itemprop="author">Josh Susskind</span></span>. <span datetime="2021" itemprop="datePublished">May 2021</span>. “<span itemprop="name">An Attention Free Transformer</span>”. <span itemprop="isPartOf" itemscope itemtype="https://schema.org/Periodical"><i itemprop="name">arXiv:2105.14103 [Cs]</i></span>, May.</span></p>
          </div>
          <div class="bl-section">
            <h2>Links to this note</h2>
            <div class="backlinks">
              <ul>
                <li>
                  <a href="/notes/attention/">Attention</a>
                </li>
                <li>
                  <a href="/notes/attention_graph_networks/">Attention graph networks</a>
                </li>
                <li>
                  <a href="/notes/graph_neural_networks/">Graph neural networks</a>
                </li>
                <li>
                  <a href="/notes/hopfield_networks/">Hopfield Networks</a>
                </li>
                <li>
                  <a href="/notes/cluneaigasaigeneratingalgorithms2019/">Notes on: AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence by Clune, J. (2019)</a>
                </li>
                <li>
                  <a href="/notes/ramsauerhopfieldnetworksall2020/">Notes on: Hopfield Networks is All You Need by Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Gruber, L., Holzleitner, M., … (2020)</a>
                </li>
                <li>
                  <a href="/notes/xiongnystromformernystr2021/">Notes on: Nyströmformer: A Nyström-Based Algorithm for Approximating Self-Attention by Xiong, Y., Zeng, Z., Chakraborty, R., Tan, M., Fung, G., Li, Y., & Singh, V. (2021)</a>
                </li>
                <li>
                  <a href="/notes/katharopoulostransformersarernns2020/">Notes on: Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention by Katharopoulos, A., Vyas, A., Pappas, N., & Fleuret, F. (2020)</a>
                </li>
                <li>
                  <a href="/notes/schmidhuber_on_consciousness/">Schmidhuber on Consciousness</a>
                </li>
                <li>
                  <a href="/notes/transformers/">Transformers</a>
                </li>
              </ul>
            </div>
          </div>
          <div class="note-footer">
            Last changed <a class="u-url" href="https://hugocisneros.com/notes/attention/"><time itemprop="datePublished" class="dt-published" datetime="2021-06-14T10:29:00+0200">14/06/2021</time></a> | authored by <a href="https://hugocisneros.com/" rel="author" class="p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Hugo Cisneros</span></a>
          </div>
        </div>
      </article><br>
      <a href="/notes#attention"><b>← Back to Notes</b></a>
      <hr>
    </main>
    <footer class="footer">
      <ul class="footer-links">
        <li>
          <a class="rss-link" href="/blog/index.xml" type="application/rss+xml" target="_blank">Blog <img class="rss-icon" src="/img/RSS.svg" alt="RSS feed icon"></a>
        </li>
        <li>
          <a href="https://github.com/hugcis/natrium-custom">Code</a>
        </li>
        <li>© Hugo Cisneros 2021</li>
      </ul>
    </footer>
  </div>
  <link rel="stylesheet" href="/js/katex/katex.min.css">
  <script src="/js/katex/katex.min.js"></script> 
  <script src="/js/katex/contrib/auto-render.min.js"></script> 
  <script>

    document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        delimiters: [
            {left: "\\[", right: "\\]", display: true},
            {left: "$", right: "$", display: false},
            {left: "\\(", right: "\\)", display: false},
        ]
  })
    });
  </script>
</body>
</html>
