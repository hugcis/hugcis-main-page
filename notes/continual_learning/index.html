<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1">
  <title>Continual learning - Hugo Cisneros</title>
  <meta property="og:title" content="Continual learning - Hugo Cisneros">
  <meta property="og:type" content="article">
  <meta property="og:image" content="/img/main.jpeg">
  <meta property="og:url" content="https://hugocisneros.com/notes/continual_learning/">
  <meta property="og:description" content="Notes about Continual learning">
  <meta name="Description" property="description" content="Notes about Continual learning">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@cisne_hug">
  <meta name="twitter:creator" content="@cisne_hug">
  <link rel="stylesheet" href="https://hugocisneros.com/css/main.min.css" media="all" type="text/css">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="theme-color" content="#ffffff">
  <link rel="webmention" href="https://webmention.io/hugocisneros.com/webmention">
  <link rel="pingback" href="https://webmention.io/hugocisneros.com/xmlrpc">
</head>
<body>
  <div class="wrapper">
    <header class="header">
      <nav class="nav">
        <div class="nav-main">
          <a href="https://hugocisneros.com/" class="nav-title">Hugo Cisneros</a>
        </div>
        <ul class="nav-links">
          <li>
            <a href="/blog/">Blog</a>
          </li>
          <li>
            <a href="/notes/">Notes</a>
          </li>
          <li>
            <a href="/projects/">Projects</a>
          </li>
          <li>
            <a href="/resume/">Resume</a>
          </li>
          <li>
            <a href="/contact/">Contact</a>
          </li>
        </ul>
      </nav>
    </header>
    <main class="content" role="main">
      <article class="article h-entry" itemprop="mainEntity" itemscope itemtype="http://schema.org/BlogPosting">
        <div class="single-note note-container">
          <h1 class="article-title p-name" itemprop="name">Continual learning</h1>
          <div class="article-content e-content p-name" itemprop="articleBody">
            <dl>
              <dt>tags</dt>
              <dd>
                <a href="/notes/machine_learning/">Machine learning</a>
              </dd>
            </dl>
            <p>Continual learning is a type of <a href="/notes/supervised_learning/">supervised learning</a> where there is no “testing phase” associated to a decision process. Instead, training samples keep being processed by the <a href="/notes/algorithm/">algorithm</a> which has to simultaneously make predictions and keep learning.</p>
            <p>This is challenging for a fixed neural network architecture since it has a fixed capacity and is bound to either forget things or be unable to learn anything new.</p>
            <p>A definition from the survey (<a href="#org0664eb0">De Lange et al. 2020</a>):</p>
            <blockquote>
              <p>The General Continual Learning setting considers an infinite stream of training data where at each time step, the system receives a (number of) new sample(s) drawn non i.i.d from a current distribution that could itself experience sudden of gradual changes.</p>
            </blockquote>
            <h2 id="examples-of-continual-learning-systems">Examples of continual learning systems</h2>
            <ul>
              <li>Never Ending Language Learner (NELL) (<a href="#org77257e3">Carlson, Betteridge, and Kisiel 2010</a>)
              </li>
            </ul>
            <h2 id="benchmarks">Benchmarks</h2>
            <h3 id="computer-vision-based-benchmarks">Computer vision based benchmarks</h3>
            <ul>
              <li>
                <p>Split MNIST: the MNIST dataset is split into 5 2-classes tasks.</p>
              </li>
              <li>
                <p>Split CIFAR10: the CIFAR10 dataset is split into 5 2-classes tasks.</p>
              </li>
              <li>
                <p>Split mini-ImageNet: a mini ImageNet (100 classes) task split into 20 5-classes tasks.</p>
              </li>
              <li>
                <p>Continual Transfer Learning Benchmark: <a href="https://github.com/facebookresearch/CTrLBenchmark">A benchmark from Facebook AI</a>, built from 7 computer vision datasets: MNIST, CIFAR10, CIFAR100, DTD, SVHN, Rainbow-MNIST, Fashion MNIST. The tasks are all 5-classes or 10-classes classification tasks. Some example task sequence constructions from (<a href="#orgbe9f18e">Veniat, Denoyer, and Ranzato 2021</a>):</p>
                <blockquote>
                  <p>The last task of \(S_out\) consists of a shuffling of the output labels of the first task. The last task of \(S_in\) is the same as its first task except that MNIST images have a different background color. \(S_long\) has 100 tasks, and it is constructed by first sampling a dataset, then 5 classes at random, and finally the amount of training data from a distribution that favors small tasks by the end of the learning experience.</p>
                </blockquote>
              </li>
              <li>
                <p>Permuted MNIST: here for each different task the pixels of the MNIST digits are permuted, generating a new task of equal difficulty as the original one but different solution. This task is not suitable if the model has some spatial prior (like a <a href="/notes/convolutional_neural_networks/">CNN</a>). Used first in (<a href="#org3ba778f">Kirkpatrick et al. 2017</a>).</p>
              </li>
              <li>
                <p>Rotated MNIST: each task contains digits rotated by a fixed angle between 0 and 180 degrees.</p>
              </li>
            </ul>
            <h2 id="bibliography">Bibliography</h2>
            <ol class="biblio-list">
              <a id="org77257e3"></a>
              <li itemprop="citation" itemscope itemtype="https://schema.org/ScholarlyArticle">
                <span itemprop="author"><span itemprop="author">Carlson, Andrew</span>, <span itemprop="author">Justin Betteridge</span>, and <span itemprop="author">Bryan Kisiel</span></span>. <span datetime="2010" itemprop="datePublished">2010</span>. "<span itemprop="name">Toward an Architecture for Never-Ending Language Learning.</span>". <span itemprop="isPartOf" itemscope itemtype="https://schema.org/Periodical"><i itemprop="name">In Proceedings of the Conference on Artificial Intelligence (AAAI) (2010)</i></span>, 1306–13. <a itemprop="sameAs" href="https://doi.org/10.1002/ajp.20927">DOI</a>.
                <p><a id="org0664eb0"></a></p>
              </li>
              <li itemprop="citation" itemscope itemtype="https://schema.org/ScholarlyArticle">
                <span itemprop="author"><span itemprop="author">De Lange, Matthias</span>, <span itemprop="author">Rahaf Aljundi</span>, <span itemprop="author">Marc Masana</span>, <span itemprop="author">Sarah Parisot</span>, <span itemprop="author">Xu Jia</span>, <span itemprop="author">Ales Leonardis</span>, <span itemprop="author">Gregory Slabaugh</span>, and <span itemprop="author">Tinne Tuytelaars</span></span>. <span datetime="2020" itemprop="datePublished">May 26, 2020</span>. “<span itemprop="name">A Continual Learning Survey: Defying Forgetting in Classification Tasks</span>”. <span itemprop="isPartOf" itemscope itemtype="https://schema.org/Periodical"><i itemprop="name">arXiv:1909.08383 [Cs, Stat]</i></span>. <a itemprop="sameAs" href="http://arxiv.org/abs/1909.08383"></a><a href="http://arxiv.org/abs/1909.08383">http://arxiv.org/abs/1909.08383</a>.
                <p><a id="org3ba778f"></a></p>
              </li>
              <li itemprop="citation" itemscope itemtype="https://schema.org/ScholarlyArticle">
                <span itemprop="author"><span itemprop="author">Kirkpatrick, James</span>, <span itemprop="author">Razvan Pascanu</span>, <span itemprop="author">Neil Rabinowitz</span>, <span itemprop="author">Joel Veness</span>, <span itemprop="author">Guillaume Desjardins</span>, <span itemprop="author">Andrei A. Rusu</span>, <span itemprop="author">Kieran Milan</span>, et al.</span>. <span datetime="2017" itemprop="datePublished">January 25, 2017</span>. “<span itemprop="name">Overcoming Catastrophic Forgetting in Neural Networks</span>”. <span itemprop="isPartOf" itemscope itemtype="https://schema.org/Periodical"><i itemprop="name">arXiv:1612.00796 [Cs, Stat]</i></span>. <a itemprop="sameAs" href="http://arxiv.org/abs/1612.00796"></a><a href="http://arxiv.org/abs/1612.00796">http://arxiv.org/abs/1612.00796</a>.
                <p><a id="orgbe9f18e"></a></p>
              </li>
              <li itemprop="citation" itemscope itemtype="https://schema.org/ScholarlyArticle">
                <span itemprop="author"><span itemprop="author">Veniat, Tom</span>, <span itemprop="author">Ludovic Denoyer</span>, and <span itemprop="author">Marc’Aurelio Ranzato</span></span>. <span datetime="2021" itemprop="datePublished">February 12, 2021</span>. “<span itemprop="name">Efficient Continual Learning with Modular Networks and Task-Driven Priors</span>”. <span itemprop="isPartOf" itemscope itemtype="https://schema.org/Periodical"><i itemprop="name">arXiv:2012.12631 [Cs]</i></span>. <a itemprop="sameAs" href="http://arxiv.org/abs/2012.12631"></a><a href="http://arxiv.org/abs/2012.12631">http://arxiv.org/abs/2012.12631</a>.
              </li>
            </ol>
          </div>
          <div class="bl-section">
            <h2>Links to this note</h2>
            <div class="backlinks">
              <ul>
                <li>
                  <a href="/notes/hudrinkingfirehosecontinual2020/">Notes on: Drinking from a Firehose: Continual Learning with Web-scale Natural Language by Hu, H., Sener, O., Sha, F., & Koltun, V. (2020)</a>
                </li>
              </ul>
            </div>
          </div>
          <div class="note-footer">
            Last changed <a class="u-url" href="https://hugocisneros.com/notes/continual_learning/"><time itemprop="datePublished" class="dt-published" datetime="2021-10-15T15:18:00+0200">15/10/2021</time></a> | authored by <a href="https://hugocisneros.com/" rel="author" class="p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Hugo Cisneros</span></a>
          </div>
        </div>
      </article><br>
      <a href="/notes#continual_learning"><b>← Back to Notes</b></a>
      <hr>
    </main>
    <footer class="footer">
      <ul class="footer-links">
        <li>
          <a class="rss-link" href="/blog/index.xml" type="application/rss+xml" target="_blank">Blog <img class="rss-icon" src="/img/RSS.svg" alt="RSS feed icon"></a>
        </li>
        <li>
          <a href="https://github.com/hugcis/natrium-custom">Code</a>
        </li>
        <li>© Hugo Cisneros 2021</li>
      </ul>
    </footer>
  </div>
  <link rel="stylesheet" href="/js/katex/katex.min.css">
  <script src="/js/katex/katex.min.js"></script> 
  <script src="/js/katex/contrib/auto-render.min.js"></script> 
  <script>

    document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        delimiters: [
            {left: "\\[", right: "\\]", display: true},
            {left: "$$", right: "$$", display: true},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "$", right: "$", display: false},
            {left: "\\(", right: "\\)", display: false},
        ]
  })
    });
  </script>
</body>
</html>
