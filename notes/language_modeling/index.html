<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
  <title>Language modeling - Hugo Cisneros</title>
  <meta property="og:title" content="Language modeling - Hugo Cisneros">
  <meta property="og:type" content="article">
  <meta property="og:image" content="/img/main.jpeg">
  <meta property="og:url" content="https://hugocisneros.com/notes/language_modeling/">
  <meta property="og:description" content="Notes about Language modeling">
  <meta name="Description" property="description" content="Notes about Language modeling">
  <link rel="me" href="https://twitter.com/@cisne_hug">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@cisne_hug">
  <meta name="twitter:creator" content="@cisne_hug">
  <link rel="me" href="https://github.com/hugcis/">
  <meta property="keywords" content="nlp">
  <link rel="stylesheet" href="https://hugocisneros.com/main.min.css" media="all" type="text/css">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="theme-color" content="#ffffff">
  <link rel="webmention" href="https://webmention.io/hugocisneros.com/webmention">
  <link rel="pingback" href="https://webmention.io/hugocisneros.com/xmlrpc">
</head>
<body>
  <div class="wrapper">
    <header class="header">
      <nav class="nav">
        <div class="nav-main">
          <a href="https://hugocisneros.com/" class="nav-title">Hugo Cisneros</a>
        </div>
        <ul class="nav-links">
          <li>
            <a href="/blog/">Blog</a>
          </li>
          <li>
            <a href="/notes/">Notes</a>
          </li>
          <li>
            <a href="/projects/">Projects</a>
          </li>
          <li>
            <a href="/resume/">Resume</a>
          </li>
          <li>
            <a href="/contact/">Contact</a>
          </li>
        </ul>
      </nav>
    </header>
    <main class="content" role="main">
      <article class="article h-entry" itemprop="mainEntity" itemscope itemtype="http://schema.org/BlogPosting">
        <div class="single-note note-container">
          <h1 class="article-title p-name" itemprop="name">Language modeling</h1>
          <div class="article-content e-content p-name" itemprop="articleBody">
            <dl>
              <dt>tags</dt>
              <dd>
                <a href="/notes/nlp/">NLP</a>
              </dd>
            </dl>
            <h2 id="lm-with-rnn--recurrent-neural-networks-dot-md--s">LM with <a href="/notes/recurrent_neural_networks/">RNN</a>s</h2>
            <p>Different models have been studied, starting from the initial <a href="/notes/recurrent_neural_networks/">Recurrent neural network</a> based language model (<a href="#mikolovRecurrentNeuralNetwork2011"><cite itemprop="citation" itemscope itemid="key:mikolovRecurrentNeuralNetwork2011">Mikolov et al. 2011</cite></a>).</p>
            <p>LSTM were then used with more success than previous models (<a href="#zarembaRecurrentNeuralNetwork2015"><cite itemprop="citation" itemscope itemid="key:zarembaRecurrentNeuralNetwork2015">Zaremba, Sutskeverand Vinyals 2015</cite></a>).</p>
            <p>Recently, <a href="#lm-with-transformers--relref-transformers-dot-md">transformers seem to have dominated language modeling</a>. However it is not clear if this is due to their real superiority over RNNs or their practical scalability (<a href="#meritySingleHeadedAttention2019"><cite itemprop="citation" itemscope itemid="key:meritySingleHeadedAttention2019">Merity 2019</cite></a>).</p>
            <h2 id="lm-with-transformers--transformers-dot-md">LM with <a href="/notes/transformers/">Transformers</a></h2>
            <h2 id="language-modeling-and-compression--compression-dot-md">Language modeling and <a href="/notes/compression/">Compression</a></h2>
            <h2 id="text-generation">Text generation</h2>
            <p>Language models can be used to generate text from a prompt or starting sentence. This is the kind of examples that made models like GPT-2 and GPT-3 famous, because of their ability to generate long sequences of apparently coherent text (<a href="#radfordLanguageModelsAre2019"><cite itemprop="citation" itemscope itemid="key:radfordLanguageModelsAre2019">Radford et al. 2019</cite></a>; <a href="#brownLanguageModelsAre2020"><cite itemprop="citation" itemscope itemid="key:brownLanguageModelsAre2020">Brown et al. 2020</cite></a>).</p>
            <h2 id="other-applications">Other applications</h2>
            <h3 id="language-modeling-for-automated-theorem-proving--automated-theorem-proving-dot-md">Language modeling for <a href="/notes/automated_theorem_proving/">Automated theorem proving</a></h3>
            <p>(<a href="#poluGenerativeLanguageModeling2020"><cite itemprop="citation" itemscope itemid="key:poluGenerativeLanguageModeling2020">Polu and Sutskever 2020</cite></a>)</p>
            <h3 id="language-modeling-for-reinforcement-learning--reinforcement-learning-dot-md">Language modeling for <a href="/notes/reinforcement_learning/">Reinforcement Learning</a></h3>
            <p>(<a href="#jannerReinforcementLearningOne">&lt;cite itemprop=“citation” itemscope=““Janner, Liand Levine,n.d.</a>)</p>
            <h2 id="bibliography">Bibliography</h2>
            <ol class="biblio-list">
              <li itemprop="citation" itemscope itemtype="https://schema.org/ScholarlyArticle" id="mikolovRecurrentNeuralNetwork2011"><span itemprop="author">Mikolov, Tomas, Martin Karafiat, Lukas Burget, Jan Cernockyand Sanjeev Khudanpur</span>. <time datetime="2011" itemprop="datePublished">2011</time>. "<span itemprop="name">Recurrent Neural Network Based Language Model</span>". In , 4.</li>
              <li itemprop="citation" itemscope itemtype="https://schema.org/ScholarlyArticle" id="zarembaRecurrentNeuralNetwork2015">
                <span itemprop="author">Zaremba, Wojciech, Ilya Sutskeverand Oriol Vinyals</span>. <time datetime="2015" itemprop="datePublished">February 19, 2015</time>. "<span itemprop="name">Recurrent Neural Network Regularization</span>". <span itemprop="isPartOf" itemscope itemtype="https://schema.org/Periodical"><i itemprop="name">Arxiv:1409.2329 [cs]</i></span>. <a itemprop="sameAs" href="http://arxiv.org/abs/1409.2329">http://arxiv.org/abs/1409.2329</a>.
              </li>
              <li itemprop="citation" itemscope itemtype="https://schema.org/ScholarlyArticle" id="meritySingleHeadedAttention2019">
                <span itemprop="author">Merity, Stephen</span>. <time datetime="2019" itemprop="datePublished">November 26, 2019</time>. "<span itemprop="name">Single Headed Attention RNN: Stop Thinking with Your Head</span>". <span itemprop="isPartOf" itemscope itemtype="https://schema.org/Periodical"><i itemprop="name">Arxiv:1911.11423 [cs]</i></span>. <a itemprop="sameAs" href="http://arxiv.org/abs/1911.11423">http://arxiv.org/abs/1911.11423</a>.
              </li>
              <li itemprop="citation" itemscope itemtype="https://schema.org/ScholarlyArticle" id="radfordLanguageModelsAre2019"><span itemprop="author">Radford, Alec, Jeffrey Wu, Rewon Child, David Luan, Dario Amodeiand Ilya Sutskever</span>. <time datetime="2019" itemprop="datePublished">2019</time>. "<span itemprop="name">Language Models Are Unsupervised Multitask Learners</span>". <span itemprop="isPartOf" itemscope itemtype="https://schema.org/Periodical"><i itemprop="name">Openai Blog</i></span> 1 (8):9.</li>
              <li itemprop="citation" itemscope itemtype="https://schema.org/ScholarlyArticle" id="brownLanguageModelsAre2020">
                <span itemprop="author">Brown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al.</span>. <time datetime="2020" itemprop="datePublished">June 4, 2020</time>. "<span itemprop="name">Language Models Are Few-shot Learners</span>". <span itemprop="isPartOf" itemscope itemtype="https://schema.org/Periodical"><i itemprop="name">Arxiv:2005.14165 [cs]</i></span>. <a itemprop="sameAs" href="http://arxiv.org/abs/2005.14165">http://arxiv.org/abs/2005.14165</a>.
              </li>
              <li itemprop="citation" itemscope itemtype="https://schema.org/ScholarlyArticle" id="poluGenerativeLanguageModeling2020">
                <span itemprop="author">Polu, Stanislasand Ilya Sutskever</span>. <time datetime="2020" itemprop="datePublished">September 7, 2020</time>. "<span itemprop="name">Generative Language Modeling for Automated Theorem Proving</span>". <span itemprop="isPartOf" itemscope itemtype="https://schema.org/Periodical"><i itemprop="name">Arxiv:2009.03393 [cs, Stat]</i></span>. <a itemprop="sameAs" href="http://arxiv.org/abs/2009.03393">http://arxiv.org/abs/2009.03393</a>.
              </li>
              <li itemprop="citation" itemscope itemtype="https://schema.org/ScholarlyArticle" id="jannerReinforcementLearningOne"><span itemprop="author">Janner, Michael, Qiyang Liand Sergey Levine</span>. n.d.. "<span itemprop="name">Reinforcement Learning as One Big Sequence Modeling Problem</span>", 15.</li>
            </ol>
          </div>
          <div class="bl-section">
            <h2>Links to this note</h2>
            <div class="backlinks">
              <ul>
                <li>
                  <a href="/notes/compression/">Compression</a>
                </li>
                <li>
                  <a href="/notes/nlp/">NLP</a>
                </li>
                <li>
                  <a href="/notes/benderclimbingnlumeaning2020/">Notes on: Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data by Bender, E. M., & Koller, A. (2020)</a>
                </li>
                <li>
                  <a href="/notes/hudrinkingfirehosecontinual2020/">Notes on: Drinking from a Firehose: Continual Learning with Web-scale Natural Language by Hu, H., Sener, O., Sha, F., & Koltun, V. (2020)</a>
                </li>
                <li>
                  <a href="/notes/zophneuralarchitecturesearch2017/">Notes on: Neural Architecture Search with Reinforcement Learning by Zoph, B., & Le, Q. V. (2017)</a>
                </li>
                <li>
                  <a href="/notes/lupretrainedtransformersuniversal2021/">Notes on: Pretrained Transformers as Universal Computation Engines by Lu, K., Grover, A., Abbeel, P., & Mordatch, I. (2021)</a>
                </li>
                <li>
                  <a href="/notes/aitkengeometryintegrationtext2020/">Notes on: The geometry of integration in text classification RNNs by Aitken, K., Ramasesh, V. V., Garg, A., Cao, Y., Sussillo, D., & Maheswaranathan, N. (2020)</a>
                </li>
                <li>
                  <a href="/notes/katharopoulostransformersarernns2020/">Notes on: Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention by Katharopoulos, A., Vyas, A., Pappas, N., & Fleuret, F. (2020)</a>
                </li>
                <li>
                  <a href="/notes/self_supervised_learning/">Self-supervised learning</a>
                </li>
                <li>
                  <a href="/notes/word_vectors/">Word vectors</a>
                </li>
              </ul>
            </div>
          </div>
          <div class="note-footer">
            Last changed <a class="u-url" href="https://hugocisneros.com/notes/language_modeling/"><time itemprop="datePublished" class="dt-published" datetime="2021-08-29T21:45:00+0200">29/08/2021</time></a> | authored by <a href="https://hugocisneros.com/" rel="author" class="p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Hugo Cisneros</span></a>
          </div>
        </div>
      </article>
      <h3>Comments</h3>
      <script data-isso="//comment.hugocisneros.com/" data-isso-require-author="true" data-isso-vote="true" src="//comment.hugocisneros.com/js/embed.min.js"></script>
      <section id="isso-thread"></section><br>
      <a href="/notes#language_modeling"><b>← Back to Notes</b></a>
      <hr>
    </main>
    <footer class="footer">
      <ul class="footer-links">
        <li>
          <a class="rss-link" href="/blog/index.xml" type="application/rss+xml" target="_blank">Blog <img class="rss-icon" src="/img/RSS.svg" alt="RSS feed icon"></a>
        </li>
        <li>
          <a href="https://github.com/hugcis/hugo-astatine-theme">Code</a>
        </li>
        <li>© Hugo Cisneros 2022</li>
      </ul>
    </footer>
  </div>
  <link rel="stylesheet" href="/js/katex/katex.min.css">
  <script src="/js/katex/katex.min.js"></script> 
  <script src="/js/katex/contrib/auto-render.min.js"></script> 
  <script>
  document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"\\begin{equation}",right:"\\end{equation}",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})})
  </script>
</body>
</html>
