<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
  <title>Neural network training - Hugo Cisneros</title>
  <meta property="og:title" content="Neural network training - Hugo Cisneros">
  <meta property="og:type" content="article">
  <meta property="og:image" content="/img/main.jpeg">
  <meta property="og:url" content="https://hugocisneros.com/notes/neural_network_training/">
  <meta property="og:description" content="Notes about Neural network training">
  <meta name="Description" property="description" content="Notes about Neural network training">
  <link rel="me" href="https://twitter.com/@cisne_hug">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@cisne_hug">
  <meta name="twitter:creator" content="@cisne_hug">
  <link rel="me" href="https://scholar.social/@hugcis">
  <link rel="me" href="https://github.com/hugcis">
  <meta property="keywords" content="neural networks, machine learning, optimization">
  <link rel="stylesheet" href="https://hugocisneros.com/css/style.css">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="theme-color" content="#ffffff">
  <link rel="webmention" href="https://webmention.io/hugocisneros.com/webmention">
  <link rel="pingback" href="https://webmention.io/hugocisneros.com/xmlrpc">
</head>
<body>
  <div class="wrapper">
    <header class="header mt-2.5">
      <nav class="nav m-auto flex flex-row flex-wrap justify-between container items-center">
        <div class="nav-main my-2.5">
          <a href="https://hugocisneros.com/" class="nav-title py-2.5 text-2xl text-zinc-600 hover:border-b-0">Hugo Cisneros</a>
        </div>
        <ul class="nav-links flex flex-row flex-wrap justify-between text-lg my-2.5">
          <li class="p-2.5 first:pl-0 last:pr-0 list-none">
            <a class="text-zinc-600 hover:border-b-0" href="/blog/">Blog</a>
          </li>
          <li class="p-2.5 first:pl-0 last:pr-0 list-none">
            <a class="text-zinc-600 hover:border-b-0" href="/notes/">Notes</a>
          </li>
          <li class="p-2.5 first:pl-0 last:pr-0 list-none">
            <a class="text-zinc-600 hover:border-b-0" href="/projects/">Projects</a>
          </li>
          <li class="p-2.5 first:pl-0 last:pr-0 list-none">
            <a class="text-zinc-600 hover:border-b-0" href="/resume/">Resume</a>
          </li>
          <li class="p-2.5 first:pl-0 last:pr-0 list-none">
            <a class="text-zinc-600 hover:border-b-0" href="/contact/">Contact</a>
          </li>
        </ul>
      </nav>
    </header>
    <main class="content" role="main">
      <article class="article h-entry" itemprop="mainEntity" itemscope itemtype="http://schema.org/BlogPosting">
        <div class="single-note note-container">
          <h1 class="article-title p-name" itemprop="name">Neural network training</h1>
          <div class="article-content e-content p-name" itemprop="articleBody">
            <dl>
              <dt>tags</dt>
              <dd>
                <a href="/notes/neural_networks/">Neural networks</a>, <a href="/notes/machine_learning/">Machine learning</a>, <a href="/notes/optimization/">Optimization</a>
              </dd>
            </dl>
            <h2 id="neural-network-training-as-development-in-program-space">Neural network training as development in program space</h2>
            <p>A neural network as a whole can be seen as a <a href="/notes/dynamical_systems/">dynamical system</a>. Its state is the collection of its parameters, and its evolution function is the <a href="/notes/optimization/">optimization</a> step taken when training the network.</p>
            <p>A neural network has parameters \(\theta_t\) at time \(t\) which can be seen as its state. In standard <a href="/notes/supervised_learning/">supervised learning</a>, the parameters are updated by the chosen <a href="/notes/optimization/">optimization</a> <a href="/notes/algorithm/">algorithm</a> and a set of training pairs \((\bm{X}_t, \bm{Y}_t)\). This is the update rule changing the state of that dynamical system at each training step.</p>
            <p>In such a framework, the goal of training the neural network is to reach a form of <a href="/notes/attractor/">attractor</a>: further optimization steps don’t change the state (parameters) of the neural network.</p>
            <p>This attractor should correspond to useful functional properties for the network, a measured by a cost function. <a href="/notes/meta_learning/">Meta-learning</a> can be used to learn the evolution function itself to make the dynamical system converge to better attractors in the least amount of steps.</p>
            <h3 id="program-evolution">Program evolution</h3>
            <p>A neural network is a program, an <a href="/notes/algorithm/">algorithm</a>. Its parameters specify a sequence of steps from input data to output prediction. Training a neural network is like moving in the algorithmic space towards programs with better performance according to a given cost function.</p>
          </div>
          <div class="bl-section">
            <h2>Links to this note</h2>
            <div class="backlinks">
              <ul>
                <li>
                  <a href="/notes/double_descent/">Double descent</a>
                </li>
                <li>
                  <a href="/notes/yenetworkdeconvolution2020/">Notes on: Network Deconvolution by Ye, C., Evanusa, M., He, H., Mitrokhin, A., Goldstein, T., Yorke, J. A., Fermuller, Cornelia, … (2020)</a>
                </li>
                <li>
                  <a href="/notes/the_lottery_ticket_hypothesis/">The Lottery ticket hypothesis</a>
                </li>
              </ul>
            </div>
          </div>
          <div class="note-footer">
            Last changed <a class="u-url" href="https://hugocisneros.com/notes/neural_network_training/"><time itemprop="datePublished" class="dt-published" datetime="2022-04-14T20:12:00+0200">14/04/2022</time></a> | authored by <a href="https://hugocisneros.com/" rel="author" class="p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Hugo Cisneros</span></a>
          </div>
        </div>
      </article>
      <h3>Comments</h3>
      <script data-isso="https://comment.hugocisneros.com/" data-isso-require-author="true" data-isso-vote="true" src="https://comment.hugocisneros.com/js/embed.min.js"></script>
      <section id="isso-thread"></section><br>
      <a href="/notes#neural_network_training"><b>← Back to Notes</b></a>
      <hr>
    </main>
    <footer class="footer container h-10 text-center">
      <ul class="footer-links">
        <li class="inline-block list-none">
          <a class="rss-link inline-block" href="/blog/index.xml" type="application/rss+xml" target="_blank">Blog <img class="rss-icon w-4 inline-block" src="/img/RSS.svg" alt="RSS feed icon"></a>
        </li>
        <li class="inline-block">
          <a href="https://github.com/hugcis/hugo-astatine-theme">Code</a>
        </li>
        <li class="inline-block">© Hugo Cisneros 2022</li>
      </ul>
    </footer>
  </div>
  <link rel="stylesheet" href="/js/katex/katex.min.css">
  <script src="/js/katex/katex.min.js"></script> 
  <script src="/js/katex/contrib/auto-render.min.js"></script> 
  <script>
  document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"\\begin{equation}",right:"\\end{equation}",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})})
  </script> 
  <script data-goatcounter="https://stats.hugocisneros.com/count" async src="//stats.hugocisneros.com/count.js"></script>
</body>
</html>
