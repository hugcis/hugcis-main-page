<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1">
  <title>Talk: Differentiation of black-box combinatorial solvers - Hugo Cisneros</title>
  <meta property="og:title" content="Talk: Differentiation of black-box combinatorial solvers - Hugo Cisneros">
  <meta property="og:type" content="article">
  <meta property="og:image" content="/img/main.jpeg">
  <meta property="og:url" content="https://hugocisneros.com/notes/talk_differentiation_of_black_box_combinatorial_solvers/">
  <meta property="og:description" content="Notes about Talk: Differentiation of black-box combinatorial solvers">
  <meta name="Description" property="description" content="Notes about Talk: Differentiation of black-box combinatorial solvers">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@cisne_hug">
  <meta name="twitter:creator" content="@cisne_hug">
  <link rel="stylesheet" href="https://hugocisneros.com/css/main.min.css" media="all" type="text/css">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <meta name="theme-color" content="#ffffff">
  <link rel="webmention" href="https://webmention.io/hugocisneros.com/webmention">
  <link rel="pingback" href="https://webmention.io/hugocisneros.com/xmlrpc">
</head>
<body>
  <div class="wrapper">
    <header class="header">
      <nav class="nav">
        <div class="nav-main">
          <a href="https://hugocisneros.com/" class="nav-title">Hugo Cisneros</a>
        </div>
        <ul class="nav-links">
          <li>
            <a href="/blog/">Blog</a>
          </li>
          <li>
            <a href="/notes/">Notes</a>
          </li>
          <li>
            <a href="/projects/">Projects</a>
          </li>
          <li>
            <a href="/resume/">Resume</a>
          </li>
          <li>
            <a href="/contact/">Contact</a>
          </li>
        </ul>
      </nav>
    </header>
    <main class="content" role="main">
      <article class="article h-entry" itemprop="mainEntity" itemscope itemtype="http://schema.org/BlogPosting">
        <div class="single-note note-container">
          <h1 class="article-title p-name" itemprop="name">Talk: Differentiation of black-box combinatorial solvers</h1>
          <div class="article-content e-content p-name" itemprop="articleBody">
            <dl>
              <dt>presenter</dt>
              <dd>
                <a href="https://scholar.google.com/citations?user=DVdSTFQAAAAJ">Michal Rolinek</a>
              </dd>
              <dt>tags</dt>
              <dd>
                <a href="/notes/combinatorics/">Combinatorics</a>, <a href="/notes/machine_learning/">Machine learning</a>
              </dd>
            </dl>
            <p>The goal is to merge combinatorial optimization and deep learning.</p>
            <p>Make use of strong battle tested optimization methods. Some of those can find almost-optimal solutions to NP-hard problems in ~quadratic time.</p>
            <p>Goal is to cover many combinatorial problems, TSP multi-cut, etc.</p>
            <ul>
              <li>fast backward pass</li>
              <li>theoretically sound</li>
              <li>easy to use</li>
            </ul>
            <p>But the goal is not to take a combinatorial problem but just relax it to make it differentiable, because there is often a huge price to pay for this.</p>
            <p>Many think that it is essential to extend classical deep learning with combinatorics for AI.</p>
            <p>Pipeline:</p>
            <p>We get an input -&gt; learn a representation with deep learning -&gt; use existing solver for features and maybe pass this output in another layer of deep learning</p>
            <p>A solve is a function taking continuous inputs and returns a discrete output (TSP: graph nodes coordinates -&gt; shortest path).</p>
            <p>Although objectives are often linear, this is usually still a huge cost. Many classical problems fall into this category. The main difficulty is often the gradient of this black-box optimizer. Usually those solvers are contrary to general opinion perfectly differentiable, actually piece-wise constant. -&gt; problem the gradient is almost always 0. Estimating the “real” gradient doesn’t help at all.</p>
            <p>Some non-solutions:</p>
            <ul>
              <li>Sample finite differences</li>
              <li>Apply smoothing</li>
              <li>Use some zero-order method?</li>
            </ul>
            <p>But these methods need a lot a samples to be accurate, and the samples are potentially very expensive because the solver is expensive.</p>
            <p>\(x \rightarrow … \rightarrow w \rightarrow y … \rightarrow L\) Let’s consider \(L(w)\), sometimes a function \(f(w)\) can be representative.</p>
            <p>Interpolate \(L(w)\) to \(L^\lambda(w)\) where lambda controls “locality” of interpolation. But the interpolation is implicit, and the gradient of this interpolated function can be estimated with only one evaluation of the solver. This exploits the fact that the solver minimizes a linear objective.</p>
            <p>Input \(dL/dy\) and output \(dL/dw\)</p>
            <p>Lambda shifts “islands” of constant values and linear slope appears in between them.</p>
          </div>
          <div class="note-footer">
            Last changed <a class="u-url" href="https://hugocisneros.com/notes/talk_differentiation_of_black_box_combinatorial_solvers/"><time itemprop="datePublished" class="dt-published" datetime="2020-07-09T12:43:00+0200">09/07/2020</time></a> | authored by <a href="https://hugocisneros.com/" rel="author" class="p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Hugo Cisneros</span></a>
          </div>
        </div>
      </article>
      <h3>Comments</h3>
      <script data-isso="//comment.hugocisneros.com/" data-isso-require-author="true" data-isso-vote="true" src="//comment.hugocisneros.com/js/embed.min.js"></script>
      <section id="isso-thread"></section><br>
      <a href="/notes#talk_differentiation_of_black_box_combinatorial_solvers"><b>← Back to Notes</b></a>
      <hr>
    </main>
    <footer class="footer">
      <ul class="footer-links">
        <li>
          <a class="rss-link" href="/blog/index.xml" type="application/rss+xml" target="_blank">Blog <img class="rss-icon" src="/img/RSS.svg" alt="RSS feed icon"></a>
        </li>
        <li>
          <a href="https://github.com/hugcis/natrium-custom">Code</a>
        </li>
        <li>© Hugo Cisneros 2022</li>
      </ul>
    </footer>
  </div>
  <link rel="stylesheet" href="/js/katex/katex.min.css">
  <script src="/js/katex/katex.min.js"></script> 
  <script src="/js/katex/contrib/auto-render.min.js"></script> 
  <script>

    document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        delimiters: [
            {left: "\\[", right: "\\]", display: true},
            {left: "$$", right: "$$", display: true},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "$", right: "$", display: false},
            {left: "\\(", right: "\\)", display: false},
        ]
  })
    });
  </script>
</body>
</html>
